Search.setIndex({"docnames": ["index", "resources/contributing", "resources/support", "tt_metal_models/get_performance", "tt_metal_models/get_started", "ttnn/about", "ttnn/adding_new_ttnn_operation", "ttnn/api", "ttnn/converting_torch_model_to_ttnn", "ttnn/demos", "ttnn/dependencies/examples", "ttnn/dependencies/index", "ttnn/dependencies/tensor", "ttnn/dependencies/tt_lib", "ttnn/get_started", "ttnn/installing", "ttnn/onboarding", "ttnn/profiling_ttnn_operations", "ttnn/tensor", "ttnn/ttnn/MaxPool2d", "ttnn/ttnn/abs", "ttnn/ttnn/acos", "ttnn/ttnn/acosh", "ttnn/ttnn/add", "ttnn/ttnn/addcdiv", "ttnn/ttnn/addcmul", "ttnn/ttnn/arange", "ttnn/ttnn/argmax", "ttnn/ttnn/as_tensor", "ttnn/ttnn/asin", "ttnn/ttnn/asinh", "ttnn/ttnn/atan", "ttnn/ttnn/atan2", "ttnn/ttnn/atanh", "ttnn/ttnn/cbrt", "ttnn/ttnn/celu", "ttnn/ttnn/clip", "ttnn/ttnn/clone", "ttnn/ttnn/close_device", "ttnn/ttnn/concat", "ttnn/ttnn/cos", "ttnn/ttnn/cosh", "ttnn/ttnn/create_sharded_memory_config", "ttnn/ttnn/deallocate", "ttnn/ttnn/deg2rad", "ttnn/ttnn/digamma", "ttnn/ttnn/dump_tensor", "ttnn/ttnn/elu", "ttnn/ttnn/embedding", "ttnn/ttnn/empty", "ttnn/ttnn/eq", "ttnn/ttnn/eqz", "ttnn/ttnn/erf", "ttnn/ttnn/erfc", "ttnn/ttnn/erfinv", "ttnn/ttnn/exp", "ttnn/ttnn/exp2", "ttnn/ttnn/expm1", "ttnn/ttnn/from_device", "ttnn/ttnn/from_torch", "ttnn/ttnn/full", "ttnn/ttnn/full_like", "ttnn/ttnn/ge", "ttnn/ttnn/geglu", "ttnn/ttnn/gelu", "ttnn/ttnn/gez", "ttnn/ttnn/global_avg_pool2d", "ttnn/ttnn/glu", "ttnn/ttnn/group_norm", "ttnn/ttnn/gt", "ttnn/ttnn/gtz", "ttnn/ttnn/hardshrink", "ttnn/ttnn/hardsigmoid", "ttnn/ttnn/hardswish", "ttnn/ttnn/hardtanh", "ttnn/ttnn/heaviside", "ttnn/ttnn/hypot", "ttnn/ttnn/i0", "ttnn/ttnn/isclose", "ttnn/ttnn/isfinite", "ttnn/ttnn/isinf", "ttnn/ttnn/isnan", "ttnn/ttnn/isneginf", "ttnn/ttnn/isposinf", "ttnn/ttnn/kv_cache/fill_cache_for_user_", "ttnn/ttnn/kv_cache/update_cache_for_token_", "ttnn/ttnn/l1_loss", "ttnn/ttnn/layer_norm", "ttnn/ttnn/ldexp", "ttnn/ttnn/le", "ttnn/ttnn/leaky_relu", "ttnn/ttnn/lerp", "ttnn/ttnn/lez", "ttnn/ttnn/lgamma", "ttnn/ttnn/linear", "ttnn/ttnn/load_tensor", "ttnn/ttnn/log", "ttnn/ttnn/log10", "ttnn/ttnn/log1p", "ttnn/ttnn/log2", "ttnn/ttnn/log_sigmoid", "ttnn/ttnn/logaddexp", "ttnn/ttnn/logaddexp2", "ttnn/ttnn/logical_and", "ttnn/ttnn/logical_not", "ttnn/ttnn/logical_or", "ttnn/ttnn/logical_xor", "ttnn/ttnn/logit", "ttnn/ttnn/lt", "ttnn/ttnn/ltz", "ttnn/ttnn/mac", "ttnn/ttnn/manage_device", "ttnn/ttnn/matmul", "ttnn/ttnn/max", "ttnn/ttnn/maximum", "ttnn/ttnn/mean", "ttnn/ttnn/min", "ttnn/ttnn/minimum", "ttnn/ttnn/mish", "ttnn/ttnn/model_preprocessing/preprocess_model", "ttnn/ttnn/model_preprocessing/preprocess_model_parameters", "ttnn/ttnn/mse_loss", "ttnn/ttnn/multigammaln", "ttnn/ttnn/multiply", "ttnn/ttnn/ne", "ttnn/ttnn/neg", "ttnn/ttnn/nextafter", "ttnn/ttnn/nez", "ttnn/ttnn/ones", "ttnn/ttnn/ones_like", "ttnn/ttnn/open_device", "ttnn/ttnn/pad", "ttnn/ttnn/permute", "ttnn/ttnn/polygamma", "ttnn/ttnn/polyval", "ttnn/ttnn/pow", "ttnn/ttnn/prelu", "ttnn/ttnn/rad2deg", "ttnn/ttnn/reallocate", "ttnn/ttnn/reciprocal", "ttnn/ttnn/register_post_operation_hook", "ttnn/ttnn/register_pre_operation_hook", "ttnn/ttnn/reglu", "ttnn/ttnn/relu", "ttnn/ttnn/relu6", "ttnn/ttnn/repeat", "ttnn/ttnn/repeat_interleave", "ttnn/ttnn/reshape", "ttnn/ttnn/rms_norm", "ttnn/ttnn/rsqrt", "ttnn/ttnn/set_printoptions", "ttnn/ttnn/sigmoid", "ttnn/ttnn/sigmoid_accurate", "ttnn/ttnn/sign", "ttnn/ttnn/signbit", "ttnn/ttnn/silu", "ttnn/ttnn/sin", "ttnn/ttnn/sinh", "ttnn/ttnn/softmax", "ttnn/ttnn/softplus", "ttnn/ttnn/softshrink", "ttnn/ttnn/softsign", "ttnn/ttnn/split", "ttnn/ttnn/sqrt", "ttnn/ttnn/square", "ttnn/ttnn/squared_difference", "ttnn/ttnn/std", "ttnn/ttnn/subtract", "ttnn/ttnn/sum", "ttnn/ttnn/swiglu", "ttnn/ttnn/swish", "ttnn/ttnn/synchronize_device", "ttnn/ttnn/tan", "ttnn/ttnn/tanh", "ttnn/ttnn/tanhshrink", "ttnn/ttnn/threshold", "ttnn/ttnn/to_device", "ttnn/ttnn/to_layout", "ttnn/ttnn/to_memory_config", "ttnn/ttnn/to_torch", "ttnn/ttnn/topk", "ttnn/ttnn/transformer/attention_softmax", "ttnn/ttnn/transformer/attention_softmax_", "ttnn/ttnn/transformer/concatenate_heads", "ttnn/ttnn/transformer/rotary_embedding", "ttnn/ttnn/transformer/split_query_key_value_and_split_heads", "ttnn/ttnn/tril", "ttnn/ttnn/triu", "ttnn/ttnn/upsample", "ttnn/ttnn/var", "ttnn/ttnn/where", "ttnn/ttnn/xlogy", "ttnn/ttnn/zeros", "ttnn/ttnn/zeros_like", "ttnn/tutorials", "ttnn/tutorials/graphing_torch_dit", "ttnn/tutorials/matmul", "ttnn/tutorials/multihead-attention", "ttnn/tutorials/profiling", "ttnn/tutorials/resnet-basic-block", "ttnn/tutorials/tensor_and_add_operation", "ttnn/tutorials/ttnn-tracer", "ttnn/tutorials/ttnn_tutorials/001", "ttnn/tutorials/ttnn_tutorials/002", "ttnn/tutorials/ttnn_tutorials/003", "ttnn/tutorials/ttnn_tutorials/004", "ttnn/tutorials/ttnn_tutorials/005", "ttnn/tutorials/ttnn_tutorials/006", "ttnn/tutorials/ttnn_tutorials/007", "ttnn/usage", "ttnn_sweeps/index"], "filenames": ["index.rst", "resources/contributing.rst", "resources/support.rst", "tt_metal_models/get_performance.rst", "tt_metal_models/get_started.rst", "ttnn/about.rst", "ttnn/adding_new_ttnn_operation.rst", "ttnn/api.rst", "ttnn/converting_torch_model_to_ttnn.rst", "ttnn/demos.rst", "ttnn/dependencies/examples.rst", "ttnn/dependencies/index.rst", "ttnn/dependencies/tensor.rst", "ttnn/dependencies/tt_lib.rst", "ttnn/get_started.rst", "ttnn/installing.rst", "ttnn/onboarding.rst", "ttnn/profiling_ttnn_operations.rst", "ttnn/tensor.rst", "ttnn/ttnn/MaxPool2d.rst", "ttnn/ttnn/abs.rst", "ttnn/ttnn/acos.rst", "ttnn/ttnn/acosh.rst", "ttnn/ttnn/add.rst", "ttnn/ttnn/addcdiv.rst", "ttnn/ttnn/addcmul.rst", "ttnn/ttnn/arange.rst", "ttnn/ttnn/argmax.rst", "ttnn/ttnn/as_tensor.rst", "ttnn/ttnn/asin.rst", "ttnn/ttnn/asinh.rst", "ttnn/ttnn/atan.rst", "ttnn/ttnn/atan2.rst", "ttnn/ttnn/atanh.rst", "ttnn/ttnn/cbrt.rst", "ttnn/ttnn/celu.rst", "ttnn/ttnn/clip.rst", "ttnn/ttnn/clone.rst", "ttnn/ttnn/close_device.rst", "ttnn/ttnn/concat.rst", "ttnn/ttnn/cos.rst", "ttnn/ttnn/cosh.rst", "ttnn/ttnn/create_sharded_memory_config.rst", "ttnn/ttnn/deallocate.rst", "ttnn/ttnn/deg2rad.rst", "ttnn/ttnn/digamma.rst", "ttnn/ttnn/dump_tensor.rst", "ttnn/ttnn/elu.rst", "ttnn/ttnn/embedding.rst", "ttnn/ttnn/empty.rst", "ttnn/ttnn/eq.rst", "ttnn/ttnn/eqz.rst", "ttnn/ttnn/erf.rst", "ttnn/ttnn/erfc.rst", "ttnn/ttnn/erfinv.rst", "ttnn/ttnn/exp.rst", "ttnn/ttnn/exp2.rst", "ttnn/ttnn/expm1.rst", "ttnn/ttnn/from_device.rst", "ttnn/ttnn/from_torch.rst", "ttnn/ttnn/full.rst", "ttnn/ttnn/full_like.rst", "ttnn/ttnn/ge.rst", "ttnn/ttnn/geglu.rst", "ttnn/ttnn/gelu.rst", "ttnn/ttnn/gez.rst", "ttnn/ttnn/global_avg_pool2d.rst", "ttnn/ttnn/glu.rst", "ttnn/ttnn/group_norm.rst", "ttnn/ttnn/gt.rst", "ttnn/ttnn/gtz.rst", "ttnn/ttnn/hardshrink.rst", "ttnn/ttnn/hardsigmoid.rst", "ttnn/ttnn/hardswish.rst", "ttnn/ttnn/hardtanh.rst", "ttnn/ttnn/heaviside.rst", "ttnn/ttnn/hypot.rst", "ttnn/ttnn/i0.rst", "ttnn/ttnn/isclose.rst", "ttnn/ttnn/isfinite.rst", "ttnn/ttnn/isinf.rst", "ttnn/ttnn/isnan.rst", "ttnn/ttnn/isneginf.rst", "ttnn/ttnn/isposinf.rst", "ttnn/ttnn/kv_cache/fill_cache_for_user_.rst", "ttnn/ttnn/kv_cache/update_cache_for_token_.rst", "ttnn/ttnn/l1_loss.rst", "ttnn/ttnn/layer_norm.rst", "ttnn/ttnn/ldexp.rst", "ttnn/ttnn/le.rst", "ttnn/ttnn/leaky_relu.rst", "ttnn/ttnn/lerp.rst", "ttnn/ttnn/lez.rst", "ttnn/ttnn/lgamma.rst", "ttnn/ttnn/linear.rst", "ttnn/ttnn/load_tensor.rst", "ttnn/ttnn/log.rst", "ttnn/ttnn/log10.rst", "ttnn/ttnn/log1p.rst", "ttnn/ttnn/log2.rst", "ttnn/ttnn/log_sigmoid.rst", "ttnn/ttnn/logaddexp.rst", "ttnn/ttnn/logaddexp2.rst", "ttnn/ttnn/logical_and.rst", "ttnn/ttnn/logical_not.rst", "ttnn/ttnn/logical_or.rst", "ttnn/ttnn/logical_xor.rst", "ttnn/ttnn/logit.rst", "ttnn/ttnn/lt.rst", "ttnn/ttnn/ltz.rst", "ttnn/ttnn/mac.rst", "ttnn/ttnn/manage_device.rst", "ttnn/ttnn/matmul.rst", "ttnn/ttnn/max.rst", "ttnn/ttnn/maximum.rst", "ttnn/ttnn/mean.rst", "ttnn/ttnn/min.rst", "ttnn/ttnn/minimum.rst", "ttnn/ttnn/mish.rst", "ttnn/ttnn/model_preprocessing/preprocess_model.rst", "ttnn/ttnn/model_preprocessing/preprocess_model_parameters.rst", "ttnn/ttnn/mse_loss.rst", "ttnn/ttnn/multigammaln.rst", "ttnn/ttnn/multiply.rst", "ttnn/ttnn/ne.rst", "ttnn/ttnn/neg.rst", "ttnn/ttnn/nextafter.rst", "ttnn/ttnn/nez.rst", "ttnn/ttnn/ones.rst", "ttnn/ttnn/ones_like.rst", "ttnn/ttnn/open_device.rst", "ttnn/ttnn/pad.rst", "ttnn/ttnn/permute.rst", "ttnn/ttnn/polygamma.rst", "ttnn/ttnn/polyval.rst", "ttnn/ttnn/pow.rst", "ttnn/ttnn/prelu.rst", "ttnn/ttnn/rad2deg.rst", "ttnn/ttnn/reallocate.rst", "ttnn/ttnn/reciprocal.rst", "ttnn/ttnn/register_post_operation_hook.rst", "ttnn/ttnn/register_pre_operation_hook.rst", "ttnn/ttnn/reglu.rst", "ttnn/ttnn/relu.rst", "ttnn/ttnn/relu6.rst", "ttnn/ttnn/repeat.rst", "ttnn/ttnn/repeat_interleave.rst", "ttnn/ttnn/reshape.rst", "ttnn/ttnn/rms_norm.rst", "ttnn/ttnn/rsqrt.rst", "ttnn/ttnn/set_printoptions.rst", "ttnn/ttnn/sigmoid.rst", "ttnn/ttnn/sigmoid_accurate.rst", "ttnn/ttnn/sign.rst", "ttnn/ttnn/signbit.rst", "ttnn/ttnn/silu.rst", "ttnn/ttnn/sin.rst", "ttnn/ttnn/sinh.rst", "ttnn/ttnn/softmax.rst", "ttnn/ttnn/softplus.rst", "ttnn/ttnn/softshrink.rst", "ttnn/ttnn/softsign.rst", "ttnn/ttnn/split.rst", "ttnn/ttnn/sqrt.rst", "ttnn/ttnn/square.rst", "ttnn/ttnn/squared_difference.rst", "ttnn/ttnn/std.rst", "ttnn/ttnn/subtract.rst", "ttnn/ttnn/sum.rst", "ttnn/ttnn/swiglu.rst", "ttnn/ttnn/swish.rst", "ttnn/ttnn/synchronize_device.rst", "ttnn/ttnn/tan.rst", "ttnn/ttnn/tanh.rst", "ttnn/ttnn/tanhshrink.rst", "ttnn/ttnn/threshold.rst", "ttnn/ttnn/to_device.rst", "ttnn/ttnn/to_layout.rst", "ttnn/ttnn/to_memory_config.rst", "ttnn/ttnn/to_torch.rst", "ttnn/ttnn/topk.rst", "ttnn/ttnn/transformer/attention_softmax.rst", "ttnn/ttnn/transformer/attention_softmax_.rst", "ttnn/ttnn/transformer/concatenate_heads.rst", "ttnn/ttnn/transformer/rotary_embedding.rst", "ttnn/ttnn/transformer/split_query_key_value_and_split_heads.rst", "ttnn/ttnn/tril.rst", "ttnn/ttnn/triu.rst", "ttnn/ttnn/upsample.rst", "ttnn/ttnn/var.rst", "ttnn/ttnn/where.rst", "ttnn/ttnn/xlogy.rst", "ttnn/ttnn/zeros.rst", "ttnn/ttnn/zeros_like.rst", "ttnn/tutorials.rst", "ttnn/tutorials/graphing_torch_dit.rst", "ttnn/tutorials/matmul.rst", "ttnn/tutorials/multihead-attention.rst", "ttnn/tutorials/profiling.rst", "ttnn/tutorials/resnet-basic-block.rst", "ttnn/tutorials/tensor_and_add_operation.rst", "ttnn/tutorials/ttnn-tracer.rst", "ttnn/tutorials/ttnn_tutorials/001.ipynb", "ttnn/tutorials/ttnn_tutorials/002.ipynb", "ttnn/tutorials/ttnn_tutorials/003.ipynb", "ttnn/tutorials/ttnn_tutorials/004.ipynb", "ttnn/tutorials/ttnn_tutorials/005.ipynb", "ttnn/tutorials/ttnn_tutorials/006.ipynb", "ttnn/tutorials/ttnn_tutorials/007.ipynb", "ttnn/usage.rst", "ttnn_sweeps/index.rst"], "titles": ["Welcome to TT-NN documentation!", "Contributing as a developer", "Support", "Performance", "Getting Started", "What is ttnn?", "Adding New ttnn Operation", "APIs", "Converting torch Model to ttnn", "Building and Uplifting Demos", "Examples of Tensor and TT-LIB Use", "Dependencies", "Tensor", "TT-LIB", "Getting Started", "Install", "Onboarding New Functionality", "Profiling ttnn Operations", "Tensor", "ttnn.MaxPool2d", "ttnn.abs", "ttnn.acos", "ttnn.acosh", "ttnn.add", "ttnn.addcdiv", "ttnn.addcmul", "ttnn.arange", "ttnn.argmax", "ttnn.as_tensor", "ttnn.asin", "ttnn.asinh", "ttnn.atan", "ttnn.atan2", "ttnn.atanh", "ttnn.cbrt", "ttnn.celu", "ttnn.clip", "ttnn.clone", "ttnn.close_device", "ttnn.concat", "ttnn.cos", "ttnn.cosh", "ttnn.create_sharded_memory_config", "ttnn.deallocate", "ttnn.deg2rad", "ttnn.digamma", "ttnn.dump_tensor", "ttnn.elu", "ttnn.embedding", "ttnn.empty", "ttnn.eq", "ttnn.eqz", "ttnn.erf", "ttnn.erfc", "ttnn.erfinv", "ttnn.exp", "ttnn.exp2", "ttnn.expm1", "ttnn.from_device", "ttnn.from_torch", "ttnn.full", "ttnn.full_like", "ttnn.ge", "ttnn.geglu", "ttnn.gelu", "ttnn.gez", "ttnn.global_avg_pool2d", "ttnn.glu", "ttnn.group_norm", "ttnn.gt", "ttnn.gtz", "ttnn.hardshrink", "ttnn.hardsigmoid", "ttnn.hardswish", "ttnn.hardtanh", "ttnn.heaviside", "ttnn.hypot", "ttnn.i0", "ttnn.isclose", "ttnn.isfinite", "ttnn.isinf", "ttnn.isnan", "ttnn.isneginf", "ttnn.isposinf", "ttnn.kv_cache.fill_cache_for_user_", "ttnn.kv_cache.update_cache_for_token_", "ttnn.l1_loss", "ttnn.layer_norm", "ttnn.ldexp", "ttnn.le", "ttnn.leaky_relu", "ttnn.lerp", "ttnn.lez", "ttnn.lgamma", "ttnn.linear", "ttnn.load_tensor", "ttnn.log", "ttnn.log10", "ttnn.log1p", "ttnn.log2", "ttnn.log_sigmoid", "ttnn.logaddexp", "ttnn.logaddexp2", "ttnn.logical_and", "ttnn.logical_not", "ttnn.logical_or", "ttnn.logical_xor", "ttnn.logit", "ttnn.lt", "ttnn.ltz", "ttnn.mac", "ttnn.manage_device", "ttnn.matmul", "ttnn.max", "ttnn.maximum", "ttnn.mean", "ttnn.min", "ttnn.minimum", "ttnn.mish", "ttnn.model_preprocessing.preprocess_model", "ttnn.model_preprocessing.preprocess_model_parameters", "ttnn.mse_loss", "ttnn.multigammaln", "ttnn.multiply", "ttnn.ne", "ttnn.neg", "ttnn.nextafter", "ttnn.nez", "ttnn.ones", "ttnn.ones_like", "ttnn.open_device", "ttnn.pad", "ttnn.permute", "ttnn.polygamma", "ttnn.polyval", "ttnn.pow", "ttnn.prelu", "ttnn.rad2deg", "ttnn.reallocate", "ttnn.reciprocal", "ttnn.register_post_operation_hook", "ttnn.register_pre_operation_hook", "ttnn.reglu", "ttnn.relu", "ttnn.relu6", "ttnn.repeat", "ttnn.repeat_interleave", "ttnn.reshape", "ttnn.rms_norm", "ttnn.rsqrt", "ttnn.set_printoptions", "ttnn.sigmoid", "ttnn.sigmoid_accurate", "ttnn.sign", "ttnn.signbit", "ttnn.silu", "ttnn.sin", "ttnn.sinh", "ttnn.softmax", "ttnn.softplus", "ttnn.softshrink", "ttnn.softsign", "ttnn.split", "ttnn.sqrt", "ttnn.square", "ttnn.squared_difference", "ttnn.std", "ttnn.subtract", "ttnn.sum", "ttnn.swiglu", "ttnn.swish", "ttnn.synchronize_device", "ttnn.tan", "ttnn.tanh", "ttnn.tanhshrink", "ttnn.threshold", "ttnn.to_device", "ttnn.to_layout", "ttnn.to_memory_config", "ttnn.to_torch", "ttnn.topk", "ttnn.transformer.attention_softmax", "ttnn.transformer.attention_softmax_", "ttnn.transformer.concatenate_heads", "ttnn.transformer.rotary_embedding", "ttnn.transformer.split_query_key_value_and_split_heads", "ttnn.tril", "ttnn.triu", "ttnn.upsample", "ttnn.var", "ttnn.where", "ttnn.xlogy", "ttnn.zeros", "ttnn.zeros_like", "Tutorials", "Graphing Torch DiT_XL_2 With TTNN", "Matmul Operation", "Multi-Head Attention", "ttnn Profiling", "Resnet Basic Block", "Tensor and Add Operation", "ttnn Tracer", "Tensor and Add Operation", "Matrix Multiplication", "Multi-Head Attention", "Tracing ttnn operations and torch modules/functions", "Profiling ttnn operations", "Resnet Block", "Build a graph of a pytorch based model", "Using ttnn", "Placeholder title"], "terms": {"what": [0, 9, 17, 208], "i": [0, 3, 4, 6, 8, 9, 10, 12, 13, 14, 16, 17, 18, 19, 27, 37, 42, 48, 50, 62, 66, 69, 89, 108, 112, 119, 120, 124, 130, 131, 140, 141, 146, 158, 177, 179, 181, 182, 184, 185, 188, 190, 194, 202, 203, 204, 205, 206, 207, 208, 209], "kei": [0, 8, 18, 185, 202, 204, 206], "featur": [0, 13, 16, 209], "get": [0, 6, 8, 10, 12, 15, 183, 190, 194, 199, 202, 203, 206], "start": [0, 8, 12, 13, 17, 26, 204, 206], "1": [0, 3, 6, 10, 12, 13, 16, 18, 19, 20, 21, 22, 28, 29, 30, 31, 33, 34, 37, 39, 40, 41, 44, 45, 47, 51, 52, 53, 54, 55, 56, 57, 59, 63, 64, 65, 66, 67, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 90, 92, 93, 96, 97, 98, 99, 100, 109, 112, 118, 122, 125, 127, 132, 137, 139, 142, 143, 144, 145, 146, 147, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 163, 164, 169, 170, 172, 173, 174, 177, 178, 185, 186, 187, 202, 203, 204, 205, 206, 207, 208], "instal": [0, 3, 9, 17, 194, 206, 208], "build": [0, 10, 15, 194, 195, 206], "2": [0, 11, 12, 18, 20, 21, 22, 23, 28, 29, 30, 31, 33, 34, 40, 41, 44, 45, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 59, 62, 64, 65, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 88, 89, 90, 92, 93, 96, 97, 98, 99, 100, 101, 102, 103, 105, 108, 109, 112, 113, 115, 116, 118, 122, 123, 124, 125, 127, 131, 132, 137, 139, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 163, 164, 165, 166, 167, 168, 170, 172, 173, 174, 179, 185, 186, 187, 188, 189, 194, 195, 202, 203, 204, 205, 206, 207], "explor": 0, "our": [0, 3, 4, 5, 9, 13, 15, 16, 18, 202], "demo": [0, 4, 17, 205], "3": [0, 3, 12, 13, 18, 28, 39, 48, 59, 66, 78, 132, 145, 147, 158, 177, 179, 185, 202, 203, 204, 205, 206, 207, 208], "tutori": [0, 15, 195, 196, 197, 198, 199, 200, 201, 204, 208], "multi": [0, 13, 18, 28, 188, 194, 202], "head": [0, 181, 182, 183, 185, 194], "attent": [0, 181, 182, 185, 194], "simpl": [0, 15, 206, 208], "4": [0, 12, 13, 18, 20, 21, 23, 27, 29, 31, 39, 40, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 62, 64, 65, 66, 68, 69, 70, 75, 77, 78, 79, 80, 81, 82, 83, 87, 88, 89, 90, 92, 96, 97, 99, 100, 101, 102, 103, 105, 108, 109, 113, 115, 116, 123, 124, 125, 127, 139, 143, 144, 145, 146, 147, 148, 149, 151, 153, 154, 155, 156, 158, 159, 163, 164, 165, 166, 167, 168, 172, 173, 177, 181, 182, 183, 184, 188, 189, 202, 203, 204, 205, 206, 207, 208], "optim": [0, 13, 194, 197, 202], "where": [0, 2, 3, 4, 7, 9, 11, 13, 17, 18, 37, 42, 112, 177, 208], "go": [0, 15, 202], "from": [0, 2, 3, 4, 5, 6, 8, 9, 11, 12, 17, 18, 28, 38, 84, 85, 167, 190, 194, 195, 199, 202, 204, 205, 206], "here": [0, 2, 15, 203, 208, 210], "step": [0, 9, 10, 13, 16, 26, 202, 208], "driver": [0, 202, 203, 204, 205, 206, 207], "firmwar": 0, "system": [0, 17], "level": [0, 17], "depend": [0, 4, 5, 9, 13, 17, 18, 37, 112, 177, 194, 206], "hugepag": [0, 202, 203, 204, 205, 206, 207], "us": [0, 3, 4, 5, 8, 9, 11, 12, 13, 14, 16, 17, 18, 28, 39, 42, 48, 52, 53, 55, 64, 94, 112, 119, 120, 131, 132, 140, 141, 145, 149, 158, 159, 177, 178, 179, 184, 185, 194, 196, 197, 200, 201, 206, 208], "metalium": [0, 3, 4], "option": [0, 6, 11, 12, 17, 20, 21, 22, 23, 27, 28, 29, 30, 31, 33, 34, 40, 41, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 69, 70, 72, 73, 74, 75, 77, 79, 80, 81, 82, 83, 87, 88, 89, 90, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 105, 108, 109, 112, 118, 122, 123, 124, 125, 126, 127, 128, 129, 137, 139, 143, 144, 148, 149, 151, 152, 153, 154, 155, 156, 157, 159, 161, 163, 164, 165, 167, 170, 172, 173, 174, 176, 177, 178, 181, 182, 184, 186, 187, 192, 193, 208, 209], "sourc": [0, 3, 4, 84, 194], "wheel": [0, 206], "5": [0, 12, 13, 42, 48, 147, 202, 203, 204, 205, 206, 207, 208], "softwar": [0, 194], "codebas": 0, "contribut": [0, 2, 14], "basic": [0, 14, 15, 194], "exampl": [0, 5, 9, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 28, 29, 30, 31, 33, 34, 37, 39, 40, 41, 42, 44, 45, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 59, 62, 64, 65, 66, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 88, 89, 90, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 105, 108, 109, 112, 118, 122, 123, 124, 125, 127, 132, 137, 139, 143, 144, 145, 146, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 163, 164, 165, 167, 170, 172, 173, 174, 177, 179, 186, 187, 202, 208], "convert": [0, 5, 10, 11, 13, 28, 37, 59, 119, 120, 178, 179, 194, 197, 200, 203], "torch": [0, 5, 6, 10, 12, 18, 20, 21, 22, 23, 27, 28, 29, 30, 31, 33, 34, 37, 39, 40, 41, 44, 45, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 59, 62, 64, 65, 66, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 88, 89, 90, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 105, 108, 109, 112, 118, 119, 120, 122, 123, 124, 125, 127, 132, 137, 139, 143, 144, 145, 146, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 163, 164, 165, 167, 170, 172, 173, 174, 177, 178, 179, 185, 186, 187, 194, 196, 197, 199, 200, 201, 206, 208], "tensor": [0, 4, 5, 6, 8, 11, 17, 22, 24, 25, 26, 28, 30, 32, 33, 34, 35, 36, 37, 39, 41, 42, 43, 44, 45, 46, 58, 59, 61, 63, 67, 71, 72, 73, 74, 76, 78, 84, 85, 86, 91, 93, 94, 95, 98, 106, 107, 110, 112, 114, 117, 118, 119, 120, 121, 122, 126, 129, 131, 132, 133, 134, 135, 137, 138, 142, 147, 152, 157, 160, 161, 169, 170, 174, 175, 176, 179, 185, 186, 187, 190, 191, 193, 194, 196, 204, 205, 207, 208], "run": [0, 5, 6, 9, 11, 13, 14, 15, 16, 17, 119, 140, 141, 194, 197, 199, 202, 203, 206], "an": [0, 2, 3, 5, 12, 13, 14, 15, 16, 17, 18, 19, 48, 66, 112, 202, 204, 208], "oper": [0, 5, 9, 10, 11, 12, 14, 16, 20, 21, 22, 29, 30, 31, 33, 34, 37, 39, 40, 41, 44, 45, 47, 51, 52, 53, 54, 55, 56, 57, 64, 65, 66, 70, 72, 73, 74, 75, 77, 79, 80, 81, 82, 83, 90, 92, 93, 94, 96, 97, 98, 99, 100, 109, 112, 118, 122, 125, 127, 131, 137, 139, 140, 141, 143, 144, 145, 146, 149, 151, 152, 153, 154, 155, 156, 157, 159, 161, 163, 164, 170, 171, 172, 173, 174, 177, 179, 186, 187, 194, 198, 201, 203, 204, 207], "devic": [0, 5, 6, 8, 9, 11, 12, 15, 17, 18, 19, 20, 21, 22, 23, 26, 28, 29, 30, 31, 33, 34, 37, 38, 39, 40, 41, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 108, 109, 111, 112, 118, 119, 120, 122, 123, 124, 125, 127, 128, 129, 130, 132, 137, 138, 139, 143, 144, 145, 146, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 163, 164, 165, 167, 170, 171, 172, 173, 174, 176, 177, 178, 186, 187, 192, 193, 194, 196, 197, 200, 205, 206, 207, 208], "__getitem__": [0, 203], "slice": [0, 13], "enabl": [0, 3, 13, 15, 16, 194, 196, 197, 206, 208], "program": [0, 3, 5, 6, 11, 17, 94, 112, 181, 182, 194, 196, 197, 206], "cach": [0, 3, 5, 11, 17, 18, 28, 38, 84, 85, 119, 120, 184, 194, 196, 197, 206, 208], "debug": [0, 5, 13, 16, 204], "intermedi": 0, "6": [0, 12, 13, 18, 202, 203, 204, 205, 206, 207, 208], "trace": [0, 5, 194, 199, 201, 208], "graph": [0, 5, 11, 119, 194, 199], "7": [0, 12, 48, 202, 203, 204, 205, 206, 207, 208], "tt_lib": [0, 5, 6, 10, 11, 12, 24, 25, 32, 35, 36, 39, 43, 58, 63, 67, 71, 76, 86, 91, 106, 107, 110, 114, 117, 121, 132, 133, 135, 138, 142, 147, 160, 169, 175, 176, 191], "8": [0, 12, 15, 17, 18, 42, 48, 178, 202, 203, 204, 205, 206, 207, 208], "log": [0, 7, 11, 17, 203, 205, 206], "9": [0, 12, 13, 15, 48, 202, 203, 204, 205, 206, 207, 208], "support": [0, 1, 5, 10, 12, 13, 18, 23, 42, 50, 62, 69, 88, 89, 101, 102, 103, 105, 108, 123, 124, 165, 167, 202, 207], "python": [0, 4, 13, 15, 16, 17, 206, 208], "10": [0, 10, 12, 13, 15, 48, 66, 78, 94, 112, 177, 178, 202, 203, 204, 206, 208], "chang": [0, 13, 37, 202, 206], "string": [0, 13, 119, 120], "represent": [0, 13, 159], "11": [0, 15, 202, 203, 204, 206], "visual": [0, 5, 205, 207, 208], "web": 0, "browser": [0, 194], "12": [0, 8, 15, 68, 87, 148, 202, 203, 204, 206, 208], "regist": [0, 140, 141], "pre": [0, 15, 141, 194, 195, 197, 206], "post": [0, 13, 17, 140], "hook": [0, 140, 141, 206], "13": [0, 202, 203, 204, 206, 207, 208], "queri": [0, 13, 185, 204], "all": [0, 5, 6, 8, 9, 12, 13, 15, 16, 17, 18, 27, 66, 119, 120, 134, 171, 202, 204, 206], "14": [0, 3, 18, 203, 204, 206], "disabl": [0, 13, 119, 120, 204, 206], "fallback": [0, 10, 11, 16], "shape": [0, 6, 8, 12, 13, 17, 39, 42, 49, 60, 66, 94, 112, 128, 131, 132, 145, 146, 147, 183, 185, 192, 202, 203, 204, 207, 208], "layout": [0, 8, 10, 12, 13, 17, 20, 21, 23, 27, 28, 29, 31, 37, 40, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 75, 77, 79, 80, 81, 82, 83, 87, 88, 89, 90, 92, 96, 97, 99, 100, 101, 102, 103, 105, 108, 109, 113, 115, 116, 123, 124, 125, 127, 128, 129, 139, 143, 144, 145, 146, 148, 149, 151, 153, 154, 155, 156, 158, 159, 163, 164, 165, 166, 167, 168, 172, 173, 177, 178, 181, 182, 183, 184, 188, 189, 192, 193, 194, 196, 200, 204, 209], "data": [0, 6, 8, 10, 12, 13, 17, 23, 27, 28, 37, 50, 59, 62, 66, 69, 88, 89, 94, 101, 102, 103, 105, 108, 112, 123, 124, 126, 165, 167, 177, 178, 188, 194, 200, 206, 209], "type": [0, 6, 8, 10, 11, 12, 17, 23, 27, 28, 37, 50, 59, 62, 66, 69, 88, 89, 94, 101, 102, 103, 105, 108, 112, 123, 124, 126, 147, 165, 167, 177, 178, 194, 200, 206, 208], "storag": [0, 11, 13, 194, 200], "shard": [0, 42, 94, 112, 178, 185], "memori": [0, 8, 9, 12, 13, 17, 20, 21, 22, 23, 27, 28, 29, 30, 31, 33, 34, 37, 39, 40, 41, 44, 45, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 59, 62, 64, 65, 66, 69, 70, 72, 73, 74, 75, 77, 79, 80, 81, 82, 83, 88, 89, 90, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 105, 108, 109, 112, 118, 122, 123, 124, 125, 126, 127, 131, 137, 139, 143, 144, 145, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 163, 164, 165, 167, 170, 172, 173, 174, 177, 181, 182, 183, 184, 185, 186, 187, 190, 202, 204], "config": [0, 8, 15, 23, 27, 37, 48, 50, 62, 69, 88, 89, 101, 102, 103, 105, 108, 123, 124, 126, 165, 167, 181, 182, 183, 184, 185, 190, 194, 196, 204, 205, 206, 209], "api": [0, 4, 5, 8, 11, 14, 15, 16, 204, 209], "rank": [0, 12, 13, 18, 179], "with_tile_pad": [0, 18], "open_devic": [0, 7, 48, 177, 178, 202, 203, 204, 205, 207, 209], "close_devic": [0, 7, 202, 203, 204, 205, 207, 209], "manage_devic": [0, 7], "synchronize_devic": [0, 7], "create_sharded_memory_config": [0, 7, 18], "core": [0, 8, 13, 17, 18, 42, 94, 112, 203, 204, 206], "as_tensor": [0, 7], "from_torch": [0, 6, 7, 8, 20, 21, 22, 23, 29, 30, 31, 33, 34, 37, 39, 40, 41, 44, 45, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 62, 64, 65, 66, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 88, 89, 90, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 105, 108, 109, 112, 118, 122, 123, 124, 125, 127, 132, 137, 139, 143, 144, 145, 146, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 163, 164, 165, 167, 170, 172, 173, 174, 177, 178, 179, 186, 187, 202, 203, 204, 205, 207, 209], "to_torch": [0, 6, 7, 8, 12, 202, 203, 204, 205, 207, 209], "to_devic": [0, 7, 23, 37, 48, 50, 62, 69, 78, 88, 89, 94, 101, 102, 103, 105, 108, 112, 123, 124, 132, 158, 165, 167, 177, 178, 203, 204], "from_devic": [0, 7, 203, 205, 206], "to_layout": [0, 5, 7, 18, 202, 203, 204], "dump_tensor": [0, 7], "load_tensor": [0, 7, 206], "dealloc": [0, 7, 18, 138, 204, 209], "realloc": [0, 7], "to_memory_config": [0, 7, 18, 207], "creation": [0, 11, 12], "arang": [0, 7, 11, 12, 13], "empti": [0, 7, 11, 13, 112, 208, 209], "zero": [0, 7, 11, 12, 13, 19, 37, 39, 132, 158, 205, 209], "zeros_lik": [0, 7, 11, 13], "ones": [0, 7, 11, 13], "ones_lik": [0, 7, 11, 13], "full": [0, 5, 7, 9, 11, 13, 17, 209], "full_lik": [0, 7, 11, 13], "matrix": [0, 11, 15, 18, 48, 94, 112, 194, 196, 202, 209], "multipl": [0, 12, 13, 17, 37, 112, 119, 177, 194, 196], "matmul": [0, 7, 11, 13, 94, 194, 203, 204, 206], "linear": [0, 7, 8, 11, 13, 159, 204], "pointwis": 0, "unari": [0, 13], "ab": [0, 7, 11, 13], "aco": [0, 7, 11, 13], "acosh": [0, 7, 11, 13], "asin": [0, 7, 11, 13], "asinh": [0, 7, 11, 13], "atan": [0, 7, 11, 13], "atan2": [0, 7, 11, 13], "atanh": [0, 7, 11, 13], "cbrt": [0, 7, 11, 13], "celu": [0, 7, 11, 13], "clip": [0, 7, 11, 13], "clone": [0, 7, 11, 13, 15, 185, 194, 195], "co": [0, 7, 11, 13], "cosh": [0, 7, 11, 13], "deg2rad": [0, 7, 11, 13], "digamma": [0, 7, 11, 13], "elu": [0, 7, 11, 13], "erf": [0, 7, 11, 13], "erfc": [0, 7, 11, 13], "erfinv": [0, 7, 11, 13], "exp": [0, 6, 7, 10, 11, 13, 205, 209], "exp2": [0, 7, 11, 13], "expm1": [0, 7, 11, 13], "geglu": [0, 7, 11, 13], "gelu": [0, 7, 8, 11, 13], "glu": [0, 7, 11, 13], "hardshrink": [0, 7, 11, 13], "hardsigmoid": [0, 7, 11, 13], "hardswish": [0, 7, 11, 13], "hardtanh": [0, 7, 11, 13], "heavisid": [0, 7, 11, 13], "hypot": [0, 7, 11, 13], "i0": [0, 7, 11, 13], "isfinit": [0, 7, 11, 13], "isinf": [0, 7, 11, 13], "isnan": [0, 7, 11, 13], "isneginf": [0, 7, 11, 13], "isposinf": [0, 7, 11, 13], "leaky_relu": [0, 7, 11, 13], "lerp": [0, 7, 11, 13], "lgamma": [0, 7, 11, 13], "log10": [0, 7, 11, 13], "log1p": [0, 7, 11, 13], "log2": [0, 7, 11, 13], "log_sigmoid": [0, 7, 11, 13], "logical_not": [0, 7], "logit": [0, 7, 11, 13], "mish": [0, 7, 11, 13], "multigammaln": [0, 7, 11, 13], "neg": [0, 7, 11, 13, 19], "prelu": [0, 7], "reglu": [0, 7, 11, 13], "relu": [0, 7, 10, 11, 13, 90, 159, 207], "relu6": [0, 7, 11, 13], "rsqrt": [0, 7, 11, 13], "sigmoid": [0, 7, 11, 13], "sigmoid_accur": [0, 7, 11, 13], "sign": [0, 7, 11, 13], "silu": [0, 7, 10, 11, 13], "sin": [0, 7, 11, 13], "sinh": [0, 7, 11, 13], "softmax": [0, 7, 11, 13, 181, 182, 204], "softplu": [0, 7, 11, 13], "softshrink": [0, 7, 11, 13], "softsign": [0, 7, 11, 13], "swish": [0, 7, 11, 13], "tan": [0, 7, 11, 13], "tanh": [0, 7, 11, 13], "signbit": [0, 7, 11, 13], "polygamma": [0, 7, 11, 13], "rad2deg": [0, 7, 11, 13], "reciproc": [0, 7, 13], "sqrt": [0, 7, 11, 13], "squar": [0, 7, 11, 13, 18, 165, 181, 182], "swiglu": [0, 7, 11, 13], "tril": [0, 7, 11, 13], "triu": [0, 7, 11, 13], "tanhshrink": [0, 7, 11, 13], "threshold": [0, 7, 11, 13, 159], "binari": [0, 13], "add": [0, 7, 9, 13, 16, 50, 62, 69, 88, 89, 101, 102, 103, 105, 108, 123, 124, 131, 165, 167, 181, 182, 194, 204, 206, 207, 209], "multipli": [0, 7, 13, 94, 112, 188, 194, 196, 209], "subtract": [0, 3, 7, 13, 185, 209], "pow": [0, 7, 10, 11, 13], "ldexp": [0, 7, 13], "logical_and": [0, 7], "logical_or": [0, 7], "logical_xor": [0, 7, 11, 13], "logaddexp": [0, 7, 13], "logaddexp2": [0, 7, 13], "xlogi": [0, 7, 11, 13], "squared_differ": [0, 7], "gtz": [0, 7, 11, 13], "ltz": [0, 7, 11, 13], "gez": [0, 7, 11, 13], "lez": [0, 7, 11, 13], "nez": [0, 7, 11, 13], "eqz": [0, 7, 11, 13], "gt": [0, 7, 202, 203, 204, 205, 206, 207, 208], "ge": [0, 7], "lt": [0, 7, 13, 204, 206, 207, 208], "le": [0, 7, 13, 15], "eq": [0, 7], "ne": [0, 7], "isclos": [0, 7, 11, 13], "polyv": [0, 7, 11, 13], "nextaft": [0, 7, 11, 13], "maximum": [0, 7, 13, 27], "minimum": [0, 7, 13, 18], "ternari": [0, 11], "addcdiv": [0, 7, 11, 13], "addcmul": [0, 7, 11, 13], "mac": [0, 7, 11, 13], "loss": [0, 11], "l1_loss": [0, 7], "mse_loss": [0, 7], "reduct": [0, 13], "max": [0, 7, 13, 19, 206, 208], "mean": [0, 7, 10, 13, 18, 94, 112], "min": [0, 7, 13, 208], "std": [0, 6, 7, 12, 13, 24, 25, 27, 32, 35, 36, 63, 67, 71, 76, 86, 91, 106, 107, 110, 114, 117, 121, 133, 135, 142, 160, 169, 175, 191], "sum": [0, 7, 11, 13], "var": [0, 7, 13], "argmax": [0, 7, 11, 13], "topk": [0, 7], "movement": 0, "concat": [0, 7, 11, 13, 16], "pad": [0, 7, 10, 11, 12, 13, 18, 19, 37, 48, 177, 202, 207], "permut": [0, 7, 11, 13, 185, 204, 207], "reshap": [0, 7, 10, 11, 12, 13, 185, 203, 204, 205, 206, 207], "repeat": [0, 5, 7, 11, 13, 146], "repeat_interleav": [0, 7, 11, 13], "normal": [0, 13, 206, 208], "group_norm": [0, 7, 11, 13], "layer_norm": [0, 7, 11, 13], "rms_norm": [0, 7, 87], "transform": [0, 8, 13, 94, 204, 205, 206], "split_query_key_value_and_split_head": [0, 7, 204], "concatenate_head": [0, 7, 204], "attention_softmax": [0, 7], "attention_softmax_": [0, 7, 204], "rotary_embed": [0, 7], "embed": [0, 11, 13, 184, 202], "pool": [0, 13, 19, 66], "global_avg_pool2d": [0, 7], "maxpool2d": [0, 7, 11, 13], "vision": 0, "upsampl": [0, 7, 13], "kv": 0, "kv_cach": [0, 7], "fill_cache_for_user_": [0, 7], "update_cache_for_token_": [0, 7], "convers": [0, 10, 12, 13, 177, 202], "model_preprocess": [0, 7, 8, 204, 205, 206, 207], "preprocess_model": [0, 7, 206, 207], "preprocess_model_paramet": [0, 7, 8, 205], "report": [0, 9, 204, 206, 209], "set_printopt": [0, 7, 209], "register_pre_operation_hook": [0, 7, 209], "register_post_operation_hook": [0, 7, 209], "creat": [0, 4, 10, 12, 13, 16, 18, 42, 194, 199, 200, 204, 208], "host": [0, 10, 11, 12, 17, 18, 28, 171, 177, 194, 200, 203, 204, 205, 206, 207, 209], "borrow": [0, 12, 18, 194, 200], "v": [0, 13, 194, 200], "own": [0, 12, 18, 194, 200], "open": [0, 111, 130, 194, 200, 203, 204, 205, 206, 207, 208, 209], "initi": [0, 8, 10, 13, 119, 120, 194, 196, 197, 200, 205, 206, 207], "b": [0, 13, 146, 184, 194, 196, 200], "random": [0, 10, 194, 196, 200], "valu": [0, 9, 10, 12, 13, 19, 26, 27, 42, 66, 75, 84, 85, 126, 131, 159, 185, 194, 196, 200, 204, 209], "inspect": [0, 194, 196, 200], "output": [0, 3, 6, 8, 9, 10, 11, 12, 17, 20, 21, 22, 23, 27, 29, 30, 31, 33, 34, 37, 39, 40, 41, 44, 45, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 62, 64, 65, 66, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 88, 89, 90, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 105, 108, 109, 112, 118, 122, 123, 124, 125, 126, 127, 132, 137, 139, 140, 143, 144, 146, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 163, 164, 165, 167, 170, 172, 173, 174, 177, 181, 182, 183, 184, 185, 186, 187, 190, 194, 196, 197, 200, 205, 209], "attribut": [0, 8, 13, 17, 18, 194, 200, 206, 209], "close": [0, 10, 38, 111, 194, 196, 197, 200, 205, 206, 207], "configur": [0, 3, 4, 9, 12, 20, 21, 22, 28, 29, 30, 31, 33, 34, 39, 40, 41, 44, 45, 47, 48, 51, 52, 53, 54, 55, 56, 57, 59, 64, 65, 66, 70, 72, 73, 74, 75, 77, 79, 80, 81, 82, 83, 90, 92, 93, 94, 96, 97, 98, 99, 100, 109, 112, 118, 122, 125, 127, 131, 137, 139, 143, 144, 145, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 163, 164, 170, 172, 173, 174, 177, 186, 187, 194, 196, 197], "result": [0, 3, 5, 10, 13, 17, 112, 194, 196], "more": [0, 1, 13, 14, 17, 18, 194, 196, 204, 206, 208], "perform": [0, 8, 9, 12, 13, 14, 16, 17, 66, 194, 196, 204], "write": [0, 1, 3, 4, 8, 18, 42, 94, 112, 194, 197, 206], "activ": [0, 4, 8, 13, 15, 23, 50, 62, 69, 88, 89, 94, 101, 102, 103, 105, 108, 112, 123, 124, 165, 167, 194, 197], "weight": [0, 8, 13, 48, 68, 87, 91, 94, 148, 194, 197, 205, 206, 207], "first": [0, 3, 8, 10, 12, 13, 15, 17, 94, 112, 131, 194, 197, 203, 209], "iter": [0, 194, 197], "subsequ": [0, 194, 197, 203, 209], "version": [0, 13, 17, 112, 119, 120, 194, 197, 199, 206], "process": [0, 13, 17, 194, 197, 206], "paramet": [0, 5, 6, 8, 13, 19, 24, 25, 35, 47, 71, 75, 90, 107, 119, 120, 133, 135, 159, 160, 194, 197, 199, 205], "check": [0, 2, 9, 12, 14, 15, 194, 197, 206], "match": [0, 12, 13, 18, 119, 120, 188, 194, 197, 202, 203, 205, 206, 207], "origin": [0, 9, 16, 119, 120, 194, 197, 202], "implement": [0, 3, 5, 8, 13, 16, 17, 112, 185, 194, 197, 199, 209], "tracer": [0, 5, 194, 205, 207, 208, 209], "modul": [0, 5, 8, 13, 14, 119, 120, 194, 199, 201, 204, 208], "function": [0, 6, 8, 9, 10, 11, 12, 23, 28, 47, 50, 62, 69, 75, 78, 88, 89, 90, 94, 101, 102, 103, 105, 108, 112, 119, 120, 123, 124, 147, 159, 165, 167, 176, 194, 201, 202], "written": [0, 84, 85, 194, 201, 204], "profil": [0, 3, 11, 150, 194, 209], "resnet": [0, 14, 17, 194, 206], "block": [0, 13, 18, 42, 58, 112, 194], "torchvis": [0, 194, 199, 206, 208], "preprocess": [0, 28, 119, 120, 194, 199], "displai": [0, 194, 195, 199], "pass": [0, 8, 10, 13, 16, 140, 141, 184, 185, 194, 199, 202, 206], "constructor": [0, 12, 194, 199], "dit_xl_2": [0, 194, 208], "With": [0, 194], "pytorch": [0, 3, 5, 11, 13, 27, 185, 194, 195, 206], "base": [0, 3, 4, 13, 18, 42, 190, 194, 195, 204], "librari": [0, 4, 5, 10, 11, 12, 194, 195], "http": [0, 14, 15, 194, 195, 206], "github": [0, 2, 14, 15, 194, 195], "com": [0, 14, 15, 194, 195], "facebookresearch": [0, 194, 195], "dit": [0, 194, 195], "git": [0, 15, 119, 120, 194, 195, 206], "download": [0, 15, 194, 195, 206], "xl": [0, 194, 195], "sampl": [0, 13, 194, 195], "train": [0, 13, 194, 195], "onboard": 0, "new": [0, 9, 11, 17, 26, 145, 202], "rewrit": 0, "switch": [0, 159], "ad": [0, 12, 13, 16, 19, 94, 202], "c": [0, 13, 17, 18, 188, 206], "pybind": 0, "unit": [0, 9, 13], "test": [0, 3, 4, 8, 9, 16, 17, 204, 206, 209], "sweep": [0, 16], "perf": [0, 202, 203, 204, 205, 206, 207], "header": [0, 3, 6], "profile_thi": [0, 206], "descript": [0, 6, 12, 13, 16], "lib": [0, 4, 11, 206, 208], "overview": [0, 11], "infrastructur": [0, 5, 11], "member": [0, 2, 11, 12], "input": [0, 6, 9, 10, 11, 12, 17, 19, 22, 26, 30, 33, 34, 41, 44, 45, 72, 73, 74, 78, 84, 85, 93, 94, 98, 110, 112, 118, 122, 126, 131, 132, 134, 137, 138, 152, 157, 161, 170, 174, 185, 186, 187, 203, 204, 207, 208, 209], "fast": [0, 11, 52, 53, 55, 64, 149], "dispatch": [0, 11, 12, 17], "cpu": [0, 3, 10, 11, 12, 13, 17, 204, 206, 208], "synchron": [0, 11, 13, 171, 209], "through": [0, 11, 15, 208], "primari": [0, 5, 11, 203], "layernorm": [0, 11, 13], "add_layernorm": [0, 11, 13], "softmax_in_plac": [0, 11, 13], "moreh_softmax": [0, 11, 13], "moreh_softmax_backward": [0, 11, 13], "moreh_softmin": [0, 11, 13], "moreh_softmin_backward": [0, 11, 13], "moreh_logsoftmax": [0, 11, 13], "moreh_logsoftmax_backward": [0, 11, 13], "scale_mask_softmax_in_plac": [0, 11, 13], "moreh_mean": [0, 11, 13], "moreh_mean_backward": [0, 11, 13], "moreh_groupnorm": [0, 11, 13], "moreh_groupnorm_backward": [0, 11, 13], "moreh_norm": [0, 11, 13], "moreh_norm_backward": [0, 11, 13], "enum": [0, 11], "bcastopmath": [0, 11, 13], "bcastopdim": [0, 11, 13], "reduceopmath": [0, 11, 13], "reduceopdim": [0, 11, 13], "elementwis": [0, 11], "div": [0, 11, 13], "div_no_nan": [0, 11, 13], "add_unari": [0, 11, 13], "sub_unari": [0, 11, 13], "mul_unari": [0, 11, 13], "div_unari": [0, 11, 13], "relu_min": [0, 11, 13], "relu_max": [0, 11, 13], "recip": [0, 11, 13], "add1": [0, 11, 13], "right_shift": [0, 11, 13], "left_shift": [0, 11, 13], "logical_xori": [0, 11, 13], "logical_not_unari": [0, 11, 13], "subalpha": [0, 11, 13], "addalpha": [0, 11, 13], "bias_gelu_unari": [0, 11, 13], "logical_andi": [0, 11, 13], "assign": [0, 10, 11, 13], "logical_ori": [0, 11, 13], "floor": [0, 11, 13], "trunc": [0, 11, 13], "round": [0, 11, 13], "floor_div": [0, 11, 13], "relat": [0, 11], "unary_n": [0, 11, 13], "unary_gt": [0, 11, 13], "unary_lt": [0, 11, 13], "math": [0, 11, 17, 42, 50, 62, 69, 88, 89, 101, 102, 103, 105, 108, 123, 124, 165, 167, 206], "bmm": [0, 11, 13], "transpos": [0, 11, 13, 184, 185], "tiliz": [0, 11, 13, 28, 203, 204], "until": [0, 6, 11, 13, 179, 203], "tilize_with_val_pad": [0, 11, 13], "untilize_with_unpad": [0, 11, 13], "tilize_with_zero_pad": [0, 11, 13], "unpad": [0, 10, 11, 12, 13, 37, 177], "typecast": [0, 11, 13], "copi": [0, 11, 12, 13, 37, 202], "split_last_dim_two_chunks_til": [0, 11, 13], "broadcast": [0, 11, 23, 50, 62, 69, 88, 89, 94, 101, 102, 103, 105, 108, 112, 123, 124, 146, 165, 167, 209], "reduc": [0, 11, 27], "bcast": [0, 11, 13], "global_min": [0, 11, 13], "global_max": [0, 11, 13], "global_sum": [0, 11, 13], "global_mean": [0, 11, 13], "rpow": [0, 11, 13], "rsub": [0, 11, 13], "rdiv": [0, 11, 13], "tensor_slic": [0, 11, 13], "chunk": [0, 11, 13, 203, 208], "conv2d": [0, 11, 13, 207], "interpol": [0, 11, 13], "batchnorm2d": [0, 11, 13, 207], "groupnorm": [0, 11, 13], "adaptiveavgpool2d": [0, 11, 13], "ceil": [0, 11, 13], "unary_fmod": [0, 11, 13], "binary_fmod": [0, 11, 13], "bitwise_not": [0, 11, 13], "unary_bitwise_or": [0, 11, 13], "unary_bitwise_and": [0, 11, 13], "unary_bitwise_xor": [0, 11, 13], "binary_bitwise_or": [0, 11, 13], "binary_bitwise_and": [0, 11, 13], "binary_bitwise_xor": [0, 11, 13], "unary_bitwise_left_shift": [0, 11, 13], "unary_bitwise_right_shift": [0, 11, 13], "binary_bitwise_left_shift": [0, 11, 13], "binary_bitwise_right_shift": [0, 11, 13], "torch_argmax": [0, 11, 13], "torch_argmin": [0, 11, 13], "experiment": [0, 4, 6, 9, 11, 206], "fuse": [0, 8, 11, 204], "mini": [0, 11], "addandnorm": [0, 11, 13], "complex": [0, 11], "complex_add": [0, 11, 13], "complex_sub": [0, 11, 13], "complex_mul": [0, 11, 13], "complex_div": [0, 11, 13], "real": [0, 11, 12, 13], "imag": [0, 11, 13, 17, 18, 208], "complex_ab": [0, 11, 13], "conj": [0, 11, 13], "complex_recip": [0, 11, 13], "polar": [0, 11, 13], "other": [0, 2, 5, 6, 8, 9, 11, 14, 18, 209], "fill_rm": [0, 11, 13], "fill_ones_rm": [0, 11, 13], "conv": [0, 11, 13, 207], "rmsnorm": [0, 11, 13], "convert_conv_weight_tensor_to_tiled_layout": [0, 11, 13], "prod": [0, 11, 13, 42], "tiled_prod": [0, 11, 13], "mean_hw": [0, 11, 13], "var_hw": [0, 11, 13], "logical_noti": [0, 11, 13], "std_hw": [0, 11, 13], "normalize_hw": [0, 11, 13], "normalize_glob": [0, 11, 13], "lamb_optim": [0, 11, 13], "ident": [0, 11, 13, 207], "argmin": [0, 11, 13], "backward": [0, 11], "prod_bw": [0, 11, 13], "addalpha_bw": [0, 11, 13], "addcmul_bw": [0, 11, 13], "addcdiv_bw": [0, 11, 13], "conj_bw": [0, 11, 13], "unary_mul_bw": [0, 11, 13], "unary_add_bw": [0, 11, 13], "unary_assign_bw": [0, 11, 13], "binary_assign_bw": [0, 11, 13], "unary_div_bw": [0, 11, 13], "div_bw": [0, 11, 13], "rdiv_bw": [0, 11, 13], "sqrt_bw": [0, 11, 13], "mul_bw": [0, 11, 13], "max_bw": [0, 11, 13], "min_bw": [0, 11, 13], "add_bw": [0, 11, 13], "tan_bw": [0, 11, 13], "exp_bw": [0, 11, 13], "exp2_bw": [0, 11, 13], "expm1_bw": [0, 11, 13], "unary_pow_bw": [0, 11, 13], "embedding_bw": [0, 11, 13], "where_bw": [0, 11, 13], "tanh_bw": [0, 11, 13], "fill_zero_bw": [0, 11, 13], "fill_bw": [0, 11, 13], "sub_bw": [0, 11, 13], "unary_sub_bw": [0, 11, 13], "log_bw": [0, 11, 13], "rsub_bw": [0, 11, 13], "abs_bw": [0, 11, 13], "complex_abs_bw": [0, 11, 13], "rsqrt_bw": [0, 11, 13], "neg_bw": [0, 11, 13], "lt_bw": [0, 11, 13], "gt_bw": [0, 11, 13], "relu_bw": [0, 11, 13], "ne_bw": [0, 11, 13], "clamp_bw": [0, 11, 13], "clamp_min_bw": [0, 11, 13], "clamp_max_bw": [0, 11, 13], "binary_le_bw": [0, 11, 13], "atan2_bw": [0, 11, 13], "hypot_bw": [0, 11, 13], "gelu_bw": [0, 11, 13], "bias_gelu_bw": [0, 11, 13], "bias_gelu_unary_bw": [0, 11, 13], "squared_difference_bw": [0, 11, 13], "lerp_bw": [0, 11, 13], "ldexp_bw": [0, 11, 13], "xlogy_bw": [0, 11, 13], "logaddexp_bw": [0, 11, 13], "logaddexp2_bw": [0, 11, 13], "concat_bw": [0, 11, 13], "hardsigmoid_bw": [0, 11, 13], "i0_bw": [0, 11, 13], "hardshrink_bw": [0, 11, 13], "softshrink_bw": [0, 11, 13], "hardswish_bw": [0, 11, 13], "softplus_bw": [0, 11, 13], "polygamma_bw": [0, 11, 13], "atan_bw": [0, 11, 13], "atanh_bw": [0, 11, 13], "asin_bw": [0, 11, 13], "asinh_bw": [0, 11, 13], "cosh_bw": [0, 11, 13], "cos_bw": [0, 11, 13], "acosh_bw": [0, 11, 13], "acos_bw": [0, 11, 13], "erfinv_bw": [0, 11, 13], "leaky_relu_bw": [0, 11, 13], "elu_bw": [0, 11, 13], "hardtanh_bw": [0, 11, 13], "angle_bw": [0, 11, 13], "sin_bw": [0, 11, 13], "sinh_bw": [0, 11, 13], "celu_bw": [0, 11, 13], "binary_lt_bw": [0, 11, 13], "subalpha_bw": [0, 11, 13], "log10_bw": [0, 11, 13], "log1p_bw": [0, 11, 13], "binary_ne_bw": [0, 11, 13], "erf_bw": [0, 11, 13], "erfc_bw": [0, 11, 13], "digamma_bw": [0, 11, 13], "deg2rad_bw": [0, 11, 13], "rad2deg_bw": [0, 11, 13], "reciprocal_bw": [0, 11, 13], "relu6_bw": [0, 11, 13], "rpow_bw": [0, 11, 13], "silu_bw": [0, 11, 13], "selu_bw": [0, 11, 13], "binary_ge_bw": [0, 11, 13], "binary_eq_bw": [0, 11, 13], "binary_gt_bw": [0, 11, 13], "square_bw": [0, 11, 13], "lgamma_bw": [0, 11, 13], "trunc_bw": [0, 11, 13], "frac_bw": [0, 11, 13], "log_sigmoid_bw": [0, 11, 13], "tanhshrink_bw": [0, 11, 13], "threshold_bw": [0, 11, 13], "unary_eq_bw": [0, 11, 13], "logit_bw": [0, 11, 13], "logiteps_bw": [0, 11, 13], "softsign_bw": [0, 11, 13], "sign_bw": [0, 11, 13], "ceil_bw": [0, 11, 13], "log2_bw": [0, 11, 13], "ge_bw": [0, 11, 13], "le_bw": [0, 11, 13], "unary_fmod_bw": [0, 11, 13], "unary_remainder_bw": [0, 11, 13], "complex_recip_bw": [0, 11, 13], "imag_bw": [0, 11, 13], "real_bw": [0, 11, 13], "complex_mul_bw": [0, 11, 13], "complex_div_bw": [0, 11, 13], "polar_bw": [0, 11, 13], "complex_add_bw": [0, 11, 13], "complex_sub_bw": [0, 11, 13], "multigammaln_bw": [0, 11, 13], "repeat_bw": [0, 11, 13], "floor_bw": [0, 11, 13], "round_bw": [0, 11, 13], "unary_div_no_nan_bw": [0, 11, 13], "mseloss": [0, 11, 13], "maeloss": [0, 11, 13], "__init__": [0, 8, 11, 12, 207], "buffer": [0, 11, 12, 13, 17, 18, 209], "get_dtyp": [0, 11, 12], "get_layout": [0, 11, 12], "get_legacy_shap": [0, 10, 11, 12], "pad_to_til": [0, 11, 12], "storage_typ": [0, 11, 12], "unpad_from_til": [0, 11, 12], "memoryconfig": [0, 11, 13, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 133, 134, 135, 137, 138, 139, 142, 143, 144, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 167, 168, 169, 170, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193], "between": [0, 5, 11, 13, 19], "one": [0, 11, 13, 112], "op": [0, 11, 13, 16, 17, 42, 203, 206, 209], "acceler": [0, 11, 12, 13, 203, 206], "odd": [0, 11], "size": [0, 11, 12, 13, 18, 19, 26, 48, 185, 188, 202], "last": [0, 11, 12, 13, 17, 18, 37, 177, 185], "dim": [0, 11, 12, 13, 18, 27, 39, 42, 63, 67, 113, 115, 116, 142, 146, 158, 166, 168, 169, 185, 189, 204, 208], "uplift": 0, "placehold": 0, "titl": 0, "prerequisit": 0, "next": [0, 13, 15, 18, 126], "file": [0, 2, 4, 9, 17, 28, 206, 208, 209], "bug": 0, "propos": [0, 16], "request": [0, 16, 37, 177, 206, 208], "troubleshoot": [0, 9], "tip": 0, "commun": 0, "develop": [0, 4, 14, 16, 17, 206], "index": [0, 12, 13, 17, 84, 85, 184, 206, 208], "search": 0, "page": [0, 14, 15], "If": [1, 2, 12, 13, 14, 15, 16, 17, 19, 27, 42, 112, 119, 120, 130, 158, 179, 185, 209], "you": [1, 2, 3, 4, 5, 9, 10, 12, 13, 14, 15, 17, 159, 194, 208, 209, 210], "would": [1, 13, 15, 16, 17, 18], "like": [1, 8, 10, 13, 15, 18, 159, 202, 209], "thi": [1, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 16, 17, 18, 66, 112, 159, 184, 194, 202, 203, 204, 208, 209], "project": [1, 2, 4, 14], "pleas": [1, 2, 9, 13, 14, 15, 16, 209], "review": [1, 14, 16], "standard": [1, 2, 9, 13, 14], "need": [1, 2, 6, 9, 10, 13, 15, 17, 18, 202, 203, 204, 209], "gain": 1, "access": [1, 2, 208], "repositori": 1, "read": [1, 13, 14, 18, 42], "section": [1, 2, 9, 13, 18], "detail": [1, 14, 208, 209], "contact": 1, "u": [1, 15, 16], "have": [2, 3, 4, 9, 12, 13, 15, 17, 18, 27, 42, 194, 202, 208], "formal": 2, "permiss": 2, "cloud": 2, "issu": [2, 9, 16, 17, 159, 202, 203, 204, 205, 206, 207], "can": [2, 3, 4, 5, 8, 10, 12, 13, 14, 17, 18, 112, 140, 141, 159, 194, 202, 203, 204, 208, 209], "out": [2, 13, 15, 179, 202, 204, 207], "relev": [2, 9], "ever": 2, "hardwar": [2, 5, 6, 8, 9, 14, 18, 202, 209], "help": [2, 5, 16, 194], "we": [2, 3, 4, 5, 6, 9, 10, 13, 15, 16, 18, 112, 202, 203, 208, 209], "offici": 2, "discord": 2, "channel": [2, 13, 17, 19, 66, 188], "repres": [2, 12, 13, 17, 18, 202], "both": [2, 8, 9, 12, 13, 17, 18, 19, 112, 202, 207], "tenstorr": [2, 5, 6, 8, 9, 14, 15, 194, 202, 203, 208, 209], "metal": [2, 5, 12, 14, 15, 194, 202, 203, 204, 205, 206, 207, 208], "join": [2, 206], "discuss": [2, 9], "board": [2, 15], "bounc": 2, "idea": [2, 9], "off": [2, 8, 13], "each": [2, 3, 5, 12, 13, 17, 18, 66, 131, 145, 146], "refer": [2, 3, 4, 5, 12, 13, 16, 18, 209], "code": [2, 10, 13, 14, 15, 16, 17, 27, 140, 141, 185, 202, 206, 209], "conduct": 2, "when": [2, 9, 12, 13, 16, 18, 37, 42, 112, 119, 177, 184, 190, 202, 204, 207, 209], "interact": 2, "ensur": [3, 4, 9], "tt": [3, 4, 5, 6, 11, 24, 25, 32, 35, 36, 63, 67, 71, 76, 86, 91, 106, 107, 110, 114, 117, 121, 133, 135, 142, 160, 169, 175, 191, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208], "environ": [3, 4, 13, 14, 15, 206, 208, 209], "requir": [3, 6, 9, 12, 13, 15, 17, 42, 119, 120, 206, 208], "model": [3, 5, 9, 15, 16, 17, 119, 120, 194, 195, 197, 201, 206, 207], "ar": [3, 4, 6, 8, 9, 10, 12, 13, 14, 15, 17, 18, 112, 140, 141, 185, 188, 194, 202, 203, 204, 209], "follow": [3, 6, 8, 10, 12, 13, 14, 15, 16, 17, 18, 112, 140, 141, 194, 208, 209], "instruct": [3, 4, 9, 14, 15, 194, 209], "readi": [3, 4, 9, 185], "come": [3, 14, 17], "typic": [3, 18, 66], "found": [3, 8, 194, 206, 208], "under": [3, 4, 9, 10, 16, 17, 194, 209], "your_model": 3, "perf_model": 3, "py": [3, 6, 8, 9, 15, 17, 206, 209], "To": [3, 10, 13, 16, 202, 203, 209], "pytest": [3, 4, 6, 8, 9, 17, 206, 209], "python_api_test": 3, "perf_your_model": 3, "csv": [3, 6, 17, 206, 209], "perf_your_model_d": 3, "contain": [3, 4, 12, 13, 18, 48, 202], "tabl": [3, 6, 13, 206], "two": [3, 8, 12, 13, 18, 37, 112, 177, 185], "row": [3, 12, 13, 17, 18, 202, 203, 206], "set": [3, 4, 8, 10, 12, 13, 15, 17, 183, 185, 190, 194, 202, 206, 208, 209], "batch": [3, 12, 13, 17, 94, 112], "sec": 3, "second": [3, 12, 13, 15, 17, 94, 112, 131, 204, 206, 209], "compil": [3, 13, 203, 206, 209], "time": [3, 9, 13, 17, 112, 119, 123, 145, 203, 204, 206, 209], "infer": [3, 9, 17, 206], "g": [3, 13, 17], "throughput": 3, "inf": [3, 13], "vit": 3, "patch16": 3, "30": [3, 206], "51": [3, 204], "16": [3, 15, 18, 202, 203, 204, 206, 208], "05": [3, 13, 78, 208], "46": [3, 202, 203, 206, 207], "0": [3, 6, 8, 10, 12, 13, 15, 17, 18, 19, 28, 39, 59, 132, 179, 185, 202, 203, 204, 205, 206, 207, 208, 209], "0623": 3, "29": [3, 203, 206], "4960": 3, "includ": [3, 6, 9], "without": [3, 10, 12, 13], "ani": [3, 5, 9, 10, 13, 206], "abovement": 3, "grayskul": [3, 6, 8, 14, 15, 194, 195, 196, 197, 198, 199, 200, 201, 209], "It": [3, 12, 13, 119, 120, 202], "sinc": [3, 10], "dure": 3, "do": [3, 6, 9, 10, 15, 204], "pai": 3, "name": [3, 8, 12, 13, 16, 17, 28, 119, 120, 206, 208, 209], "suggest": 3, "calcul": [3, 13, 17, 42], "comput": [3, 5, 13, 17, 66, 68, 87, 88, 94, 101, 102, 103, 105, 112, 148, 158, 165, 181, 182, 185, 202, 203], "": [3, 4, 5, 9, 12, 13, 18, 119, 120, 202, 203, 204, 208], "also": [3, 9, 10, 12, 13, 14, 15, 17, 37, 208], "maintain": [3, 16], "script": [3, 4, 9, 15, 17, 206], "run_perform": [3, 9], "sh": [3, 4, 9, 15, 17, 206], "facilit": 3, "easi": [3, 202], "wai": [3, 5, 8, 13, 119, 120, 202], "attempt": [3, 13, 206], "fastest": 3, "command": [3, 13, 17, 23, 27, 50, 62, 69, 88, 89, 101, 102, 103, 105, 108, 123, 124, 165, 167, 209], "execut": [3, 9, 10, 13, 17, 140, 141, 203, 204, 206, 209], "merg": [3, 16], "built": [4, 15, 206, 208], "now": [4, 14, 15, 18, 188, 202, 204], "root": [4, 13, 181, 182], "provid": [4, 5, 9, 12, 13, 15, 16, 17, 18, 27, 119, 120, 158, 202, 204, 209], "virtual": [4, 15], "which": [4, 5, 8, 12, 13, 17, 18, 42, 94, 112, 119, 120, 158], "ll": 4, "work": [4, 8, 9, 14, 194, 195, 196, 197, 198, 199, 200, 201, 209], "python_env": [4, 15, 206, 208], "bin": [4, 15, 206], "python_env_dir": 4, "variabl": [4, 13, 15, 209], "create_venv": [4, 15], "control": [4, 13, 19, 202], "pythonpath": [4, 15, 208], "common": [4, 9, 13, 15], "practic": 4, "export": [4, 13, 15, 209], "pwd": [4, 15], "folder": [4, 9, 14, 17, 206], "split": [4, 13, 18, 185], "them": [4, 13, 17, 185, 202], "sub": [4, 5, 13], "In": [4, 6, 8, 10, 13, 17, 18, 37, 112, 177, 182, 202, 208], "find": [4, 15, 202, 203, 204, 205, 206, 207], "prepar": [4, 9, 206], "readm": [4, 9, 206, 208], "md": [4, 9, 15], "give": [4, 13, 17], "how": [4, 9, 12, 13, 17, 18, 203, 204, 209], "progress": [4, 208], "yet": 4, "user": [4, 5, 9, 13, 14, 16, 119, 120, 202, 203, 204, 205, 206, 207, 208, 209], "mani": [4, 8, 203, 208], "part": [4, 9, 13, 17, 204], "entir": [4, 13, 66], "path_to_test_fil": 4, "test_in_fil": 4, "ttnn": [4, 7, 12, 16, 18, 194, 197, 199, 200, 203, 208], "friendli": [4, 5, 14], "top": [4, 12, 194], "doc": [4, 6, 15, 206], "document": [4, 6, 9, 15, 16, 206], "interfac": [5, 13], "design": 5, "intuit": [5, 202], "familiar": [5, 15], "trust": 5, "valuabl": 5, "your": [5, 9, 10, 13, 15, 17, 194], "journei": 5, "take": [5, 6, 9, 12, 13, 14, 18, 19, 140, 141, 183, 202], "advantag": 5, "n": [5, 13, 15, 17, 112, 188, 202, 203, 206, 208], "d": [5, 206], "row_major_layout": [5, 18, 28, 37, 48, 59, 177, 202, 203, 204], "tile_layout": [5, 8, 18, 37, 146, 177, 202, 203, 204, 209], "stabl": [5, 13], "The": [5, 8, 9, 10, 12, 13, 14, 16, 17, 18, 47, 48, 66, 75, 84, 85, 90, 112, 140, 141, 145, 146, 188, 202, 203, 208, 209], "networkx": [5, 206, 208], "compat": [5, 15], "some": [5, 6, 13, 209], "nn": [5, 6, 8, 12, 119, 120, 194, 195, 196, 197, 198, 199, 200, 201, 207], "object": [5, 8, 12, 13, 16, 42, 207, 208], "could": [5, 202, 203, 204, 205, 206, 207], "significantli": [5, 203], "speed": [5, 203], "up": [5, 13, 15, 17, 194, 203, 208], "abil": [5, 13], "compar": [5, 13, 50, 62, 69, 108, 124, 203], "equival": [5, 13, 18, 27, 185], "veri": [5, 17, 159, 202, 204], "meant": 6, "contributor": 6, "Not": [6, 8, 209], "mai": [6, 8, 13, 15, 209], "wormhol": [6, 8, 15, 194, 209], "tt_eager": [6, 13, 206], "tt_dnn": 6, "op_librari": 6, "new_oper": 6, "hpp": [6, 204], "pragma": 6, "onc": [6, 203], "namespac": [6, 208], "tt_metal": [6, 12, 13, 15, 17, 24, 25, 32, 35, 36, 63, 67, 71, 76, 86, 91, 106, 107, 110, 114, 117, 121, 133, 135, 142, 160, 169, 175, 191, 203, 206], "struct": [6, 13], "newoper": [6, 13], "bool": [6, 13, 19, 42, 43, 47, 52, 53, 55, 58, 64, 75, 78, 90, 94, 112, 113, 115, 116, 119, 120, 149, 166, 168, 181, 182, 189], "some_arg": 6, "These": [6, 9, 10, 13, 15, 194, 209], "method": [6, 13, 15, 18, 206], "produc": [6, 10, 13, 202, 203], "void": [6, 13], "valid": [6, 8, 9, 12, 13, 17, 112, 119, 120, 206], "const": [6, 13], "vector": [6, 12, 13, 112], "input_tensor": [6, 13, 20, 21, 22, 24, 25, 27, 29, 30, 31, 33, 34, 35, 36, 39, 40, 41, 44, 45, 47, 48, 51, 52, 53, 54, 55, 56, 57, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 77, 79, 80, 81, 82, 83, 87, 90, 92, 93, 96, 97, 98, 99, 100, 107, 109, 113, 115, 116, 118, 122, 125, 127, 131, 132, 133, 135, 137, 138, 139, 142, 143, 144, 145, 146, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 166, 168, 169, 170, 172, 173, 174, 175, 181, 182, 183, 184, 185, 186, 187, 188, 189, 205, 207, 209], "compute_output_shap": [6, 13], "create_output_tensor": [6, 13], "programwithcallback": [6, 13], "create_program": [6, 13], "output_tensor": [6, 13, 23, 27, 50, 62, 69, 88, 89, 101, 102, 103, 105, 108, 123, 124, 165, 167, 202, 207, 209], "20": [6, 13, 15, 17, 159, 203, 206, 208], "static": [6, 13], "constexpr": [6, 13], "auto": [6, 13], "attribute_nam": [6, 13], "forward_as_tupl": [6, 13], "attribute_valu": [6, 13], "return": [6, 8, 10, 12, 13, 23, 26, 27, 37, 50, 62, 66, 69, 88, 89, 94, 101, 102, 103, 105, 108, 112, 123, 124, 126, 130, 134, 138, 140, 141, 145, 165, 167, 177, 183, 185, 204, 205, 206, 207, 208], "cpp": [6, 204], "host_api": 6, "run_oper": 6, "output_shap": 6, "deviceoper": 6, "csrc": 6, "tt_lib_bindings_tensor": 6, "line": [6, 206], "m_tensor": 6, "def": [6, 8, 204, 205, 206, 207, 208, 209], "arg": [6, 12, 13, 20, 21, 22, 23, 26, 27, 28, 29, 30, 31, 33, 34, 37, 39, 40, 41, 42, 44, 45, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 59, 62, 64, 65, 66, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 89, 90, 92, 93, 96, 97, 98, 99, 100, 101, 102, 103, 105, 108, 109, 118, 119, 120, 122, 123, 124, 125, 126, 127, 131, 132, 134, 136, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 163, 164, 165, 167, 170, 172, 173, 174, 176, 177, 178, 179, 181, 182, 183, 184, 185, 186, 187, 188, 190, 209], "noconvert": 6, "r": [6, 13, 15, 206], "argument": [6, 12, 13, 19, 94, 112, 140, 141, 202], "rang": [6, 12, 13], "w0": [6, 13], "z0": [6, 13], "y0": [6, 13], "x0": [6, 13], "ye": [6, 12, 13], "stuff": 6, "unit_test": 6, "ttl": [6, 12, 17], "test_": 6, "import": [6, 8, 9, 10, 17, 202, 203, 204, 205, 206, 207, 208, 209], "utils_for_test": [6, 8], "assert_with_pcc": [6, 8], "mark": [6, 8, 9], "parametr": [6, 8], "height": [6, 13, 17, 18, 37, 42, 66, 112, 177], "32": [6, 10, 12, 13, 18, 37, 39, 66, 94, 112, 132, 146, 158, 177, 178, 202, 203, 205, 206, 209], "width": [6, 13, 17, 37, 42, 66, 112, 177, 183], "manual_se": [6, 8, 202, 203, 204, 207, 208], "torch_input_tensor": [6, 146, 207, 209], "rand": [6, 48, 146, 202, 205, 207, 209], "torch_output_tensor": [6, 209], "sweep_test": 6, "ttl_": 6, "tupl": [6, 13, 19, 42, 113, 115, 116, 131, 166, 168, 185, 188, 189], "check_with_pcc": 6, "384": [6, 8, 204, 205], "1024": [6, 203], "4096": [6, 12], "str": [6, 12, 13, 23, 28, 46, 50, 62, 69, 86, 88, 89, 94, 95, 101, 102, 103, 105, 108, 112, 119, 120, 121, 123, 124, 150, 165, 167, 208], "particular": [8, 13, 15, 202, 209], "onli": [8, 9, 12, 13, 14, 17, 18, 42, 112, 185, 194, 195, 196, 197, 198, 199, 200, 201, 207, 209], "case": [8, 9, 13, 18, 37, 177, 202, 209], "basi": 8, "There": [8, 12, 13, 18], "recommend": [8, 202], "approach": [8, 16, 159], "re": [8, 13, 14, 203], "given": [8, 12, 13, 17, 27, 37, 39, 119, 120, 130, 146, 188, 202, 204], "rewritten": 8, "For": [8, 9, 12, 13, 15, 16, 17, 18, 112, 185], "bert": [8, 14, 205, 206], "modeling_bert": [8, 205], "bertintermedi": 8, "class": [8, 9, 12, 13, 17, 18, 19, 110, 206, 207, 208], "self": [8, 12, 13, 18, 207], "super": [8, 207], "dens": 8, "hidden_s": [8, 185, 204, 205], "intermediate_s": 8, "forward": [8, 13, 207], "hidden_st": [8, 204, 205], "tdd": 8, "torch_bert": 8, "utility_funct": 8, "torch_random": 8, "model_nam": [8, 119, 120, 205, 206], "phiyodr": [8, 205], "larg": [8, 159, 205], "finetun": [8, 205], "squad2": [8, 205], "batch_siz": [8, 13, 19, 66, 183, 185, 204, 205, 206], "sequence_s": [8, 183, 185, 204, 205, 206], "test_bert_intermedi": 8, "bertconfig": [8, 205], "from_pretrain": [8, 205, 208], "eval": [8, 205, 206, 207, 208], "torch_hidden_st": [8, 204], "dtype": [8, 12, 13, 18, 19, 20, 21, 22, 23, 27, 28, 29, 30, 31, 33, 34, 37, 39, 40, 41, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 87, 88, 89, 90, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 105, 108, 109, 112, 113, 115, 116, 118, 122, 123, 124, 125, 126, 127, 128, 129, 132, 134, 137, 139, 143, 144, 145, 146, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 163, 164, 165, 166, 167, 168, 170, 172, 173, 174, 177, 178, 179, 181, 182, 183, 184, 186, 187, 188, 189, 192, 193, 202, 203, 204, 205, 207, 209], "float32": [8, 12, 17, 18, 177, 178, 202, 207, 209], "torch_output": [8, 204], "golden": [8, 209], "initialize_model": [8, 119, 120, 205, 207], "lambda": [8, 13, 205, 207], "convert_to_ttnn": [8, 119, 120], "_": [8, 17, 204, 208], "fals": [8, 13, 19, 20, 21, 23, 27, 29, 31, 40, 42, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 62, 64, 65, 66, 68, 69, 70, 75, 77, 78, 79, 80, 81, 82, 83, 87, 88, 89, 90, 92, 96, 97, 99, 100, 101, 102, 103, 105, 108, 109, 113, 115, 116, 123, 124, 125, 127, 139, 143, 144, 145, 146, 148, 149, 151, 153, 154, 155, 156, 158, 159, 163, 164, 165, 166, 167, 168, 172, 173, 177, 178, 181, 182, 183, 184, 188, 189, 190, 204, 206, 207, 208, 209], "keep": [8, 18], "bert_intermedi": 8, "9999": [8, 204, 209], "And": [8, 12, 13, 18, 202, 203], "final": [8, 9, 10, 16, 112, 202], "make": [8, 18, 119, 120, 159, 185, 206, 209], "bia": [8, 13, 68, 87, 94, 204, 207], "dictionari": 8, "its": [8, 9, 12, 13, 15, 16, 17, 18, 112, 209], "so": [8, 10, 12, 13, 202, 208], "structur": 8, "ha": [8, 9, 10, 12, 13, 17, 18, 119, 120, 185, 188, 202, 208, 209], "singl": [8, 16, 17, 18, 202], "turn": 8, "ttnn_bert": [8, 205], "put": [8, 119, 120, 202, 204, 207], "bfloat16": [8, 10, 12, 13, 17, 18, 20, 21, 22, 23, 27, 28, 29, 30, 31, 33, 34, 37, 39, 40, 41, 44, 45, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 59, 62, 64, 65, 66, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 87, 88, 89, 90, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 105, 108, 109, 112, 113, 115, 116, 118, 122, 123, 124, 125, 127, 132, 137, 139, 143, 144, 145, 146, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 163, 164, 165, 166, 167, 168, 170, 172, 173, 174, 177, 178, 179, 181, 182, 183, 184, 186, 187, 188, 189, 202, 203, 204, 206, 207, 209], "999": 8, "Then": [8, 185], "custom_preprocessor": [8, 119, 120, 205], "bfloat8_b": [8, 12, 13, 17, 18, 20, 21, 23, 29, 31, 37, 40, 47, 50, 51, 52, 53, 54, 55, 56, 57, 62, 64, 65, 66, 69, 70, 75, 77, 79, 80, 81, 82, 83, 87, 88, 89, 90, 92, 96, 97, 99, 100, 101, 102, 103, 105, 108, 109, 113, 115, 116, 123, 124, 125, 127, 139, 143, 144, 145, 148, 149, 151, 153, 154, 155, 156, 158, 159, 163, 164, 165, 166, 167, 168, 172, 173, 177, 178, 181, 182, 183, 184, 188, 189, 204], "bias": [8, 13, 204], "someth": 8, "ttnn_optimized_bert": [8, 205], "isinst": 8, "preprocess_linear_weight": [8, 204], "preprocess_linear_bia": [8, 204], "num_cores_x": [8, 204], "ff1_weight": 8, "ff1_bia": 8, "memory_config": [8, 12, 13, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 133, 134, 135, 137, 138, 139, 142, 143, 144, 145, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 167, 168, 169, 170, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193, 203, 204, 207, 209], "l1_memory_config": [8, 18, 37, 203, 204, 209], "local": [8, 9, 18], "core_grid": [8, 42, 94, 112, 203, 204], "specifi": [8, 12, 13, 26, 119, 120, 131, 145, 203, 204], "manual": [8, 209], "grid": [8, 18, 94, 112], "best": [8, 202], "possibl": [8, 13, 179], "true": [8, 12, 13, 20, 21, 23, 27, 29, 31, 40, 42, 43, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 62, 64, 65, 66, 68, 69, 70, 75, 77, 79, 80, 81, 82, 83, 87, 88, 89, 90, 92, 96, 97, 99, 100, 101, 102, 103, 105, 108, 109, 113, 115, 116, 123, 124, 125, 127, 139, 143, 144, 145, 146, 148, 149, 151, 153, 154, 155, 156, 158, 159, 163, 164, 165, 166, 167, 168, 172, 173, 177, 178, 181, 182, 183, 184, 188, 189, 190, 206, 207, 208, 209], "addit": [8, 13, 15], "integr": [8, 9, 10, 13], "incredibli": 9, "excit": 9, "exploratori": 9, "done": [9, 12, 13, 17, 202, 206], "allow": [9, 12, 13, 16], "freedom": 9, "try": [9, 15, 202, 206], "improv": [9, 159], "showcas": 9, "few": [9, 18, 202], "question": 9, "answer": 9, "befor": [9, 13, 18, 28, 131, 141, 159], "move": [9, 10, 12, 13, 202, 204, 205, 206, 207], "see": [9, 13, 16, 202, 206, 208], "below": [9, 13, 17, 18], "highlight": [9, 18], "expect": [9, 12, 13, 16, 112, 185, 202], "successfulli": [9, 194, 206, 208], "migrat": [9, 209], "doe": [9, 13, 17, 37], "good": 9, "documen": 9, "within": [9, 12, 13, 18, 194], "describ": [9, 13], "should": [9, 12, 13, 14, 16, 17, 131, 177, 204], "credit": 9, "author": 9, "appropri": 9, "necessari": 9, "A": [9, 10, 12, 13, 15, 16, 18, 112, 159], "error": [9, 13, 179], "might": [9, 13, 203], "encount": 9, "demonstr": [9, 17], "adequ": 9, "achiev": [9, 16], "accept": [9, 16], "pearson": 9, "correl": [9, 13], "coeffici": [9, 13, 134], "pcc": [9, 16], "been": [9, 119, 120, 208], "ci": 9, "pipelin": [9, 17], "metric": 9, "specif": [9, 13, 15, 18, 206], "meet": 9, "accuraci": [9, 13], "continu": [9, 16], "automat": [9, 10, 13, 17, 18, 37, 94, 112, 177, 202, 203], "against": [9, 209], "upon": 9, "everi": [9, 12, 17, 204, 209], "commit": [9, 206], "ongo": 9, "complianc": 9, "catch": 9, "regress": 9, "earli": 9, "end": [9, 12, 13, 17, 26, 204, 206], "collect": [9, 17, 194, 206], "limit": [9, 13], "usag": 9, "varieti": [9, 13], "condit": [9, 13, 190], "measur": 9, "updat": [9, 15, 16, 85, 209], "special": [9, 13, 18], "run_device_perf_model": 9, "annot": 9, "models_device_performance_bare_met": 9, "schedul": 9, "appli": [9, 13, 19, 20, 21, 22, 23, 29, 30, 31, 33, 34, 40, 41, 44, 45, 47, 50, 51, 52, 53, 54, 55, 56, 57, 62, 64, 65, 66, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 88, 89, 90, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 105, 108, 109, 112, 118, 122, 123, 124, 125, 127, 131, 137, 139, 143, 144, 145, 146, 149, 151, 152, 153, 154, 155, 156, 157, 159, 161, 163, 164, 165, 167, 170, 172, 173, 174, 184, 186, 187], "clear": [9, 16, 204, 206], "incorpor": 9, "autom": 9, "extern": [9, 16, 18], "servic": 9, "thei": [9, 13, 203, 204], "impact": 9, "either": [9, 13, 15, 18, 37, 42, 112, 177, 194], "run_perf_models_oth": 9, "run_perf_models_llm_javelin": 9, "run_perf_models_cnn_javelin": 9, "models_performance_bare_met": 9, "purpos": [9, 16, 18, 112], "organ": [9, 18, 37, 177], "manag": [9, 15, 111, 140, 141], "look": [9, 14, 18, 112, 206, 208], "test_ttnn_functional_resnet50": 9, "resnet50testinfra": 9, "wa": [9, 17, 18, 202, 208], "setup": [9, 14, 15, 206, 208], "handl": [10, 202], "machin": [10, 12, 13, 17, 194, 208], "send": [10, 12, 13], "print": [10, 12, 13, 17, 18, 28, 39, 59, 94, 112, 132, 145, 146, 158, 177, 179, 202, 203, 204, 206, 208, 209], "__name__": 10, "__main__": [10, 206], "pci": [10, 202, 203, 204, 205, 206, 207], "slot": 10, "tt_devic": [10, 12, 13], "createdevic": [10, 12], "py_tensor": [10, 12], "randn": [10, 12, 28, 59, 66, 94, 112, 177, 178, 179, 203, 204, 208], "tt_tensor": [10, 12, 13], "tolist": [10, 12], "datatyp": [10, 12, 13, 19, 20, 21, 23, 27, 28, 29, 31, 37, 40, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 75, 77, 79, 80, 81, 82, 83, 87, 88, 89, 90, 92, 94, 96, 97, 99, 100, 101, 102, 103, 105, 108, 109, 112, 113, 115, 116, 123, 124, 125, 126, 127, 128, 129, 134, 139, 143, 144, 145, 146, 148, 149, 151, 153, 154, 155, 156, 158, 159, 163, 164, 165, 166, 167, 168, 172, 173, 177, 178, 181, 182, 183, 184, 188, 189, 192, 193, 202], "row_major": [10, 12, 13, 17, 20, 21, 27, 29, 31, 40, 42, 47, 48, 51, 52, 53, 54, 55, 56, 57, 64, 65, 68, 70, 75, 77, 79, 80, 81, 82, 83, 87, 90, 92, 96, 97, 99, 100, 109, 125, 127, 139, 143, 144, 145, 148, 149, 151, 153, 154, 155, 156, 159, 163, 164, 172, 173, 177, 178, 188, 202], "tt_relu_out": 10, "tt_output": [10, 12], "closedevic": 10, "previou": 10, "after": [10, 13, 16, 17, 112, 126, 131, 140, 202, 209], "expon": [10, 13], "back": [10, 17, 183, 202, 204], "power": [10, 13], "scalar": [10, 13], "power_fp": 10, "float": [10, 12, 13, 23, 24, 25, 32, 35, 36, 50, 60, 61, 62, 68, 69, 71, 76, 78, 87, 88, 89, 91, 101, 102, 103, 105, 106, 107, 108, 110, 114, 117, 123, 124, 126, 131, 133, 134, 135, 148, 159, 160, 165, 167, 175, 191], "point": [10, 13, 17, 19, 126, 159], "posit": [10, 13], "actual": [10, 13, 18, 202], "But": 10, "suppli": [10, 12, 13], "lastli": 10, "fallback_op": [10, 13], "py_tensor_exp": 10, "randint": [10, 205], "py_relu_out": 10, "avail": [10, 12, 13, 188, 194, 209], "py_pow_out": 10, "tt_pow_out": 10, "behav": [10, 13], "regular": 10, "even": [10, 13, 112], "though": [10, 112], "hood": 10, "tt_silu_out": 10, "tt_exp_out": 10, "t": [10, 12, 13, 15, 17, 119, 120, 202, 204, 206], "dimens": [10, 12, 13, 18, 27, 37, 39, 66, 112, 132, 146, 158, 177, 179, 183, 185], "must": [10, 12, 13, 15, 18, 27, 112, 140, 141, 210], "call": [10, 12, 13, 16, 17, 18, 131, 140, 141, 202, 204, 206, 209], "setdefaultdevic": [10, 13], "default": [10, 12, 13, 17, 19, 42, 48, 94, 112, 119, 120, 181, 182, 203, 209], "want": [10, 13, 15, 203, 209], "modifi": [10, 13, 159, 202], "31": [10, 12, 13, 206, 208], "leav": 10, "note": [10, 12, 13, 15, 17, 18, 37, 112, 202, 204, 208, 209], "anyth": 10, "alreadi": [10, 119, 120, 130, 194, 206, 208], "manipul": [12, 13], "sent": 12, "receiv": [12, 17], "platform": [12, 14, 206], "ttdnn": 12, "util": [12, 202, 203, 208], "differ": [12, 13, 18, 112, 165, 202, 209], "store": [12, 13, 17, 18, 202], "w": [12, 13, 17, 188], "z": [12, 13, 17, 208], "y": [12, 13, 15, 17, 18, 190, 203, 204, 208], "x": [12, 13, 15, 17, 18, 94, 112, 190, 203, 204, 207, 208], "order": [12, 13, 15, 17, 18, 42, 112, 132, 194, 202, 204, 209], "divis": [12, 13, 18], "exist": [12, 130, 206, 208], "construct": [12, 209], "nor": 12, "tile": [12, 13, 17, 18, 20, 21, 23, 29, 31, 40, 47, 50, 51, 52, 53, 54, 55, 56, 57, 62, 64, 65, 66, 68, 69, 70, 75, 77, 79, 80, 81, 82, 83, 87, 88, 89, 90, 92, 96, 97, 99, 100, 101, 102, 103, 105, 108, 109, 113, 115, 116, 123, 124, 125, 127, 139, 143, 144, 145, 146, 148, 149, 151, 153, 154, 155, 156, 158, 159, 163, 164, 165, 166, 167, 168, 172, 173, 177, 178, 181, 182, 183, 184, 188, 189, 202, 203, 206], "subsect": 12, "major": [12, 13, 18, 202, 203], "insid": [12, 209], "64": [12, 13, 18, 37, 39, 42, 94, 112, 132, 158, 177, 178, 204, 205, 206, 207, 209], "63": [12, 206], "65": [12, 206, 208], "66": 12, "127": [12, 206], "3968": 12, "3969": 12, "3970": 12, "4031": 12, "4032": 12, "4033": 12, "4034": 12, "4095": 12, "4097": 12, "4098": 12, "4159": 12, "4160": 12, "4161": 12, "6462": 12, "4223": 12, "8064": 12, "8065": 12, "8066": 12, "8127": 12, "8128": 12, "8129": 12, "8130": 12, "8191": 12, "95": 12, "1984": 12, "1985": 12, "2015": [12, 206], "33": [12, 203, 206], "96": [12, 206, 209], "97": [12, 206], "2016": 12, "2017": [12, 206, 208], "2047": 12, "2080": 12, "2081": 12, "2111": 12, "2144": 12, "2145": 12, "2175": 12, "4064": 12, "4065": 12, "fourth": [12, 13], "6111": 12, "6176": 12, "ownedstorag": [12, 13], "borrowedstorag": 12, "devicestorag": [12, 13], "dram": [12, 13, 18, 24, 25, 32, 35, 36, 63, 67, 71, 76, 86, 91, 106, 107, 110, 114, 117, 121, 133, 135, 142, 160, 169, 175, 178, 191, 202], "correspond": [12, 13, 48], "itself": 12, "share": 12, "pointer": 12, "That": [12, 18, 203], "underli": 12, "simpli": [12, 13, 37, 177, 202], "count": [12, 13, 17, 206], "well": [12, 16], "numpi": [12, 18, 206, 208], "etc": [12, 15], "l1": [12, 18, 42, 94, 112, 178, 204], "reason": 12, "list": [12, 13, 23, 39, 42, 48, 50, 62, 69, 88, 89, 101, 102, 103, 105, 108, 123, 124, 132, 134, 147, 165, 167], "int": [12, 13, 19, 23, 26, 27, 32, 39, 42, 48, 50, 60, 61, 62, 63, 67, 68, 69, 76, 84, 85, 88, 89, 91, 101, 102, 103, 105, 106, 108, 111, 113, 114, 115, 116, 117, 123, 124, 130, 131, 132, 142, 146, 147, 158, 165, 166, 167, 168, 169, 179, 181, 182, 184, 185, 189, 191, 207, 208], "data_typ": [12, 13, 204], "number": [12, 13, 16, 17, 18, 19, 23, 50, 62, 69, 88, 89, 101, 102, 103, 105, 108, 123, 124, 131, 145, 146, 165, 167, 181, 182, 204, 208], "uint32": [12, 13, 17, 18, 27, 48, 66, 145, 177, 178, 202], "bfloat4_b": [12, 13, 23, 50, 62, 69, 87, 88, 89, 101, 102, 103, 105, 108, 123, 124, 148, 165, 167, 177, 178], "No": [12, 13], "mem_config": [12, 178], "bank": [12, 13], "kwarg": [12, 13, 136, 140, 141, 147, 176, 209], "overload": [12, 13, 147, 176, 202], "arg0": [12, 13], "none": [12, 13, 19, 20, 21, 22, 23, 27, 28, 29, 30, 31, 33, 34, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 72, 73, 74, 75, 77, 79, 80, 81, 82, 83, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 108, 109, 112, 113, 115, 116, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 134, 137, 138, 139, 140, 141, 143, 144, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 163, 164, 165, 166, 167, 168, 170, 171, 172, 173, 174, 176, 177, 178, 179, 181, 182, 183, 184, 185, 186, 187, 189, 190, 192, 193, 204, 205, 206, 207], "arg1": [12, 13], "arg2": [12, 13], "arg3": [12, 13], "arg4": [12, 13], "divisbl": [12, 13], "arg5": [12, 13], "tensormemorylayout": [12, 13, 24, 25, 32, 35, 36, 63, 67, 71, 76, 86, 91, 106, 107, 110, 114, 117, 121, 133, 135, 142, 160, 169, 175, 191], "single_bank": 12, "strategi": [12, 13, 17, 18, 42, 112, 206], "dict": [12, 19, 46, 119, 120, 208], "ptr": 12, "np": 12, "owned_buffer_for_uint16_t": 12, "owned_buffer_for_int32_t": 12, "owned_buffer_for_uint32_t": 12, "owned_buffer_for_float32_t": 12, "owned_buffer_for_bfloat16_t": 12, "borrowed_buffer_for_uint16_t": 12, "borrowed_buffer_for_int32_t": 12, "borrowed_buffer_for_uint32_t": 12, "borrowed_buffer_for_float32_t": 12, "borrowed_buffer_for_bfloat16_t": 12, "indic": [12, 13, 27, 48], "everywher": [12, 13], "els": [12, 13, 205, 207, 208], "place": [12, 13, 18, 84, 85, 182], "along": [12, 13, 15, 18, 158, 183], "output_tensor_shap": [12, 13], "input_tensor_shap": [12, 13], "input_tensor_start": [12, 13], "pad_valu": [12, 13], "inp": 12, "tt_tensor_pad": 12, "npad": 12, "right": [12, 13], "bottom": [12, 194], "storagetyp": 12, "memory_layout": [12, 13, 24, 25, 32, 35, 36, 63, 67, 71, 76, 86, 91, 106, 107, 110, 114, 117, 121, 133, 135, 142, 160, 169, 175, 191], "interleav": [12, 13, 18, 24, 25, 32, 35, 36, 63, 67, 71, 76, 86, 91, 106, 107, 110, 114, 117, 121, 133, 135, 142, 146, 160, 169, 175, 178, 185, 191], "buffer_typ": [12, 13, 24, 25, 32, 35, 36, 63, 67, 71, 76, 86, 91, 106, 107, 110, 114, 117, 121, 133, 135, 142, 160, 169, 175, 191], "buffertyp": [12, 13, 24, 25, 32, 35, 36, 63, 67, 71, 76, 86, 91, 106, 107, 110, 114, 117, 121, 133, 135, 142, 160, 169, 175, 191], "shard_spec": [12, 13, 24, 25, 32, 35, 36, 63, 67, 71, 76, 86, 91, 106, 107, 110, 114, 117, 121, 133, 135, 142, 160, 169, 175, 191], "nullopt": [12, 13, 24, 25, 27, 32, 35, 36, 63, 67, 71, 76, 86, 91, 106, 107, 110, 114, 117, 121, 133, 135, 142, 160, 169, 175, 191], "device_mesh": 12, "multi_devic": [12, 176], "devicemesh": [12, 176, 177], "target_layout": [12, 13], "worker": [12, 177], "target": [12, 13], "thread": [12, 177, 206, 209], "ti": 12, "inclus": [12, 13, 18], "output_tensor_end": [12, 13], "output_tensor_start": [12, 13], "tt_tensor_unpad": 12, "nunpad": 12, "align": [12, 13, 17], "left": [12, 13, 16], "remov": [12, 13, 38, 112, 179, 202, 206, 208], "apart": 12, "restrict": 12, "defin": [12, 13, 16, 18, 28], "eight": 12, "shardspec": 12, "across": [12, 13, 17, 18, 66], "otherwis": [12, 13, 204, 209], "select": [12, 13, 16, 190], "dram_channel": 12, "rememb": 12, "show": [12, 18, 203, 204], "py_output": 12, "unifi": 13, "locat": [13, 14, 17, 206, 209], "current": [13, 14, 15, 18, 42, 112, 119, 120, 194, 195, 196, 197, 198, 199, 200, 201, 202, 209], "dimension": [13, 18, 112, 202], "better": 13, "kernel": [13, 15, 17, 19, 94, 112, 203], "caller": 13, "howev": [13, 15, 202], "launch": [13, 194], "gener": [13, 15, 17, 202, 204, 206, 209, 210], "plug": 13, "declar": 13, "some_memb": 13, "cref": 13, "optional_input_tensor": 13, "leverag": [13, 112], "instead": [13, 28, 202, 204, 208], "validate_with_output_tensor": 13, "programwithoptionaloutputtensor": 13, "compute_output_tensor": 13, "box": [13, 15], "preferred_nam": 13, "parallelization_strategi": 13, "get_parallelization_strategi": 13, "parallel": [13, 17, 206], "parallelizationstrategyenum": 13, "enqueu": 13, "wait": [13, 17, 171], "finish": [13, 17, 203, 206], "asynchron": 13, "complet": [13, 171], "reload": 13, "same": [13, 17, 18, 23, 37, 50, 62, 69, 88, 89, 101, 102, 103, 105, 108, 119, 120, 123, 124, 165, 167, 177, 202, 204], "program_cach": 13, "disable_and_clear": 13, "entri": 13, "num_entri": 13, "cachabl": 13, "mandatori": 13, "override_runtime_args_callback": 13, "e": [13, 15, 17, 112, 209], "unary_reader_kernel_id": 13, "unary_writer_kernel_id": 13, "input_buff": 13, "output_buff": 13, "src_dram_buff": 13, "dst_dram_buff": 13, "corecoord": 13, "runtime_arg": 13, "getruntimearg": 13, "address": 13, "tt_metal_logger_typ": [13, 209], "tt_metal_logger_level": [13, 209], "inform": 13, "1280": 13, "layoutconversiononhost": 13, "320": [13, 42], "miss": [13, 209], "eltwiseunari": 13, "op_typ": 13, "unaryoptyp": 13, "param": [13, 208], "_tt": 13, "operation_history_csv": [13, 209], "csv_file_path": 13, "histori": 13, "dump": [13, 119, 207, 208, 209], "autofunct": [13, 104], "ep": 13, "gamma": 13, "beta": [13, 159], "output_mem_config": [13, 206], "program_config": [13, 87, 94, 112, 181, 182], "union": [13, 19, 60, 61], "layernormdefaultprogramconfig": 13, "layernormshardedmulticoreprogramconfig": 13, "0x7fcc082919f0": 13, "compute_kernel_config": [13, 94, 112, 184], "grayskullcomputekernelconfig": 13, "wormholecomputekernelconfig": 13, "via": 13, "0x7fcc0828ac30": 13, "softmaxdefaultprogramconfig": [13, 181, 182], "softmaxshardedmulticoreprogramconfig": 13, "0x7fcc085047f0": 13, "morehsoftmaxopparallelizationstrategi": 13, "output_grad_tensor": 13, "input_grad_tensor": 13, "morehsoftmaxbackwardopparallelizationstrategi": 13, "grad": 13, "softmin": 13, "logsoftmax": 13, "scale": [13, 72, 73, 159], "mask": [13, 181, 182], "0x7fcc0829deb0": 13, "is_causal_mask": 13, "attention_mask": [13, 181, 182, 204], "output_grad": 13, "input_grad": 13, "num_group": [13, 68], "999999747378752e": 13, "06": [13, 208], "are_required_output": 13, "rstd": 13, "mean_mem_config": 13, "rstd_mem_config": 13, "gamma_grad": 13, "beta_grad": 13, "input_grad_mem_config": 13, "gamma_grad_mem_config": 13, "beta_grad_mem_config": 13, "p": [13, 15, 18, 112], "mul": [13, 204], "h": [13, 15, 18, 188], "hw": 13, "input_a": [13, 78, 126], "input_b": [13, 78, 126], "accurate_mod": 13, "element": [13, 18, 19, 20, 21, 22, 27, 29, 30, 31, 33, 34, 40, 41, 44, 45, 47, 51, 52, 53, 54, 55, 56, 57, 64, 65, 66, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 90, 92, 93, 96, 97, 98, 99, 100, 109, 118, 122, 125, 127, 131, 134, 137, 139, 143, 144, 145, 146, 149, 151, 152, 153, 154, 155, 156, 157, 159, 161, 163, 164, 170, 172, 173, 174, 186, 187, 190, 202], "wise": [13, 20, 21, 22, 29, 30, 31, 33, 34, 40, 41, 44, 45, 47, 51, 52, 53, 54, 55, 56, 57, 64, 65, 70, 72, 73, 74, 75, 77, 79, 80, 81, 82, 83, 90, 92, 93, 96, 97, 98, 99, 100, 109, 118, 122, 125, 127, 137, 139, 143, 144, 149, 151, 152, 153, 154, 155, 156, 157, 159, 161, 163, 164, 170, 172, 173, 174, 186, 187], "non": [13, 19, 112], "numer": [13, 159], "denomin": 13, "mode": [13, 52, 53, 55, 64, 149, 202, 203, 204, 205, 206, 207], "eltwis": 13, "fast_and_approx": 13, "gaussian": 13, "approx": 13, "accur": 13, "slow": 13, "rectifi": 13, "lower_limit": 13, "down": 13, "carri": 13, "minvalu": 13, "upper_limit": 13, "cap": 13, "exponenti": 13, "natur": 13, "logarithm": 13, "hyperbol": 13, "tangent": 13, "low": [13, 74], "high": [13, 74, 209], "hard": [13, 159, 202], "0f": 13, "equal": [13, 50, 62, 89, 124, 209], "coeff": [13, 134], "highest": 13, "degre": 13, "signum": 13, "absolut": 13, "negat": 13, "tensor1": [13, 23, 39, 50, 62, 69, 78, 88, 89, 101, 102, 103, 105, 108, 112, 123, 124, 165, 167], "tensor2": [13, 23, 39, 50, 62, 69, 78, 88, 89, 101, 102, 103, 105, 108, 112, 123, 124, 165, 167], "accumul": [13, 131], "float1": 13, "float2": 13, "input11": 13, "1666666716337204": 13, "shift": [13, 72, 73], "5f": 13, "slope": [13, 90], "leaki": [13, 90], "cosin": [13, 184], "sine": [13, 184], "arccosin": 13, "arcsin": 13, "alpha": [13, 47], "factor": 13, "shift_amt": 13, "bit": 13, "wormhole_b0": [13, 15], "int32": [13, 145, 177, 178, 205], "arctan": 13, "invers": 13, "immedi": [13, 15], "logic": [13, 103, 105, 112, 119, 120], "xor": 13, "cq_id": 13, "queue": [13, 23, 27, 50, 62, 69, 88, 89, 101, 102, 103, 105, 108, 123, 124, 165, 167], "id": [13, 17, 23, 27, 50, 62, 69, 88, 89, 101, 102, 103, 105, 108, 123, 124, 165, 167], "integ": [13, 131], "boolean": 13, "finit": 13, "elsewher": 13, "infinit": 13, "infin": [13, 19], "nan": [13, 206], "clamp": 13, "greater": [13, 62, 69, 209], "than": [13, 15, 17, 62, 69, 89, 108, 204, 209], "AND": [13, 103], "multivari": 13, "mvlgamma": 13, "output_dtyp": 13, "queue_id": [13, 23, 27, 50, 62, 69, 88, 89, 101, 102, 103, 105, 108, 123, 124, 165, 167], "uint8_t": 13, "rtol": [13, 78], "atol": [13, 78], "99999993922529e": 13, "09": [13, 206], "equal_nan": [13, 78], "consid": 13, "1e": [13, 68, 78, 87, 148], "05f": 13, "08f": 13, "zeroth": 13, "bessel": 13, "kind": 13, "deriv": 13, "45": [13, 203, 204, 206], "OR": [13, 105], "decim": 13, "less": [13, 15, 17, 89, 108, 209], "predic": [13, 190], "true_valu": 13, "false_valu": 13, "third": 13, "three": 13, "replac": 13, "kernel_config": 13, "untilize_out": 13, "retain": 13, "dim0": 13, "dim1": 13, "swap": 13, "desir": [13, 132, 178, 179], "use_multicor": 13, "whether": [13, 94, 112, 119, 120, 185], "use_pack_until": 13, "pack": 13, "ofth": 13, "uint16": [13, 18, 23, 50, 62, 66, 69, 88, 89, 101, 102, 103, 105, 108, 123, 124, 165, 167, 177, 178], "1d": [13, 26, 94, 112, 206], "increment": [13, 26], "fill_valu": [13, 60, 61], "fill": [13, 17, 145], "assum": [13, 184, 188, 194], "diag": [13, 186, 187], "lower": 13, "triangular": 13, "rest": 13, "being": [13, 17, 18, 140, 141], "diagon": 13, "chosen": [13, 17, 208], "int32_t": 13, "upper": [13, 18], "math_op": 13, "let": [13, 18, 202, 204], "w1": 13, "z1": 13, "y1": 13, "x1": 13, "determin": [13, 94, 112, 119, 120, 202, 203, 204, 205, 206, 207], "hold": 13, "aggreg": [13, 17], "scaler": 13, "mathemat": 13, "ax": 13, "rais": [13, 207], "respect": [13, 18, 112], "subtrah": 13, "minuend": 13, "divid": [13, 181, 182], "ellipsi": 13, "output_layout": 13, "output_on_devic": 13, "except": [13, 202, 204, 206], "fewer": 13, "stride": [13, 19, 202, 207], "dilat": [13, 19, 207], "group": [13, 207], "2d": [13, 18, 19, 66, 112, 188], "convolut": [13, 207], "over": [13, 19, 66, 68, 87, 148, 158], "compos": [13, 19, 66], "sever": [13, 19, 66], "plane": [13, 19, 66, 207], "four": 13, "side": [13, 17, 19, 202, 203, 204, 205, 206, 207], "space": [13, 18, 19], "connect": 13, "paper": 13, "frac": 13, "mathrm": [13, 20, 21, 22, 23, 29, 30, 31, 33, 34, 40, 41, 44, 45, 47, 50, 51, 52, 53, 54, 55, 56, 57, 62, 64, 65, 66, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 88, 89, 90, 92, 93, 96, 97, 98, 99, 100, 101, 102, 103, 105, 108, 109, 118, 122, 123, 124, 125, 126, 127, 134, 137, 139, 143, 144, 149, 151, 152, 153, 154, 155, 156, 157, 159, 161, 163, 164, 165, 167, 170, 172, 173, 174, 186, 187], "epsilon": [13, 68, 87, 148], "separ": 13, "stabil": [13, 16, 159], "normalized_shap": 13, "layer": [13, 17, 207], "text": 13, "constant": [13, 131], "much": [13, 17, 203], "m": [13, 203], "reflect": [13, 16], "replic": 13, "circular": 13, "scale_factor": [13, 188], "nearest": [13, 188], "align_corn": 13, "recompute_scale_factor": 13, "antialia": 13, "algorithm": [13, 188], "spatial": [13, 66, 188], "bilinear": 13, "bicub": 13, "trilinear": 13, "area": 13, "exact": [13, 18, 204], "center": 13, "corner": 13, "pixel": 13, "recomput": [13, 119], "flag": [13, 28, 206], "anti": 13, "alias": 13, "output_s": 13, "repetit": [13, 145, 146], "total": [13, 17], "axi": [13, 146], "concaten": [13, 39, 183, 185], "known": 13, "sigma": 13, "logist": 13, "x_": 13, "x_i": 13, "sum_j": 13, "x_j": 13, "lie": 13, "in_channel": 13, "out_channel": 13, "kernel_s": [13, 19, 207], "padding_mod": 13, "signal": [13, 19, 66, 206], "simplest": 13, "c_": 13, "h_": 13, "w_": 13, "precis": 13, "n_i": 13, "_j": 13, "sum_": 13, "k": [13, 15, 203], "star": 13, "cross": 13, "denot": 13, "convolv": 13, "learnabl": 13, "running_mean": 13, "running_var": 13, "num_batches_track": 13, "num_featur": 13, "momentum": 13, "affin": 13, "track_running_stat": 13, "4d": 13, "deep": 13, "network": 13, "intern": [13, 14], "covari": 13, "track": 13, "varianc": 13, "num_channel": 13, "lernabl": 13, "per": [13, 206], "elementwise_affin": 13, "return_indic": 13, "ceil_mod": 13, "channels_last": [13, 17], "reshape_2d": 13, "kh": 13, "kw": 13, "begin": [13, 17], "c_j": 13, "max_": 13, "ldot": 13, "window": [13, 19], "implicit": [13, 19], "adapt": [13, 66], "averag": [13, 17, 66, 206], "smallest": 13, "largest": 13, "truncat": 13, "mod": 13, "dividend": 13, "bitwis": 13, "NOT": [13, 204], "arithmet": 13, "operand": 13, "promot": 13, "behavior": [13, 112], "undefin": 13, "keepdim": [13, 113, 115, 116, 166, 168, 189], "don": [13, 202], "unexpect": 13, "fusion": 13, "togeth": 13, "fused_op": 13, "in_featur": 13, "out_featur": 13, "num_dim": 13, "spec": [13, 42], "moment": 13, "add_and_norm": 13, "imaginari": 13, "compon": [13, 206], "complextensor": 13, "portion": 13, "conjug": 13, "cartesian": 13, "theta": 13, "flexibl": 13, "earlier": 13, "while": [13, 16], "cost": 13, "contigu": [13, 185, 202], "logsigmoid": 13, "1e6": 13, "ouptut": 13, "complementari": 13, "hone": 13, "wone": 13, "val_hi": 13, "val_lo": 13, "nchw": 13, "hfill": 13, "wfill": 13, "hi": 13, "lo": 13, "region": 13, "arg6": 13, "arg7": 13, "arg8": 13, "arg9": 13, "arg10": 13, "conv_param": 13, "group_siz": 13, "conv_weight_tensor": 13, "in1_block_h": 13, "in1_block_w": 13, "all_dimens": 13, "irrespect": 13, "ignor": 13, "deviat": 13, "gate": 13, "embeddings_typ": 13, "embeddingstyp": 13, "pad_token": [13, 48], "num_row": 13, "num_embed": 13, "num_column": 13, "token": [13, 48, 85, 184, 206], "uint32_t": 13, "toward": [13, 126], "exp_avg": 13, "exp_avg_sq": 13, "beta1": 13, "beta2": 13, "step_siz": 13, "weight_decai": 13, "accord": [13, 112, 145], "sfpu": 13, "shouldn": 13, "gradient": 13, "other_grad": 13, "input_a_grad": 13, "input_b_grad": 13, "round_mod": 13, "uniqu": 13, "nonzero": 13, "yield": 13, "subract": 13, "revers": 13, "hypotenus": 13, "approxim": [13, 52, 53, 55, 64, 149], "lambd": 13, "negative_slop": 13, "009999999776482582": 13, "is_complextensor": 13, "angl": 13, "selu": 13, "fmod": 13, "ramaind": 13, "taken": 13, "input_refer": 13, "input_predict": 13, "reduce_mod": 13, "lossreductionmod": 13, "ml": 14, "workload": 14, "guid": [14, 15], "falcon": 14, "7b": 14, "navig": 14, "mistral": 14, "llama2": 14, "70b": 14, "soon": 14, "t3000": [14, 15], "learn": [14, 18, 203, 206], "dive": 14, "deeper": 14, "jupyt": [14, 194, 206], "notebook": [14, 194, 206, 208], "tool": [15, 17, 206], "purchas": 15, "card": 15, "o": [15, 17, 206, 208], "drive": 15, "flash": 15, "smi": 15, "topolog": 15, "graysk": 15, "ull": 15, "ubun": 15, "tu": 15, "v1": [15, 185], "26": [15, 203, 206], "fw_pack": 15, "80": 15, "0_acec1267": 15, "tar": 15, "gz": 15, "v4": 15, "v2": 15, "abov": 15, "wormho": 15, "v80": 15, "wormh": 15, "ol": 15, "mesh": 15, "sudo": [15, 17], "apt": 15, "properti": [15, 18], "99": [15, 206], "essenti": 15, "8ubuntu1": 15, "python3": [15, 206, 208], "venv": 15, "0ubuntu1": 15, "04": [15, 204, 208], "libhwloc": 15, "dev": [15, 206], "graphviz": [15, 206], "patchelf": 15, "wget": 15, "llvm": 15, "org": [15, 206, 208], "chmod": 15, "17": [15, 204, 206, 208], "libc": 15, "abi": 15, "latest": [15, 17], "setup_hugepag": 15, "raw": [15, 208], "githubusercont": 15, "main": [15, 16, 194, 206, 208, 209], "infra": 15, "machine_setup": 15, "first_pass": 15, "reboot": [15, 17], "choos": 15, "matter": 15, "still": [15, 18], "just": [15, 204, 208], "lf": 15, "repo": 15, "recurs": 15, "submodul": [15, 119, 120], "cd": [15, 17, 206], "foreach": 15, "fetch": 15, "pull": [15, 16], "arch_nam": 15, "tt_metal_hom": [15, 17, 206], "releas": [15, 112], "cmake": 15, "flow": [15, 17], "build_met": 15, "about": [15, 18, 203], "variou": 15, "shown": [15, 18], "architectur": [15, 209], "ie": 15, "choic": [15, 202], "pip": [15, 206, 208], "wheel_fil": 15, "whl": [15, 206, 208], "further": [15, 203], "txt": [15, 206], "visit": 15, "1ubuntu1": 15, "pandoc": [15, 206], "libtbb": 15, "libcapston": 15, "pkg": 15, "ninja": 15, "doxygen": 15, "higher": [15, 17, 18, 159], "intend": 16, "reliabl": 16, "simultan": 16, "fine": 16, "tune": 16, "themselv": [16, 18], "goal": 16, "ask": 16, "driven": 16, "popular": 16, "kent": 16, "beck": 16, "By": [16, 159, 203], "long": 16, "term": 16, "benefit": 16, "submit": 16, "label": [16, 18], "fulli": [16, 17], "branch": 16, "pattern": [16, 119], "brief": 16, "4730": 16, "rst": 16, "format": 16, "referenc": [16, 206], "verifi": 16, "codeown": 16, "pr": 16, "comparison": 16, "decor": [16, 204, 206], "comment": 16, "build_script": [17, 206], "build_with_profiler_opt": [17, 206], "test_perf_resnet": 17, "test_perf_bare_met": 17, "0185": 17, "25": [17, 177, 203, 206, 208], "consol": 17, "similar": [17, 202, 204], "shorter": 17, "append": [17, 112, 208], "cli": 17, "explain": 17, "reset": 17, "tt_smi": 17, "tensix_reset": 17, "due": [17, 18, 202, 204], "tensix": 17, "skew": 17, "timer": 17, "wh": 17, "popul": [17, 84, 119], "least": [17, 112], "twice": 17, "analyz": 17, "1000": [17, 208], "fixtur": 17, "dumpdeviceprofil": 17, "avoid": [17, 119, 159], "drop": 17, "around": 17, "120": [17, 206], "eighth": 17, "warn": [17, 202, 203, 204, 205, 206, 207], "messag": 17, "mention": 17, "risc": 17, "faster": [17, 204], "those": 17, "analysi": 17, "affect": 17, "column": [17, 18, 206], "ran": [17, 204], "python_fallback": [17, 206], "tt_dnn_cpu": 17, "tt_dnn_devic": [17, 206], "global": [17, 206], "fidel": [17, 206], "field": 17, "lofi": 17, "hifi2": 17, "hifi3": 17, "hifi4": [17, 206], "clock": 17, "stamp": 17, "durat": [17, 204, 206, 209], "nanosecond": [17, 203], "end_t": 17, "start_t": 17, "fw": 17, "cycl": 17, "earliest": 17, "core_frequ": 17, "marker": 17, "brisc": 17, "ncrisc": 17, "trisc0": 17, "trisc1": 17, "trisc2": 17, "cb": 17, "front": [17, 208], "spent": 17, "cb_wait_front": 17, "reserv": 17, "cb_reserve_back": 17, "path": [17, 28, 46, 95, 206, 208, 209], "hash": [17, 119, 120], "datamov": 17, "templat": 17, "io": 17, "input_0_memori": 17, "dev_0_dram": 17, "dec_0_l1": 17, "tgz": 17, "filenam": [17, 208], "item": [17, 206], "timestamp": 17, "28": [18, 206, 208], "32x32": 18, "bracket": 18, "obtain": [18, 206], "consecut": 18, "4x4": 18, "transit": 18, "2x2": 18, "illustr": 18, "byte": 18, "sizeof": 18, "becaus": [18, 202, 203, 204], "owned_host_storag": 18, "alloc": [18, 202, 203, 204, 205, 206, 207], "borrowed_host_storag": 18, "device_storag": 18, "distribut": [18, 42, 46, 94, 112], "ideal": 18, "abstract": 18, "awai": 18, "compress": 18, "remain": 18, "128x128": 18, "who": 18, "subset": 18, "orient": [18, 42], "know": 18, "understand": 18, "unshard": 18, "coordin": 18, "dram_memory_config": [18, 26, 37, 78, 94, 112, 126, 131, 134, 185, 207], "physic": 18, "pybind11_object": 18, "_ttnn": [18, 147, 176], "input_height": 19, "input_width": 19, "reader_patterns_cach": [19, 119, 207], "parallel_config_overrid": 19, "deallocate_activ": 19, "implicitli": 19, "attr": [19, 206], "_tensor": [20, 21, 22, 23, 29, 30, 31, 33, 34, 40, 41, 44, 45, 47, 51, 52, 53, 54, 55, 56, 57, 64, 65, 66, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 90, 92, 93, 96, 97, 98, 99, 100, 109, 118, 122, 125, 126, 127, 134, 137, 139, 143, 144, 149, 151, 152, 153, 154, 155, 156, 157, 159, 161, 163, 164, 170, 172, 173, 174, 186, 187], "_i": [20, 21, 22, 23, 29, 30, 31, 33, 34, 40, 41, 44, 45, 47, 50, 51, 52, 53, 54, 55, 56, 57, 62, 64, 65, 66, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 88, 89, 90, 92, 93, 96, 97, 98, 99, 100, 101, 102, 103, 105, 108, 109, 118, 122, 123, 124, 125, 126, 127, 134, 137, 139, 143, 144, 149, 151, 152, 153, 154, 155, 156, 157, 159, 161, 163, 164, 165, 167, 170, 172, 173, 174, 186, 187], "keyword": [20, 21, 22, 23, 27, 29, 30, 31, 33, 34, 39, 40, 41, 44, 45, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 62, 64, 65, 66, 69, 70, 72, 73, 74, 75, 77, 79, 80, 81, 82, 83, 88, 89, 90, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 105, 108, 109, 112, 118, 122, 123, 124, 125, 126, 127, 134, 137, 139, 140, 141, 143, 144, 145, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 163, 164, 165, 167, 170, 172, 173, 174, 181, 182, 183, 186, 187, 190], "min_rank": [20, 21, 23, 27, 29, 31, 40, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 62, 64, 65, 66, 68, 69, 70, 75, 77, 79, 80, 81, 82, 83, 87, 88, 89, 90, 92, 96, 97, 99, 100, 101, 102, 103, 105, 108, 109, 113, 115, 116, 123, 124, 125, 127, 139, 143, 144, 145, 146, 148, 149, 151, 153, 154, 155, 156, 158, 159, 163, 164, 165, 166, 167, 168, 172, 173, 177, 178, 181, 182, 183, 184, 188, 189], "max_rank": [20, 21, 23, 27, 29, 31, 40, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 62, 64, 65, 66, 68, 69, 70, 75, 77, 79, 80, 81, 82, 83, 87, 88, 89, 90, 92, 96, 97, 99, 100, 101, 102, 103, 105, 108, 109, 113, 115, 116, 123, 124, 125, 127, 139, 143, 144, 145, 146, 148, 149, 151, 153, 154, 155, 156, 158, 159, 163, 164, 165, 166, 167, 168, 172, 173, 177, 178, 181, 182, 183, 184, 188, 189], "can_be_on_devic": [20, 21, 23, 27, 29, 31, 40, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 62, 64, 65, 66, 68, 69, 70, 75, 77, 79, 80, 81, 82, 83, 87, 88, 89, 90, 92, 96, 97, 99, 100, 101, 102, 103, 105, 108, 109, 113, 115, 116, 123, 124, 125, 127, 139, 143, 144, 145, 146, 148, 149, 151, 153, 154, 155, 156, 158, 159, 163, 164, 165, 166, 167, 168, 172, 173, 177, 178, 181, 182, 183, 184, 188, 189], "can_be_on_cpu": [20, 21, 23, 27, 29, 31, 40, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 62, 64, 65, 66, 68, 69, 70, 75, 77, 79, 80, 81, 82, 83, 87, 88, 89, 90, 92, 96, 97, 99, 100, 101, 102, 103, 105, 108, 109, 113, 115, 116, 123, 124, 125, 127, 139, 143, 144, 145, 146, 148, 149, 151, 153, 154, 155, 156, 158, 159, 163, 164, 165, 166, 167, 168, 172, 173, 177, 178, 181, 182, 183, 184, 188, 189], "can_be_scalar": [20, 21, 23, 27, 29, 31, 40, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 62, 64, 65, 66, 68, 69, 70, 75, 77, 79, 80, 81, 82, 83, 87, 88, 89, 90, 92, 96, 97, 99, 100, 101, 102, 103, 105, 108, 109, 113, 115, 116, 123, 124, 125, 127, 139, 143, 144, 145, 146, 148, 149, 151, 153, 154, 155, 156, 158, 159, 163, 164, 165, 166, 167, 168, 172, 173, 177, 178, 181, 182, 183, 184, 188, 189], "is_opt": [20, 21, 23, 27, 29, 31, 40, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 62, 64, 65, 66, 68, 69, 70, 75, 77, 79, 80, 81, 82, 83, 87, 88, 89, 90, 92, 96, 97, 99, 100, 101, 102, 103, 105, 108, 109, 113, 115, 116, 123, 124, 125, 127, 139, 143, 144, 145, 146, 148, 149, 151, 153, 154, 155, 156, 158, 159, 163, 164, 165, 166, 167, 168, 172, 173, 177, 178, 181, 182, 183, 184, 188, 189], "input_tensor_a": [23, 32, 50, 62, 69, 76, 78, 86, 88, 89, 91, 94, 101, 102, 103, 105, 106, 108, 112, 114, 117, 121, 123, 124, 126, 134, 165, 167, 191, 202, 209], "input_tensor_b": [23, 32, 50, 62, 69, 76, 78, 86, 88, 89, 91, 94, 101, 102, 103, 105, 106, 108, 112, 114, 117, 121, 123, 124, 126, 165, 167, 191, 202, 209], "_a": [23, 78, 126, 134], "_b": [23, 78, 126], "prealloc": [23, 27, 50, 62, 69, 88, 89, 101, 102, 103, 105, 108, 123, 124, 165, 167], "uint8": [23, 27, 50, 62, 69, 88, 89, 101, 102, 103, 105, 108, 123, 124, 165, 167], "input_tensor1": [24, 25], "input_tensor2": [24, 25], "flatten": 27, "cache_file_nam": 28, "pathlib": 28, "serial": 28, "mesh_mapp": 28, "tensortomesh": 28, "map": [28, 202, 203, 204, 205, 206, 207], "use_device_til": 28, "375": [28, 59, 203], "30469": [28, 59], "714844": [28, 59], "761719": [28, 59], "53125": [28, 59], "652344": [28, 59], "parameter1": [36, 175], "parameter2": [36, 175], "datayp": 37, "becom": [37, 177], "tnn": 37, "coregrid": [42, 94, 112, 203, 204], "corerang": 42, "shardstrategi": 42, "shardorient": 42, "halo": 42, "use_height_and_width_as_shard_shap": 42, "travers": 42, "overlap": 42, "seen": [42, 202, 203], "forc": 43, "file_nam": [46, 95, 208, 209], "fast_and_approximate_mod": [47, 52, 53, 55, 64, 75, 90, 149], "inxput_tensor": 48, "retriev": 48, "word": 48, "device_id": [48, 111, 130, 177, 178, 202, 203, 204, 205, 207, 209], "106445": 48, "988281": 48, "59375": 48, "212891": 48, "964844": [48, 203], "199219": 48, "996094": 48, "78362e": 48, "38": [48, 206], "89785e": 48, "39": [48, 203, 204, 206, 208], "04479e": 48, "25815e": 48, "71833e": 48, "59995e": 48, "60398e": 48, "83671e": 48, "22242e": 48, "88263e": 48, "35917e": 48, "49994e": 48, "08": [78, 202, 203, 205, 206, 207], "batch_index": 84, "update_index": 85, "batch_offset": 85, "loss_mod": [86, 121], "residual_input_tensor": 87, "programconfig": 87, "mcompar": 89, "matmulprogramconfig": [94, 112], "use_1d_systolic_arrai": [94, 112], "devicecomputekernelconfig": [94, 112, 184], "systol": [94, 112], "arrai": [94, 112], "128": [94, 112, 209], "input1": 110, "input2": 110, "context": [111, 140, 141], "product": 112, "prepend": 112, "j": 112, "n_size": 112, "k_size": 112, "stategi": 112, "m_size": 112, "dot": 112, "fix": 112, "upcom": 112, "tensorensor": 112, "callabl": [119, 120], "parameterdict": [119, 120], "prefix": [119, 120], "run_model": [119, 207], "doesn": [119, 120, 202], "invalid": [119, 120], "preprocessor": [119, 120], "attach": [119, 120, 206], "appear": [119, 120], "ttnn_module_arg": 119, "tmp": [119, 204, 207, 208], "model_graph": [119, 207], "svg": [119, 207, 208, 209], "reader": 119, "custom": [140, 141, 204], "fit": 146, "expand": 146, "torch_result": 146, "0310059": 158, "adjust": 159, "steep": 159, "steeper": 159, "whose": 177, "42188": 177, "398438": 177, "vice": 178, "versa": 178, "torch_rank": 179, "Will": 179, "squeez": 179, "reach": 179, "ttnn_tensor": [179, 202], "torch_tensor": [179, 202], "3008": 179, "8438": 179, "3242": 179, "9023": 179, "5820": 179, "5312": 179, "head_siz": [181, 182, 183, 185, 204], "softmaxprogramconfig": [181, 182], "causal_mask": [181, 182], "causal": [181, 182], "num_head": [183, 185, 204], "cos_cach": 184, "sin_cach": 184, "token_index": 184, "rotari": 184, "token_idx": 184, "seq_len": 184, "head_dim": 184, "kv_input_tensor": 185, "num_kv_head": 185, "score": [185, 206], "q1": 185, "k1": 185, "qn": 185, "kn": 185, "vn": 185, "cat": [185, 204, 208], "transpose_kei": 185, "num": 185, "form": 188, "ramp": 194, "skillset": 194, "tree": 194, "directori": [194, 208], "lab": 194, "port": 194, "8888": 194, "hint": 194, "Be": 194, "sure": [194, 209], "alwai": [194, 202, 204, 206], "cell": 194, "central": 202, "sens": 202, "sram": 202, "concept": 202, "bfp8": 202, "f": [202, 203, 204, 206, 208, 209], "As": [202, 203], "1234": 202, "again": 202, "action": 202, "868396": 202, "199809": 202, "505658": 202, "0919966": 202, "441207": 202, "465399": 202, "225584": 202, "497159": 202, "205919": 202, "219386": 202, "0836022": 202, "761129": 202, "pick": 202, "float16": 202, "9375": 202, "0683594": 202, "765625": 202, "894531": 202, "100098": 202, "285156": 202, "597656": 202, "21582": 202, "203125": 202, "730469": 202, "310547": 202, "453125": 202, "explicitli": 202, "most": 202, "effici": [202, 203], "transfer": 202, "constraint": 202, "nshape": 202, "nlayout": 202, "020752": 202, "0820312": 202, "664062": 202, "0742188": 202, "0463867": 202, "785156": 202, "0195312": 202, "304688": 202, "287109": 202, "671875": 202, "808594": 202, "insert": 202, "cale": 202, "info": [202, 203, 204, 205, 206, 207, 208], "2024": [202, 203, 204, 205, 206, 207, 208, 209], "02": [202, 203, 205, 206, 207], "19": [202, 205, 206, 208], "597": 202, "silicondriv": [202, 203, 204, 205, 206, 207], "detect": [202, 203, 204, 205, 206, 207], "610": 202, "init_detect_tt_device_numanod": [202, 203, 204, 205, 206, 207], "numanodeset": [202, 203, 204, 205, 206, 207], "physical_device_id": [202, 203, 204, 205, 206, 207], "pci_bus_id": [202, 203, 204, 205, 206, 207], "0000": [202, 203, 204, 205, 206, 207], "00": [202, 203, 204, 205, 206, 207, 208], "612": 202, "bind_area_memory_nodeset": [202, 203, 204, 205, 206, 207], "unabl": [202, 203, 204, 205, 206, 207], "numanod": [202, 203, 204, 205, 206, 207], "skip": [202, 203, 204, 205, 206, 207, 208], "membind": [202, 203, 204, 205, 206, 207], "ttsilicondevic": [202, 203, 204, 205, 206, 207], "init_hugepag": [202, 203, 204, 205, 206, 207], "bind_area_to_memory_nodeset": [202, 203, 204, 205, 206, 207], "fail": [202, 203, 204, 205, 206, 207], "ch": [202, 203, 204, 205, 206, 207], "effect": [202, 203, 204, 205, 206, 207], "decreas": [202, 203, 204, 205, 206, 207], "893": [202, 203, 204, 205, 206, 207], "ai": [202, 203, 204, 205, 206, 207], "clk": [202, 203, 204, 205, 206, 207], "1202": [202, 203, 204, 205, 206, 207], "mhz": [202, 203, 204, 205, 206, 207], "torch_input_tensor_a": [202, 209], "torch_input_tensor_b": [202, 209], "therefor": [202, 204], "stai": 202, "unless": [202, 209], "explicit": 202, "obviou": 202, "figur": 202, "hang": 202, "properli": 202, "01": [203, 207], "23": [203, 206], "902": 203, "913": 203, "915": 203, "repeatedli": 203, "enable_program_cach": [203, 204, 209], "torch_a": 203, "torch_b": 203, "175489": 203, "326608": 203, "47769": 203, "165459": 203, "longer": 203, "38930": 203, "35890": 203, "576872807": 203, "577071926": 203, "99419": 203, "signific": 203, "39200": 203, "22440": 203, "1183694": 203, "1224093": 203, "64480": 203, "aslo": 203, "why": 203, "conver": 203, "todo": 203, "508667002": 203, "nanosecondsprint": 203, "508783061": 203, "1352602": 203, "1744890": 203, "34": [203, 206, 207], "625": 203, "3125": 203, "45312": 203, "875": 203, "125": 203, "39062": 203, "8125": 203, "6875": 203, "18": [203, 204, 206, 208], "42": [203, 204, 206, 208], "75": 203, "27": [203, 206, 208], "44": [203, 205, 206], "43": [203, 205, 206], "4375": 203, "5625": 203, "711456": 203, "123629": 203, "190228": 203, "effeci": 203, "46380": 203, "33729": 203, "1330892": 203, "1996019": 203, "556706140": 203, "556884870": 203, "424187": 203, "473467": 203, "116419": 203, "27450": 203, "652476970": 203, "652929758": 203, "86579": 203, "enjoi": 203, "massiv": 203, "38110": 203, "24079": 203, "129909": 203, "164599": 203, "24209": 203, "l1_small_siz": [204, 205], "8192": [204, 205], "615": 204, "126": 204, "cache_path": 204, "posixpath": 204, "home": [204, 206, 208], "ubuntu": [204, 206, 208], "comparison_mode_pcc": [204, 209], "enable_comparison_mod": [204, 209], "enable_detailed_buffer_report": [204, 209], "enable_detailed_tensor_report": [204, 209], "enable_fast_runtime_mod": [204, 209], "enable_graph_report": [204, 209], "enable_log": [204, 209], "enable_model_cach": 204, "model_cache_path": 204, "report_nam": [204, 209], "root_report_path": 204, "throw_exception_on_fallback": 204, "tmp_dir": [204, 208], "906": 204, "918": 204, "07": [204, 205], "920": 204, "fashion": 204, "mind": 204, "multi_head_attent": 204, "query_weight": 204, "query_bia": 204, "key_weight": 204, "key_bia": 204, "value_weight": 204, "value_bia": 204, "output_weight": 204, "output_bia": 204, "fallback_reshap": 204, "get_fallback_funct": 204, "attention_scor": 204, "attention_prob": 204, "context_lay": 204, "self_output": 204, "torch_attention_mask": [204, 205], "torch_query_weight": 204, "torch_query_bia": 204, "torch_key_weight": 204, "torch_key_bia": 204, "torch_value_weight": 204, "torch_value_bia": 204, "torch_output_weight": 204, "torch_output_bia": 204, "752": 204, "call_wrapp": 204, "557": 204, "fall": 204, "tt_throw": 204, "98": [204, 206], "fatal": [204, 208], "47": [204, 206, 207], "240": [204, 206], "605": 204, "50": 204, "150": 204, "2719199657440186": 204, "786": 204, "813": 204, "171": 204, "535": 204, "3269269466400146": 204, "ahead": 204, "optimized_multi_head_attent": 204, "fused_qkv_weight": 204, "fused_qkv_bia": 204, "self_output_weight": 204, "self_output_bia": 204, "fused_qkv_output": 204, "context_layer_after_concatenate_head": 204, "qkv": 204, "torch_qkv_weight": 204, "torch_qkv_bia": 204, "qkv_weight": 204, "qkv_bia": 204, "optimized_output": 204, "9824471473693848": 204, "15": [204, 206], "002396821975708008": 204, "magnitud": 204, "torch_optimized_output": 204, "assert": [204, 209], "allclos": 204, "set_verbosity_error": 205, "100": [205, 206], "googl": [205, 208], "bert_uncased_l": 205, "4_h": 205, "256_a": 205, "bertselfoutput": 205, "59": 205, "074": 205, "085": 205, "086": 205, "num_hidden_lay": 205, "bertforquestionansw": 205, "input_id": 205, "vocab_s": 205, "torch_token_type_id": 205, "torch_position_id": 205, "ttnn_bert_input": 205, "preprocess_input": 205, "bert_for_question_answ": 205, "032": 205, "338": 205, "054": 205, "340": 205, "bash": 206, "unset": 206, "silent": 206, "nuke": 206, "jobserv": 206, "unavail": 206, "j1": 206, "parent": 206, "rule": 206, "artifact": 206, "conf": 206, "env": [206, 208], "backend": 206, "pypi": [206, 208], "satisfi": [206, 208], "setuptool": 206, "site": [206, 208], "packag": [206, 208], "py3": 206, "kb": 206, "edit": 206, "statu": 206, "metadata": [206, 208], "click": 206, "loguru": 206, "58": 206, "ipywidget": 206, "139": 206, "90": 206, "db": 206, "290ab3a34f2ef0b5a0f89235dc2d40fea83e77de84ed2dc05c": 206, "pyyaml": [206, 208], "cp38": 206, "linux_x86_64": 206, "jupyterlab": 206, "mb": 206, "pyelftool": 206, "py2": 206, "174": 206, "4f": 206, "ed": 206, "863cf4386fe6db3c09333712009ec1c5146a36f3904b469d13": 206, "curtsi": 206, "91": 206, "b7": 206, "0c117d73912c6c2beb1eb0d7d6884f4e79e6e5b5e91eeb34f5": 206, "torchtrail": [206, 207], "manylinux_2_12_x86_64": 206, "manylinux2010_x86_64": 206, "matplotlib": 206, "toolz": 206, "55": 206, "pillow": [206, 208], "manylinux_2_17_x86_64": 206, "manylinux2014_x86_64": 206, "panda": 206, "2bcpu": 206, "199": 206, "dash": 206, "rich": 206, "238": 206, "seaborn": 206, "293": 206, "plotli": 206, "traitlet": 206, "85": 206, "widgetsnbextens": 206, "ipython": [206, 207, 208], "798": 206, "widget": 206, "jupyterlab_widget": 206, "215": 206, "comm": 206, "async": 206, "lru": 206, "async_lru": 206, "tomli": 206, "python_vers": 206, "server": 206, "jupyter_serv": 206, "380": 206, "jinja2": [206, 208], "133": 206, "ipykernel": 206, "116": 206, "shim": 206, "notebook_shim": 206, "jupyterlab_serv": 206, "lsp": 206, "jupyter_lsp": 206, "68": 206, "53": 206, "importlib": [206, 208], "resourc": 206, "importlib_resourc": 206, "importlib_metadata": 206, "jupyter_cor": 206, "tornado": 206, "abi3": 206, "manylinux_2_5_x86_64": 206, "manylinux1_x86_64": 206, "435": 206, "bless": 206, "cwcwidth": 206, "92": 206, "pyrsist": 206, "121": 206, "pypars": 206, "103": 206, "kiwisolv": 206, "contourpi": 206, "301": [206, 207], "fonttool": 206, "22": 206, "48": 206, "dateutil": 206, "python_dateutil": 206, "247": 206, "cycler": 206, "pytz": 206, "2020": 206, "505": 206, "extens": [206, 208], "typing_extens": 206, "html": 206, "dash_html_compon": 206, "dash_tabl": 206, "flask": 206, "101": 206, "dash_core_compon": 206, "pygment": 206, "markdown": 206, "markdown_it_pi": 206, "84": 206, "tenac": 206, "24": [206, 208], "pickleshar": 206, "prompt": 206, "toolkit": 206, "37": 206, "prompt_toolkit": 206, "386": 206, "stack": 206, "stack_data": 206, "backcal": 206, "jedi": 206, "pexpect": 206, "sys_platform": 206, "win32": 206, "inlin": 206, "matplotlib_inlin": 206, "send2trash": 206, "anyio": 206, "termin": 206, "jupyter_server_termin": 206, "client": 206, "jupyter_cli": 206, "105": 206, "nbformat": 206, "77": 206, "overrid": [206, 209], "nbconvert": 206, "257": 206, "event": 206, "jupyter_ev": 206, "websocket": 206, "websocket_cli": 206, "pyzmq": 206, "prometheu": 206, "prometheus_cli": 206, "54": 206, "argon2": 206, "cffi": 206, "argon2_cffi": 206, "terminado": 206, "markupsaf": [206, 208], "nest": 206, "asyncio": 206, "nest_asyncio": 206, "psutil": 206, "cp36": 206, "288": 206, "debugpi": 206, "babel": 206, "62": 206, "jsonschema": 206, "21": [206, 208], "json5": 206, "zipp": [206, 208], "platformdir": 206, "six": 206, "wcwidth": 206, "itsdanger": 206, "blinker": 206, "werkzeug": 206, "226": 206, "mdurl": 206, "pure": 206, "pure_ev": 206, "asttoken": 206, "parso": 206, "ptyprocess": 206, "exceptiongroup": 206, "idna": [206, 208], "61": 206, "sniffio": 206, "fastjsonschema": 206, "defusedxml": 206, "beautifulsoup4": 206, "147": [206, 207], "jupyterlab_pyg": 206, "pandocfilt": 206, "mistun": 206, "tinycss2": 206, "bleach": 206, "162": 206, "nbclient": 206, "rfc3986": 206, "rfc3986_valid": 206, "json": [206, 209], "logger": 206, "python_json_logg": 206, "rfc3339": 206, "rfc3339_valid": 206, "bind": 206, "argon2_cffi_bind": 206, "86": 206, "urllib3": [206, 208], "charset": [206, 208], "charset_norm": 206, "141": 206, "certifi": [206, 208], "163": 206, "2023": [206, 208], "03": 206, "jsonschema_specif": 206, "pkgutil": 206, "resolv": 206, "pkgutil_resolve_nam": 206, "60": 206, "rpd": 206, "rpds_py": 206, "soupsiev": 206, "36": 206, "webencod": 206, "444": 206, "pycpars": 206, "118": 206, "pre_commit": 206, "202": 206, "black": 206, "twine": 206, "yamllint": 206, "docutil": 206, "570": 206, "sphinx": 206, "rtd": 206, "theme": 206, "sphinx_rtd_them": 206, "sphinxcontrib": 206, "email": 206, "sphinxcontrib_email": 206, "lxml": 206, "manylinux_2_24_x86_64": 206, "breath": 206, "35": 206, "nbsphinx": 206, "jqueri": 206, "sphinxcontrib_jqueri": 206, "3a": 206, "a8": 206, "3237a93e3a6261bd24edabf3277ca59f64c1710b3d8c7c72a0": 206, "317": 206, "timeout": 206, "pytest_timeout": 206, "6c": 206, "40": 206, "5706d21e6b4dff52e7af12bff9ca126a3f15beb4dff386aa29": 206, "jsbeautifi": 206, "dataset": 206, "462": 206, "xlsxwriter": 206, "152": 206, "tiktoken": 206, "tqdm": [206, 208], "sentencepiec": 206, "numba": 206, "56": [206, 207], "librosa": 206, "252": 206, "timm": [206, 208], "549": 206, "opencv": 206, "headless": 206, "74": 206, "opencv_python_headless": 206, "cp37": 206, "49": [206, 208], "diffus": [206, 208], "604": 206, "219": 206, "ftfy": 206, "gitpython": 206, "188": 206, "einop": 206, "multiprocess": 206, "70": 206, "py38": 206, "132": 206, "evalu": 206, "81": 206, "bert_scor": 206, "fsspec": [206, 208], "173": 206, "nodeenv": 206, "cfgv": 206, "identifi": [206, 209], "virtualenv": 206, "pathspec": 206, "mypi": 206, "mypy_extens": 206, "pyproject_hook": 206, "render": 206, "readme_render": 206, "pkginfo": 206, "toolbelt": 206, "requests_toolbelt": 206, "keyr": 206, "images": 206, "serializinghtml": 206, "sphinxcontrib_serializinghtml": 206, "94": 206, "jsmath": 206, "sphinxcontrib_jsmath": 206, "snowballstemm": 206, "93": 206, "htmlhelp": 206, "sphinxcontrib_htmlhelp": 206, "alabast": 206, "applehelp": 206, "sphinxcontrib_applehelp": 206, "devhelp": 206, "sphinxcontrib_devhelp": 206, "qthelp": 206, "sphinxcontrib_qthelp": 206, "ply": 206, "plumbum": 206, "iniconfig": 206, "pluggi": 206, "0rc8": 206, "editorconfig": 206, "respons": 206, "pyarrow": 206, "xxhash": 206, "194": 206, "huggingfac": [206, 208], "hub": [206, 208], "huggingface_hub": 206, "330": 206, "aiohttp": 206, "dill": 206, "110": 206, "regex": [206, 208], "2019": [206, 208], "777": 206, "filelock": [206, 208], "llvmlite": 206, "0dev0": 206, "soxr": 206, "soundfil": 206, "pooch": 206, "lazi": 206, "loader": 206, "lazy_load": 206, "scipi": 206, "joblib": 206, "302": 206, "audioread": 206, "scikit": 206, "scikit_learn": 206, "msgpack": 206, "534": 206, "gitdb": 206, "distlib": 206, "468": 206, "nh3": 206, "secretstorag": 206, "linux": 206, "jeepnei": 206, "jaraco": 206, "frozenlist": 206, "async_timeout": 206, "aiosign": 206, "yarl": 206, "308": 206, "multidict": 206, "129": 206, "threadpoolctl": 206, "smmap": 206, "cryptographi": 206, "itertool": 206, "more_itertool": 206, "57": 206, "pyproject": 206, "uninstal": 206, "msg": 206, "t5": 206, "integration_test": 206, "test_perform": 206, "test_t5_for_conditional_gener": 206, "functional_t5": 206, "ttnn_functional_t5": 206, "small": 206, "373": 206, "ops_devic": 206, "session": 206, "cachedir": 206, "pytest_cach": 206, "rootdir": 206, "configfil": 206, "ini": 206, "plugin": 206, "600": 206, "func_onli": 206, "670": 206, "681": 206, "684": 206, "llruntim": 206, "watcher": 206, "watch": 206, "109": 206, "465": 206, "save": [206, 207, 208], "ttnn_t5": 206, "6ba823894": 206, "149": 206, "484": 206, "487": 206, "216": 206, "489": 206, "721": 206, "359902381896973": 206, "07123565673828": 206, "722": 206, "102": 206, "44269247283137575": 206, "detach": 206, "short": [206, 209], "summari": 206, "627": 206, "638": 206, "639": 206, "458": 206, "load": [206, 208], "224": 206, "460": 206, "292": 206, "41": 206, "164": 206, "22393798828125": 206, "165": 206, "322504758834839": 206, "407821983919596": 206, "pd": 206, "glob": 206, "getenv": 206, "get_latest_report": 206, "base_path": 206, "latest_dir": 206, "listdir": 206, "isdir": 206, "getmtim": 206, "valueerror": [206, 207], "latest_profile_report": 206, "df": 206, "read_csv": 206, "2024_02_09_01_38_37": 206, "ops_perf_results_resnet_2024_02_09_01_38_37": 206, "output_0_w": 206, "output_0_z": 206, "output_0_i": 206, "output_0_x": 206, "output_0_layout": 206, "output_0_data": 206, "output_0_memori": 206, "depth": 206, "compileprogram": 206, "load_tensor_ttnn": 206, "137428381893955": 206, "137428382188762": 206, "294807": 206, "137428382500949": 206, "137428399402163": 206, "16901214": 206, "137428399802068": 206, "137428399873758": 206, "71690": 206, "137428400102635": 206, "137428400351033": 206, "248398": 206, "137428400548071": 206, "137428400792528": 206, "244457": 206, "4391": 206, "reshape_ttnn": 206, "4392": 206, "137450414555424": 206, "137450414599894": 206, "44470": 206, "4393": 206, "137450414740752": 206, "137450414782422": 206, "41670": 206, "4394": 206, "bcast_batch": 206, "tt_me": 206, "108": 206, "matmulparallelizationstrategi": 206, "multi_cor": 206, "137450414881851": 206, "137450414983440": 206, "101589": 206, "32128": 206, "dev_0_dram_interleav": 206, "4395": 206, "137450415113099": 206, "137450415158748": 206, "45649": 206, "from_device_ttnn": 206, "4396": 206, "137450415235897": 206, "137450453493048": 206, "38257151": 206, "157": 207, "159": 207, "conv3x3": 207, "in_plan": 207, "out_plan": 207, "3x3": 207, "torchbasicblock": 207, "expans": 207, "inplan": 207, "downsampl": 207, "base_width": 207, "norm_lay": 207, "basicblock": 207, "notimplementederror": 207, "conv1": 207, "bn1": 207, "inplac": 207, "conv2": 207, "bn2": 207, "torch_model": 207, "222": 207, "_initialize_model_and_preprocess_paramet": 207, "434": 207, "infer_ttnn_module_arg": 207, "368": 207, "346": 207, "multidigraph": 207, "visualize_graph": 207, "316": 207, "550": 207, "543": 207, "551": 207, "545": 207, "0x7f29c3b0fc10": 207, "0x7f299d093eb0": 207, "ttnnbasicblock": 207, "__call__": 207, "get_memory_config": 207, "run_conv": 207, "copy_input_to_devic": 207, "copy_output_from_devic": 207, "ttnn_model": 207, "walk": 208, "mirror": 208, "colab": 208, "research": 208, "blob": 208, "run_dit": 208, "ipynb": 208, "tab": 208, "ov": 208, "assumpt": 208, "chdir": 208, "content": 208, "upgrad": 208, "save_imag": 208, "create_diffus": 208, "autoencoderkl": 208, "find_model": 208, "collis": 208, "pil": 208, "set_grad_en": 208, "cuda": 208, "is_avail": 208, "gpu": 208, "322": 208, "destin": 208, "date": 208, "safetensor": 208, "sympi": 208, "mpmath": 208, "image_s": 208, "256": 208, "512": 208, "vae_model": 208, "stabilityai": 208, "sd": 208, "vae": 208, "ft": 208, "ema": 208, "mse": 208, "latent_s": 208, "input_s": 208, "state_dict": 208, "pt": 208, "load_state_dict": 208, "seed": 208, "num_sampling_step": 208, "250": 208, "slider": 208, "cfg_scale": 208, "class_label": 208, "207": 208, "360": 208, "387": 208, "974": 208, "88": 208, "979": 208, "417": 208, "279": 208, "samples_per_row": 208, "nois": 208, "len": 208, "classifi": 208, "free": 208, "guidanc": 208, "y_null": 208, "model_kwarg": 208, "p_sample_loop": 208, "forward_with_cfg": 208, "clip_denois": 208, "null": 208, "captur": 208, "decod": 208, "18215": 208, "dit_model_graph": 208, "png": 208, "nrow": 208, "value_rang": 208, "987": 208, "210": 208, "show_svg": 208, "snippet": 209, "spdx": 209, "filecopyrighttext": 209, "inc": 209, "licens": 209, "apach": 209, "view": 209, "unlik": 209, "start_tim": 209, "end_tim": 209, "stdout": 209, "6391518115997314": 209, "0007393360137939453": 209, "manage_config": 209, "9998": 209, "too": 209, "exp_trac": 209, "ttnn_config_overrid": 209, "operation_histori": 209, "substitut": 209, "disk": 209, "implementaiton": 209, "addition": 209, "ttnn_config_path": 209, "2048": 209, "app": 209, "pre_hook_to_print_args_and_kwarg": 209, "post_hook_to_print_output": 209, "query_registered_oper": 209, "slower": 209, "notifi": 209, "ttnn_throw_exception_on_fallback": 209, "ttnn_sweep": 210}, "objects": {"tt_lib.device": [[13, 0, 1, "", "Synchronize"]], "tt_lib.fallback_ops": [[13, 1, 1, "", "AdaptiveAvgPool2d"], [13, 1, 1, "", "BatchNorm2d"], [13, 1, 1, "", "Conv2d"], [13, 1, 1, "", "GroupNorm"], [13, 1, 1, "", "LayerNorm"], [13, 1, 1, "", "MaxPool2d"], [13, 1, 1, "", "binary_bitwise_and"], [13, 1, 1, "", "binary_bitwise_left_shift"], [13, 1, 1, "", "binary_bitwise_or"], [13, 1, 1, "", "binary_bitwise_right_shift"], [13, 1, 1, "", "binary_bitwise_xor"], [13, 1, 1, "", "binary_fmod"], [13, 1, 1, "", "bitwise_not"], [13, 1, 1, "", "ceil"], [13, 0, 1, "", "chunk"], [13, 0, 1, "", "concat"], [13, 0, 1, "", "conv2d"], [13, 1, 1, "", "floor"], [13, 0, 1, "", "full"], [13, 0, 1, "", "group_norm"], [13, 0, 1, "", "interpolate"], [13, 0, 1, "", "layer_norm"], [13, 0, 1, "", "pad"], [13, 0, 1, "", "repeat"], [13, 0, 1, "", "repeat_interleave"], [13, 0, 1, "", "reshape"], [13, 0, 1, "", "silu"], [13, 0, 1, "", "softmax"], [13, 0, 1, "", "tensor_slice"], [13, 1, 1, "", "torch_argmax"], [13, 1, 1, "", "torch_argmin"], [13, 1, 1, "", "trunc"], [13, 1, 1, "", "unary_bitwise_and"], [13, 1, 1, "", "unary_bitwise_left_shift"], [13, 1, 1, "", "unary_bitwise_or"], [13, 1, 1, "", "unary_bitwise_right_shift"], [13, 1, 1, "", "unary_bitwise_xor"], [13, 1, 1, "", "unary_fmod"]], "tt_lib.fused_ops.add_and_norm": [[13, 0, 1, "", "AddAndNorm"]], "tt_lib.fused_ops.layernorm": [[13, 0, 1, "", "Layernorm"]], "tt_lib.fused_ops.linear": [[13, 0, 1, "", "Linear"]], "tt_lib.fused_ops.softmax": [[13, 0, 1, "", "softmax"]], "tt_lib.operations.primary": [[13, 0, 1, "", "add_layernorm"], [13, 0, 1, "", "layernorm"], [13, 0, 1, "", "moreh_groupnorm"], [13, 0, 1, "", "moreh_groupnorm_backward"], [13, 0, 1, "", "moreh_logsoftmax"], [13, 0, 1, "", "moreh_logsoftmax_backward"], [13, 0, 1, "", "moreh_mean"], [13, 0, 1, "", "moreh_mean_backward"], [13, 0, 1, "", "moreh_norm"], [13, 0, 1, "", "moreh_norm_backward"], [13, 0, 1, "", "moreh_softmax"], [13, 0, 1, "", "moreh_softmax_backward"], [13, 0, 1, "", "moreh_softmin"], [13, 0, 1, "", "moreh_softmin_backward"], [13, 0, 1, "", "softmax_in_place"]], "tt_lib.operations.primary.transformers": [[13, 0, 1, "", "scale_mask_softmax_in_place"]], "tt_lib.tensor": [[13, 1, 1, "", "BcastOpDim"], [13, 1, 1, "", "BcastOpMath"], [12, 1, 1, "", "MemoryConfig"], [13, 1, 1, "", "ReduceOpDim"], [13, 1, 1, "", "ReduceOpMath"], [12, 1, 1, "", "Tensor"], [13, 0, 1, "", "abs"], [13, 0, 1, "", "abs_bw"], [13, 0, 1, "", "acos"], [13, 0, 1, "", "acos_bw"], [13, 0, 1, "", "acosh"], [13, 0, 1, "", "acosh_bw"], [13, 0, 1, "", "add1"], [13, 0, 1, "", "add_bw"], [13, 0, 1, "", "add_layernorm"], [13, 0, 1, "", "add_unary"], [13, 0, 1, "", "addalpha"], [13, 0, 1, "", "addalpha_bw"], [13, 0, 1, "", "addcdiv"], [13, 0, 1, "", "addcdiv_bw"], [13, 0, 1, "", "addcmul"], [13, 0, 1, "", "addcmul_bw"], [13, 0, 1, "", "angle_bw"], [13, 0, 1, "", "arange"], [13, 0, 1, "", "argmax"], [13, 0, 1, "", "argmin"], [13, 0, 1, "", "asin"], [13, 0, 1, "", "asin_bw"], [13, 0, 1, "", "asinh"], [13, 0, 1, "", "asinh_bw"], [13, 0, 1, "", "assign"], [13, 0, 1, "", "atan"], [13, 0, 1, "", "atan2"], [13, 0, 1, "", "atan2_bw"], [13, 0, 1, "", "atan_bw"], [13, 0, 1, "", "atanh"], [13, 0, 1, "", "atanh_bw"], [13, 0, 1, "", "bcast"], [13, 0, 1, "", "bias_gelu_bw"], [13, 0, 1, "", "bias_gelu_unary"], [13, 0, 1, "", "bias_gelu_unary_bw"], [13, 0, 1, "", "binary_assign_bw"], [13, 0, 1, "", "binary_eq_bw"], [13, 0, 1, "", "binary_ge_bw"], [13, 0, 1, "", "binary_gt_bw"], [13, 0, 1, "", "binary_le_bw"], [13, 0, 1, "", "binary_lt_bw"], [13, 0, 1, "", "binary_ne_bw"], [13, 0, 1, "", "bmm"], [13, 0, 1, "", "cbrt"], [13, 0, 1, "", "ceil_bw"], [13, 0, 1, "", "celu"], [13, 0, 1, "", "celu_bw"], [13, 0, 1, "", "clamp_bw"], [13, 0, 1, "", "clamp_max_bw"], [13, 0, 1, "", "clamp_min_bw"], [13, 0, 1, "", "clip"], [13, 0, 1, "", "clone"], [13, 0, 1, "", "complex_abs"], [13, 0, 1, "", "complex_abs_bw"], [13, 0, 1, "", "complex_add"], [13, 0, 1, "", "complex_add_bw"], [13, 0, 1, "", "complex_div"], [13, 0, 1, "", "complex_div_bw"], [13, 0, 1, "", "complex_mul"], [13, 0, 1, "", "complex_mul_bw"], [13, 0, 1, "", "complex_recip"], [13, 0, 1, "", "complex_recip_bw"], [13, 0, 1, "", "complex_sub"], [13, 0, 1, "", "complex_sub_bw"], [13, 0, 1, "", "concat"], [13, 0, 1, "", "concat_bw"], [13, 0, 1, "", "conj"], [13, 0, 1, "", "conj_bw"], [13, 0, 1, "", "conv"], [13, 0, 1, "", "convert_conv_weight_tensor_to_tiled_layout"], [13, 0, 1, "", "copy"], [13, 0, 1, "", "cos"], [13, 0, 1, "", "cos_bw"], [13, 0, 1, "", "cosh"], [13, 0, 1, "", "cosh_bw"], [13, 0, 1, "", "deg2rad"], [13, 0, 1, "", "deg2rad_bw"], [13, 0, 1, "", "digamma"], [13, 0, 1, "", "digamma_bw"], [13, 0, 1, "", "div"], [13, 0, 1, "", "div_bw"], [13, 0, 1, "", "div_no_nan"], [13, 0, 1, "", "div_unary"], [13, 0, 1, "", "elu"], [13, 0, 1, "", "elu_bw"], [13, 0, 1, "", "embedding_bw"], [13, 0, 1, "", "embeddings"], [13, 0, 1, "", "empty"], [13, 0, 1, "", "eqz"], [13, 0, 1, "", "erf"], [13, 0, 1, "", "erf_bw"], [13, 0, 1, "", "erfc"], [13, 0, 1, "", "erfc_bw"], [13, 0, 1, "", "erfinv"], [13, 0, 1, "", "erfinv_bw"], [13, 0, 1, "", "exp"], [13, 0, 1, "", "exp2"], [13, 0, 1, "", "exp2_bw"], [13, 0, 1, "", "exp_bw"], [13, 0, 1, "", "expm1"], [13, 0, 1, "", "expm1_bw"], [13, 0, 1, "", "fill_bw"], [13, 0, 1, "", "fill_ones_rm"], [13, 0, 1, "", "fill_rm"], [13, 0, 1, "", "fill_zero_bw"], [13, 0, 1, "", "floor"], [13, 0, 1, "", "floor_bw"], [13, 0, 1, "", "floor_div"], [13, 0, 1, "", "frac_bw"], [13, 0, 1, "", "full"], [13, 0, 1, "", "full_like"], [13, 0, 1, "", "ge_bw"], [13, 0, 1, "", "geglu"], [13, 0, 1, "", "gelu"], [13, 0, 1, "", "gelu_bw"], [13, 0, 1, "", "gez"], [13, 0, 1, "", "global_max"], [13, 0, 1, "", "global_mean"], [13, 0, 1, "", "global_min"], [13, 0, 1, "", "global_sum"], [13, 0, 1, "", "glu"], [13, 0, 1, "", "groupnorm"], [13, 0, 1, "", "gt_bw"], [13, 0, 1, "", "gtz"], [13, 0, 1, "", "hardshrink"], [13, 0, 1, "", "hardshrink_bw"], [13, 0, 1, "", "hardsigmoid"], [13, 0, 1, "", "hardsigmoid_bw"], [13, 0, 1, "", "hardswish"], [13, 0, 1, "", "hardswish_bw"], [13, 0, 1, "", "hardtanh"], [13, 0, 1, "", "hardtanh_bw"], [13, 0, 1, "", "heaviside"], [13, 0, 1, "", "hypot"], [13, 0, 1, "", "hypot_bw"], [13, 0, 1, "", "i0"], [13, 0, 1, "", "i0_bw"], [13, 0, 1, "", "identity"], [13, 0, 1, "", "imag"], [13, 0, 1, "", "imag_bw"], [13, 0, 1, "", "isclose"], [13, 0, 1, "", "isfinite"], [13, 0, 1, "", "isinf"], [13, 0, 1, "", "isnan"], [13, 0, 1, "", "isneginf"], [13, 0, 1, "", "isposinf"], [13, 0, 1, "", "lamb_optimizer"], [13, 0, 1, "", "layernorm"], [13, 0, 1, "", "ldexp_bw"], [13, 0, 1, "", "le_bw"], [13, 0, 1, "", "leaky_relu"], [13, 0, 1, "", "leaky_relu_bw"], [13, 0, 1, "", "left_shift"], [13, 0, 1, "", "lerp"], [13, 0, 1, "", "lerp_bw"], [13, 0, 1, "", "lez"], [13, 0, 1, "", "lgamma"], [13, 0, 1, "", "lgamma_bw"], [13, 0, 1, "", "log"], [13, 0, 1, "", "log10"], [13, 0, 1, "", "log10_bw"], [13, 0, 1, "", "log1p"], [13, 0, 1, "", "log1p_bw"], [13, 0, 1, "", "log2"], [13, 0, 1, "", "log2_bw"], [13, 0, 1, "", "log_bw"], [13, 0, 1, "", "log_sigmoid"], [13, 0, 1, "", "log_sigmoid_bw"], [13, 0, 1, "", "logaddexp2_bw"], [13, 0, 1, "", "logaddexp_bw"], [13, 0, 1, "", "logical_andi"], [13, 0, 1, "", "logical_not_unary"], [13, 0, 1, "", "logical_noti"], [13, 0, 1, "", "logical_ori"], [13, 0, 1, "", "logical_xor"], [13, 0, 1, "", "logical_xori"], [13, 0, 1, "", "logit"], [13, 0, 1, "", "logit_bw"], [13, 0, 1, "", "logiteps_bw"], [13, 0, 1, "", "lt_bw"], [13, 0, 1, "", "ltz"], [13, 0, 1, "", "mac"], [13, 0, 1, "", "maeloss"], [13, 0, 1, "", "matmul"], [13, 0, 1, "", "max_bw"], [13, 0, 1, "", "mean_hw"], [13, 0, 1, "", "min_bw"], [13, 0, 1, "", "mish"], [13, 0, 1, "", "mseloss"], [13, 0, 1, "", "mul_bw"], [13, 0, 1, "", "mul_unary"], [13, 0, 1, "", "multigammaln"], [13, 0, 1, "", "multigammaln_bw"], [13, 0, 1, "", "ne_bw"], [13, 0, 1, "", "neg"], [13, 0, 1, "", "neg_bw"], [13, 0, 1, "", "nextafter"], [13, 0, 1, "", "nez"], [13, 0, 1, "", "normalize_global"], [13, 0, 1, "", "normalize_hw"], [13, 0, 1, "", "ones"], [13, 0, 1, "", "ones_like"], [13, 0, 1, "", "pad"], [13, 0, 1, "", "permute"], [13, 0, 1, "", "polar"], [13, 0, 1, "", "polar_bw"], [13, 0, 1, "", "polygamma"], [13, 0, 1, "", "polygamma_bw"], [13, 0, 1, "", "polyval"], [13, 0, 1, "", "pow"], [13, 0, 1, "", "prod"], [13, 0, 1, "", "prod_bw"], [13, 0, 1, "", "rad2deg"], [13, 0, 1, "", "rad2deg_bw"], [13, 0, 1, "", "rdiv"], [13, 0, 1, "", "rdiv_bw"], [13, 0, 1, "", "real"], [13, 0, 1, "", "real_bw"], [13, 0, 1, "", "recip"], [13, 0, 1, "", "reciprocal_bw"], [13, 0, 1, "", "reduce"], [13, 0, 1, "", "reglu"], [13, 0, 1, "", "relu"], [13, 0, 1, "", "relu6"], [13, 0, 1, "", "relu6_bw"], [13, 0, 1, "", "relu_bw"], [13, 0, 1, "", "relu_max"], [13, 0, 1, "", "relu_min"], [13, 0, 1, "", "repeat"], [13, 0, 1, "", "repeat_bw"], [13, 0, 1, "", "repeat_interleave"], [13, 0, 1, "", "reshape"], [13, 0, 1, "", "right_shift"], [13, 0, 1, "", "rmsnorm"], [13, 0, 1, "", "round"], [13, 0, 1, "", "round_bw"], [13, 0, 1, "", "rpow"], [13, 0, 1, "", "rpow_bw"], [13, 0, 1, "", "rsqrt"], [13, 0, 1, "", "rsqrt_bw"], [13, 0, 1, "", "rsub"], [13, 0, 1, "", "rsub_bw"], [13, 0, 1, "", "selu_bw"], [13, 0, 1, "", "sigmoid"], [13, 0, 1, "", "sigmoid_accurate"], [13, 0, 1, "", "sign"], [13, 0, 1, "", "sign_bw"], [13, 0, 1, "", "signbit"], [13, 0, 1, "", "silu"], [13, 0, 1, "", "silu_bw"], [13, 0, 1, "", "sin"], [13, 0, 1, "", "sin_bw"], [13, 0, 1, "", "sinh"], [13, 0, 1, "", "sinh_bw"], [13, 0, 1, "", "softplus"], [13, 0, 1, "", "softplus_bw"], [13, 0, 1, "", "softshrink"], [13, 0, 1, "", "softshrink_bw"], [13, 0, 1, "", "softsign"], [13, 0, 1, "", "softsign_bw"], [13, 0, 1, "", "split_last_dim_two_chunks_tiled"], [13, 0, 1, "", "sqrt"], [13, 0, 1, "", "sqrt_bw"], [13, 0, 1, "", "square"], [13, 0, 1, "", "square_bw"], [13, 0, 1, "", "squared_difference_bw"], [13, 0, 1, "", "std_hw"], [13, 0, 1, "", "sub_bw"], [13, 0, 1, "", "sub_unary"], [13, 0, 1, "", "subalpha"], [13, 0, 1, "", "subalpha_bw"], [13, 0, 1, "", "sum"], [13, 0, 1, "", "swiglu"], [13, 0, 1, "", "swish"], [13, 0, 1, "", "tan"], [13, 0, 1, "", "tan_bw"], [13, 0, 1, "", "tanh"], [13, 0, 1, "", "tanh_bw"], [13, 0, 1, "", "tanhshrink"], [13, 0, 1, "", "tanhshrink_bw"], [13, 0, 1, "", "threshold"], [13, 0, 1, "", "threshold_bw"], [13, 0, 1, "", "tiled_prod"], [13, 0, 1, "", "tilize"], [13, 0, 1, "", "tilize_with_val_padding"], [13, 0, 1, "", "tilize_with_zero_padding"], [13, 0, 1, "", "transpose"], [13, 0, 1, "", "tril"], [13, 0, 1, "", "triu"], [13, 0, 1, "", "trunc"], [13, 0, 1, "", "trunc_bw"], [13, 0, 1, "", "typecast"], [13, 0, 1, "", "unary_add_bw"], [13, 0, 1, "", "unary_assign_bw"], [13, 0, 1, "", "unary_div_bw"], [13, 0, 1, "", "unary_div_no_nan_bw"], [13, 0, 1, "", "unary_eq_bw"], [13, 0, 1, "", "unary_fmod_bw"], [13, 0, 1, "", "unary_gt"], [13, 0, 1, "", "unary_lt"], [13, 0, 1, "", "unary_mul_bw"], [13, 0, 1, "", "unary_ne"], [13, 0, 1, "", "unary_pow_bw"], [13, 0, 1, "", "unary_remainder_bw"], [13, 0, 1, "", "unary_sub_bw"], [13, 0, 1, "", "unpad"], [13, 0, 1, "", "untilize"], [13, 0, 1, "", "untilize_with_unpadding"], [13, 0, 1, "", "var_hw"], [13, 0, 1, "", "where"], [13, 0, 1, "", "where_bw"], [13, 0, 1, "", "xlogy"], [13, 0, 1, "", "xlogy_bw"], [13, 0, 1, "", "zeros"], [13, 0, 1, "", "zeros_like"]], "tt_lib.tensor.MemoryConfig": [[12, 2, 1, "", "__init__"]], "tt_lib.tensor.Tensor": [[12, 2, 1, "", "__init__"], [12, 2, 1, "", "buffer"], [13, 0, 1, "", "cpu"], [12, 2, 1, "", "device"], [12, 2, 1, "", "get_dtype"], [12, 2, 1, "", "get_layout"], [12, 2, 1, "", "get_legacy_shape"], [12, 2, 1, "", "pad"], [12, 2, 1, "", "pad_to_tile"], [12, 2, 1, "", "storage_type"], [12, 2, 1, "", "to"], [12, 2, 1, "", "unpad"], [12, 2, 1, "", "unpad_from_tile"]], "ttnn": [[19, 1, 1, "", "MaxPool2d"], [18, 1, 1, "", "Shape"], [20, 0, 1, "", "abs"], [21, 0, 1, "", "acos"], [22, 0, 1, "", "acosh"], [23, 0, 1, "", "add"], [24, 0, 1, "", "addcdiv"], [25, 0, 1, "", "addcmul"], [26, 0, 1, "", "arange"], [27, 0, 1, "", "argmax"], [28, 0, 1, "", "as_tensor"], [29, 0, 1, "", "asin"], [30, 0, 1, "", "asinh"], [31, 0, 1, "", "atan"], [32, 0, 1, "", "atan2"], [33, 0, 1, "", "atanh"], [34, 0, 1, "", "cbrt"], [35, 0, 1, "", "celu"], [36, 0, 1, "", "clip"], [37, 0, 1, "", "clone"], [38, 0, 1, "", "close_device"], [39, 0, 1, "", "concat"], [40, 0, 1, "", "cos"], [41, 0, 1, "", "cosh"], [42, 0, 1, "", "create_sharded_memory_config"], [43, 0, 1, "", "deallocate"], [44, 0, 1, "", "deg2rad"], [45, 0, 1, "", "digamma"], [46, 0, 1, "", "dump_tensor"], [47, 0, 1, "", "elu"], [48, 0, 1, "", "embedding"], [49, 0, 1, "", "empty"], [50, 0, 1, "", "eq"], [51, 0, 1, "", "eqz"], [52, 0, 1, "", "erf"], [53, 0, 1, "", "erfc"], [54, 0, 1, "", "erfinv"], [55, 0, 1, "", "exp"], [56, 0, 1, "", "exp2"], [57, 0, 1, "", "expm1"], [58, 0, 1, "", "from_device"], [59, 0, 1, "", "from_torch"], [60, 0, 1, "", "full"], [61, 0, 1, "", "full_like"], [62, 0, 1, "", "ge"], [63, 0, 1, "", "geglu"], [64, 0, 1, "", "gelu"], [65, 0, 1, "", "gez"], [66, 0, 1, "", "global_avg_pool2d"], [67, 0, 1, "", "glu"], [68, 0, 1, "", "group_norm"], [69, 0, 1, "", "gt"], [70, 0, 1, "", "gtz"], [71, 0, 1, "", "hardshrink"], [72, 0, 1, "", "hardsigmoid"], [73, 0, 1, "", "hardswish"], [74, 0, 1, "", "hardtanh"], [75, 0, 1, "", "heaviside"], [76, 0, 1, "", "hypot"], [77, 0, 1, "", "i0"], [78, 0, 1, "", "isclose"], [79, 0, 1, "", "isfinite"], [80, 0, 1, "", "isinf"], [81, 0, 1, "", "isnan"], [82, 0, 1, "", "isneginf"], [83, 0, 1, "", "isposinf"], [86, 0, 1, "", "l1_loss"], [87, 0, 1, "", "layer_norm"], [88, 0, 1, "", "ldexp"], [89, 0, 1, "", "le"], [90, 0, 1, "", "leaky_relu"], [91, 0, 1, "", "lerp"], [92, 0, 1, "", "lez"], [93, 0, 1, "", "lgamma"], [94, 0, 1, "", "linear"], [95, 0, 1, "", "load_tensor"], [96, 0, 1, "", "log"], [97, 0, 1, "", "log10"], [98, 0, 1, "", "log1p"], [99, 0, 1, "", "log2"], [100, 0, 1, "", "log_sigmoid"], [101, 0, 1, "", "logaddexp"], [102, 0, 1, "", "logaddexp2"], [103, 0, 1, "", "logical_and"], [105, 0, 1, "", "logical_or"], [106, 0, 1, "", "logical_xor"], [107, 0, 1, "", "logit"], [108, 0, 1, "", "lt"], [109, 0, 1, "", "ltz"], [110, 0, 1, "", "mac"], [111, 0, 1, "", "manage_device"], [112, 0, 1, "", "matmul"], [113, 0, 1, "", "max"], [114, 0, 1, "", "maximum"], [115, 0, 1, "", "mean"], [116, 0, 1, "", "min"], [117, 0, 1, "", "minimum"], [118, 0, 1, "", "mish"], [121, 0, 1, "", "mse_loss"], [122, 0, 1, "", "multigammaln"], [123, 0, 1, "", "multiply"], [124, 0, 1, "", "ne"], [125, 0, 1, "", "neg"], [126, 0, 1, "", "nextafter"], [127, 0, 1, "", "nez"], [128, 0, 1, "", "ones"], [129, 0, 1, "", "ones_like"], [130, 0, 1, "", "open_device"], [131, 0, 1, "", "pad"], [132, 0, 1, "", "permute"], [133, 0, 1, "", "polygamma"], [134, 0, 1, "", "polyval"], [135, 0, 1, "", "pow"], [136, 0, 1, "", "prelu"], [137, 0, 1, "", "rad2deg"], [138, 0, 1, "", "reallocate"], [139, 0, 1, "", "reciprocal"], [140, 0, 1, "", "register_post_operation_hook"], [141, 0, 1, "", "register_pre_operation_hook"], [142, 0, 1, "", "reglu"], [143, 0, 1, "", "relu"], [144, 0, 1, "", "relu6"], [145, 0, 1, "", "repeat"], [146, 0, 1, "", "repeat_interleave"], [147, 0, 1, "", "reshape"], [148, 0, 1, "", "rms_norm"], [149, 0, 1, "", "rsqrt"], [150, 0, 1, "", "set_printoptions"], [151, 0, 1, "", "sigmoid"], [152, 0, 1, "", "sigmoid_accurate"], [153, 0, 1, "", "sign"], [154, 0, 1, "", "signbit"], [155, 0, 1, "", "silu"], [156, 0, 1, "", "sin"], [157, 0, 1, "", "sinh"], [158, 0, 1, "", "softmax"], [159, 0, 1, "", "softplus"], [160, 0, 1, "", "softshrink"], [161, 0, 1, "", "softsign"], [163, 0, 1, "", "sqrt"], [164, 0, 1, "", "square"], [165, 0, 1, "", "squared_difference"], [166, 0, 1, "", "std"], [167, 0, 1, "", "subtract"], [168, 0, 1, "", "sum"], [169, 0, 1, "", "swiglu"], [170, 0, 1, "", "swish"], [171, 0, 1, "", "synchronize_device"], [172, 0, 1, "", "tan"], [173, 0, 1, "", "tanh"], [174, 0, 1, "", "tanhshrink"], [175, 0, 1, "", "threshold"], [176, 0, 1, "", "to_device"], [177, 0, 1, "", "to_layout"], [178, 0, 1, "", "to_memory_config"], [179, 0, 1, "", "to_torch"], [186, 0, 1, "", "tril"], [187, 0, 1, "", "triu"], [188, 0, 1, "", "upsample"], [189, 0, 1, "", "var"], [190, 0, 1, "", "where"], [191, 0, 1, "", "xlogy"], [192, 0, 1, "", "zeros"], [193, 0, 1, "", "zeros_like"]], "ttnn.Shape": [[18, 3, 1, "", "rank"], [18, 2, 1, "", "with_tile_padding"]], "ttnn.kv_cache": [[84, 0, 1, "", "fill_cache_for_user_"], [85, 0, 1, "", "update_cache_for_token_"]], "ttnn.model_preprocessing": [[119, 0, 1, "", "preprocess_model"], [120, 0, 1, "", "preprocess_model_parameters"]], "ttnn.transformer": [[181, 0, 1, "", "attention_softmax"], [182, 0, 1, "", "attention_softmax_"], [183, 0, 1, "", "concatenate_heads"], [184, 0, 1, "", "rotary_embedding"], [185, 0, 1, "", "split_query_key_value_and_split_heads"]]}, "objtypes": {"0": "py:function", "1": "py:class", "2": "py:method", "3": "py:property"}, "objnames": {"0": ["py", "function", "Python function"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "property", "Python property"]}, "titleterms": {"welcom": 0, "tt": [0, 10, 12, 13, 14, 15], "nn": [0, 14, 15], "document": 0, "ttnn": [0, 5, 6, 8, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 195, 198, 201, 202, 204, 205, 206, 207, 209], "model": [0, 4, 7, 8, 14, 204, 205, 208], "resourc": 0, "indic": 0, "tabl": 0, "contribut": [1, 15], "develop": 1, "support": [2, 209], "report": [2, 7, 17], "bug": 2, "featur": [2, 5], "propos": 2, "request": 2, "troubleshoot": 2, "debug": [2, 209], "tip": 2, "commun": 2, "perform": [3, 203], "prerequisit": [3, 4], "run": [3, 4, 10, 204, 207, 209], "perf": [3, 17], "file": 3, "all": [3, 209], "get": [4, 14, 207], "start": [4, 14, 15], "an": [4, 209], "exampl": [4, 8, 10, 12, 209], "next": 4, "step": [4, 8, 15], "what": 5, "i": 5, "kei": 5, "ad": 6, "new": [6, 13, 16], "oper": [6, 7, 8, 13, 17, 196, 200, 202, 205, 206, 209], "c": 6, "implement": [6, 204, 207], "add": [6, 23, 200, 202], "pybind": 6, "unit": 6, "test": 6, "sweep": 6, "api": [7, 12, 13, 18], "devic": [7, 10, 13, 202, 203, 204, 209], "memori": [7, 18], "config": [7, 18, 203], "core": 7, "tensor": [7, 10, 12, 13, 18, 20, 21, 23, 27, 29, 31, 40, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 62, 64, 65, 66, 68, 69, 70, 75, 77, 79, 80, 81, 82, 83, 87, 88, 89, 90, 92, 96, 97, 99, 100, 101, 102, 103, 105, 108, 109, 113, 115, 116, 123, 124, 125, 127, 139, 143, 144, 145, 146, 148, 149, 151, 153, 154, 155, 156, 158, 159, 163, 164, 165, 166, 167, 168, 172, 173, 177, 178, 181, 182, 183, 184, 188, 189, 200, 202, 203, 209], "creation": [7, 13], "matrix": [7, 13, 203], "multipl": [7, 18, 203], "pointwis": 7, "unari": 7, "binari": 7, "ternari": [7, 13], "loss": [7, 13], "reduct": 7, "data": [7, 18, 202], "movement": 7, "normal": 7, "transform": [7, 181, 182, 183, 184, 185], "embed": [7, 48], "pool": 7, "vision": 7, "kv": 7, "cach": [7, 13, 203, 204, 209], "convers": 7, "hook": [7, 209], "convert": [8, 12, 202, 204, 209], "torch": [8, 195, 202, 203, 204, 205, 207, 209], "1": [8, 14, 15, 23, 48, 50, 62, 69, 87, 88, 89, 101, 102, 103, 105, 108, 123, 124, 148, 165, 167, 181, 182, 184, 209], "rewrit": 8, "2": [8, 13, 14, 15, 87, 184, 208, 209], "switch": 8, "3": [8, 14, 15, 87, 209], "optim": [8, 14, 204], "more": [8, 203], "build": [9, 14, 208], "uplift": 9, "demo": [9, 14], "lib": [10, 13], "us": [10, 15, 202, 203, 204, 205, 209], "one": 10, "op": 10, "from": [10, 13, 14, 15, 207, 208, 209], "acceler": 10, "pytorch": [10, 12, 208], "odd": 10, "size": 10, "last": 10, "dim": 10, "depend": [11, 15], "overview": [12, 13], "storag": [12, 18, 202], "memoryconfig": 12, "between": 12, "infrastructur": 13, "member": 13, "option": [13, 15], "input": [13, 20, 21, 23, 27, 29, 31, 40, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 62, 64, 65, 66, 68, 69, 70, 75, 77, 79, 80, 81, 82, 83, 87, 88, 89, 90, 92, 96, 97, 99, 100, 101, 102, 103, 105, 108, 109, 113, 115, 116, 123, 124, 125, 127, 139, 143, 144, 145, 146, 148, 149, 151, 153, 154, 155, 156, 158, 159, 163, 164, 165, 166, 167, 168, 172, 173, 177, 178, 181, 182, 183, 184, 188, 189], "output": [13, 202, 203, 204], "host": [13, 202], "profil": [13, 17, 198, 206], "fast": 13, "dispatch": 13, "program": [13, 203, 204, 209], "log": [13, 96, 209], "through": 13, "tt_lib": [13, 209], "primari": 13, "enum": 13, "elementwis": 13, "relat": 13, "math": 13, "broadcast": 13, "reduc": 13, "fallback": [13, 209], "experiment": 13, "fuse": 13, "mini": 13, "graph": [13, 195, 207, 208, 209], "librari": [13, 208], "complex": 13, "type": [13, 18, 202], "other": 13, "backward": 13, "function": [13, 16, 205], "instal": [14, 15], "explor": 14, "our": 14, "tutori": [14, 194], "multi": [14, 197, 204], "head": [14, 197, 204], "attent": [14, 197, 204], "simpl": 14, "4": [14, 15, 209], "where": [14, 190], "go": 14, "here": 14, "driver": 15, "firmwar": 15, "system": 15, "level": 15, "hugepag": 15, "metalium": 15, "sourc": 15, "wheel": 15, "5": [15, 209], "softwar": 15, "codebas": 15, "onboard": 16, "header": 17, "profile_thi": 17, "descript": 17, "shape": 18, "layout": [18, 202, 203], "requir": 18, "width": 18, "shard": 18, "maxpool2d": 19, "ab": 20, "0": [20, 21, 23, 27, 29, 31, 40, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 62, 64, 65, 66, 68, 69, 70, 75, 77, 79, 80, 81, 82, 83, 87, 88, 89, 90, 92, 96, 97, 99, 100, 101, 102, 103, 105, 108, 109, 113, 115, 116, 123, 124, 125, 127, 139, 143, 144, 145, 146, 148, 149, 151, 153, 154, 155, 156, 158, 159, 163, 164, 165, 166, 167, 168, 172, 173, 177, 178, 181, 182, 183, 184, 188, 189], "aco": 21, "acosh": 22, "addcdiv": 24, "addcmul": 25, "arang": 26, "argmax": 27, "as_tensor": 28, "asin": 29, "asinh": 30, "atan": 31, "atan2": 32, "atanh": 33, "cbrt": 34, "celu": 35, "clip": 36, "clone": [37, 208], "close_devic": 38, "concat": 39, "co": 40, "cosh": 41, "create_sharded_memory_config": 42, "dealloc": 43, "deg2rad": 44, "digamma": 45, "dump_tensor": 46, "elu": 47, "empti": 49, "eq": 50, "eqz": 51, "erf": 52, "erfc": 53, "erfinv": 54, "exp": 55, "exp2": 56, "expm1": 57, "from_devic": 58, "from_torch": 59, "full": 60, "full_lik": 61, "ge": 62, "geglu": 63, "gelu": 64, "gez": 65, "global_avg_pool2d": 66, "glu": 67, "group_norm": 68, "gt": 69, "gtz": 70, "hardshrink": 71, "hardsigmoid": 72, "hardswish": 73, "hardtanh": 74, "heavisid": 75, "hypot": 76, "i0": 77, "isclos": 78, "isfinit": 79, "isinf": 80, "isnan": 81, "isneginf": 82, "isposinf": 83, "kv_cach": [84, 85], "fill_cache_for_user_": 84, "update_cache_for_token_": 85, "l1_loss": 86, "layer_norm": 87, "ldexp": 88, "le": 89, "leaky_relu": 90, "lerp": 91, "lez": 92, "lgamma": 93, "linear": 94, "load_tensor": 95, "log10": 97, "log1p": 98, "log2": 99, "log_sigmoid": 100, "logaddexp": 101, "logaddexp2": 102, "logical_and": 103, "logical_not": 104, "logical_or": 105, "logical_xor": 106, "logit": 107, "lt": 108, "ltz": 109, "mac": 110, "manage_devic": 111, "matmul": [112, 196], "max": 113, "maximum": 114, "mean": 115, "min": 116, "minimum": 117, "mish": 118, "model_preprocess": [119, 120], "preprocess_model": 119, "preprocess_model_paramet": 120, "mse_loss": 121, "multigammaln": 122, "multipli": [123, 203], "ne": 124, "neg": 125, "nextaft": 126, "nez": 127, "ones": 128, "ones_lik": 129, "open_devic": 130, "pad": 131, "permut": 132, "polygamma": 133, "polyv": 134, "pow": 135, "prelu": 136, "rad2deg": 137, "realloc": 138, "reciproc": 139, "register_post_operation_hook": 140, "register_pre_operation_hook": 141, "reglu": 142, "relu": 143, "relu6": 144, "repeat": 145, "repeat_interleav": 146, "reshap": 147, "rms_norm": 148, "rsqrt": 149, "set_printopt": 150, "sigmoid": 151, "sigmoid_accur": 152, "sign": 153, "signbit": 154, "silu": 155, "sin": 156, "sinh": 157, "softmax": 158, "softplu": 159, "softshrink": 160, "softsign": 161, "split": 162, "sqrt": 163, "squar": 164, "squared_differ": 165, "std": 166, "subtract": 167, "sum": 168, "swiglu": 169, "swish": 170, "synchronize_devic": 171, "tan": 172, "tanh": 173, "tanhshrink": 174, "threshold": 175, "to_devic": 176, "to_layout": 177, "to_memory_config": 178, "to_torch": 179, "topk": 180, "attention_softmax": 181, "attention_softmax_": 182, "concatenate_head": 183, "rotary_embed": 184, "split_query_key_value_and_split_head": 185, "tril": 186, "triu": 187, "upsampl": 188, "var": 189, "xlogi": 191, "zero": 192, "zeros_lik": 193, "dit_xl_2": 195, "With": 195, "resnet": [199, 207], "basic": [199, 209], "block": [199, 207], "tracer": 201, "creat": [202, 207], "borrow": 202, "v": 202, "own": 202, "open": 202, "initi": [202, 203, 204], "b": [202, 203], "random": [202, 203], "valu": [202, 203], "inspect": [202, 203], "attribut": 202, "close": [202, 203, 204], "enabl": [203, 204, 209], "configur": [203, 204], "result": 203, "write": 204, "activ": 204, "weight": 204, "first": 204, "iter": 204, "subsequ": 204, "version": [204, 207], "pre": [204, 208, 209], "process": 204, "paramet": [204, 207], "check": 204, "match": 204, "origin": 204, "trace": [205, 207, 209], "modul": [205, 207], "written": 205, "torchvis": 207, "preprocess": 207, "displai": [207, 208], "pass": 207, "constructor": 207, "base": 208, "http": 208, "github": 208, "com": 208, "facebookresearch": 208, "dit": 208, "git": 208, "download": 208, "xl": 208, "sampl": 208, "train": 208, "__getitem__": 209, "slice": 209, "intermedi": 209, "6": 209, "7": 209, "8": 209, "9": 209, "python": 209, "10": 209, "chang": 209, "string": 209, "represent": 209, "11": 209, "visual": 209, "web": 209, "browser": 209, "12": 209, "regist": 209, "post": 209, "13": 209, "queri": 209, "14": 209, "disabl": 209, "placehold": 210, "titl": 210}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "nbsphinx": 4, "sphinx": 58}, "alltitles": {"Welcome to TT-NN documentation!": [[0, "welcome-to-tt-nn-documentation"]], "TTNN": [[0, null]], "Models": [[0, null]], "Resources": [[0, null]], "Indices and tables": [[0, "indices-and-tables"]], "Contributing as a developer": [[1, "contributing-as-a-developer"]], "Support": [[2, "support"]], "Reporting bugs, feature proposals, or support requests": [[2, "reporting-bugs-feature-proposals-or-support-requests"]], "Troubleshooting and debugging tips": [[2, "troubleshooting-and-debugging-tips"]], "Community": [[2, "community"]], "Performance": [[3, "performance"]], "Prerequisites": [[3, "prerequisites"], [4, "prerequisites"]], "Running a perf file": [[3, "running-a-perf-file"]], "Running all the perf files": [[3, "running-all-the-perf-files"]], "Getting Started": [[4, "getting-started"], [14, "getting-started"]], "Running an example model": [[4, "running-an-example-model"]], "Next steps": [[4, "next-steps"]], "What is ttnn?": [[5, "what-is-ttnn"]], "Key features of ttnn": [[5, "key-features-of-ttnn"]], "Adding New ttnn Operation": [[6, "adding-new-ttnn-operation"]], "C++ Implementation": [[6, "c-implementation"]], "Add pybindings": [[6, "add-pybindings"]], "Adding a unit test": [[6, "adding-a-unit-test"]], "Adding a sweep test": [[6, "adding-a-sweep-test"]], "APIs": [[7, "apis"], [18, "apis"]], "Device": [[7, "device"]], "Memory Config": [[7, "memory-config"], [18, "memory-config"]], "Operations": [[7, "operations"]], "Core": [[7, "core"]], "Tensor Creation": [[7, "tensor-creation"]], "Matrix Multiplication": [[7, "matrix-multiplication"], [203, "Matrix-Multiplication"]], "Pointwise Unary": [[7, "pointwise-unary"]], "Pointwise Binary": [[7, "pointwise-binary"]], "Pointwise Ternary": [[7, "pointwise-ternary"]], "Losses": [[7, "losses"]], "Reduction": [[7, "reduction"]], "Data Movement": [[7, "data-movement"]], "Normalization": [[7, "normalization"]], "Transformer": [[7, "transformer"]], "Embedding": [[7, "embedding"]], "Pooling": [[7, "pooling"]], "Vision": [[7, "vision"]], "KV Cache": [[7, "kv-cache"]], "Model Conversion": [[7, "model-conversion"]], "Reports": [[7, "reports"]], "Operation Hooks": [[7, "operation-hooks"]], "Converting torch Model to ttnn": [[8, "converting-torch-model-to-ttnn"]], "Step 1 - Rewriting the Model": [[8, "step-1-rewriting-the-model"]], "Step 2 - Switching to ttnn Operations": [[8, "step-2-switching-to-ttnn-operations"]], "Step 3 - Optimizing the Model": [[8, "step-3-optimizing-the-model"]], "More examples": [[8, "more-examples"]], "Building and Uplifting Demos": [[9, "building-and-uplifting-demos"]], "Examples of Tensor and TT-LIB Use": [[10, "examples-of-tensor-and-tt-lib-use"]], "Run one OP from TT-LIB on TT Accelerator device": [[10, "run-one-op-from-tt-lib-on-tt-accelerator-device"]], "Run TT-LIB and PyTorch OPs": [[10, "run-tt-lib-and-pytorch-ops"]], "Tensors with odd size of last dim": [[10, "tensors-with-odd-size-of-last-dim"]], "Dependencies": [[11, "dependencies"]], "Tensor": [[12, "tensor"], [18, "tensor"]], "Overview": [[12, "overview"], [13, "overview"]], "Tensor Storage": [[12, "tensor-storage"]], "Tensor API": [[12, "tensor-api"]], "MemoryConfig": [[12, "memoryconfig"]], "Examples of converting between PyTorch Tensor and TT Tensor": [[12, "examples-of-converting-between-pytorch-tensor-and-tt-tensor"]], "Converting a PyTorch Tensor to a TT Tensor": [[12, "converting-a-pytorch-tensor-to-a-tt-tensor"]], "Converting a TT Tensor to a PyTorch Tensor": [[12, "converting-a-tt-tensor-to-a-pytorch-tensor"]], "TT-LIB": [[13, "tt-lib"]], "Operation Infrastructure": [[13, "operation-infrastructure"]], "New Device Operation": [[13, "new-device-operation"]], "New Device Operation with a member": [[13, "new-device-operation-with-a-member"]], "New Device Operation with Optional Input Tensors": [[13, "new-device-operation-with-optional-input-tensors"]], "New Device Operation with Optional Output Tensors": [[13, "new-device-operation-with-optional-output-tensors"]], "New Host Operation": [[13, "new-host-operation"]], "Profiler": [[13, "profiler"]], "Fast Dispatch": [[13, "fast-dispatch"]], "Program Caching": [[13, "program-caching"]], "Logs": [[13, "logs"]], "TT-LIB API through tt_lib": [[13, "tt-lib-api-through-tt-lib"]], "Primary Operations": [[13, "primary-operations"]], "Enums": [[13, "enums"]], "Tensor elementwise operations": [[13, "tensor-elementwise-operations"]], "Tensor relational operations": [[13, "tensor-relational-operations"]], "Tensor ternary operations": [[13, "tensor-ternary-operations"]], "Tensor matrix math operations": [[13, "tensor-matrix-math-operations"]], "Tensor creation operations": [[13, "tensor-creation-operations"]], "Broadcast and Reduce": [[13, "broadcast-and-reduce"]], "Fallback Operations": [[13, "fallback-operations"]], "Experimental Operations": [[13, "experimental-operations"]], "Fused Operations from tt_lib Mini-Graph Library": [[13, "fused-operations-from-tt-lib-mini-graph-library"]], "Complex Operations": [[13, "complex-operations"]], "Complex Operations (Type 2)": [[13, "complex-operations-type-2"]], "Other Operations": [[13, "other-operations"]], "Backward Operations": [[13, "backward-operations"]], "Loss Functions": [[13, "loss-functions"]], "1. Install and Build": [[14, "install-and-build"]], "2. Explore our model demos": [[14, "explore-our-model-demos"]], "3. TT-NN Tutorial: Multi-Head Attention (Simple)": [[14, "tt-nn-tutorial-multi-head-attention-simple"]], "4. TT-NN Tutorial: Multi-Head Attention (Optimized)": [[14, "tt-nn-tutorial-multi-head-attention-optimized"]], "Where to go from here": [[14, "where-to-go-from-here"]], "Install": [[15, "install"]], "Installation Steps": [[15, "installation-steps"]], "Step 1. Driver & Firmware": [[15, "step-1-driver-firmware"]], "Step 2. System-level dependencies": [[15, "step-2-system-level-dependencies"]], "Step 3. Hugepages": [[15, "step-3-hugepages"]], "Step 4. Install and start using TT-NN and TT-Metalium!": [[15, "step-4-install-and-start-using-tt-nn-and-tt-metalium"]], "Option 1: From source": [[15, "option-1-from-source"]], "Option 2: From wheel": [[15, "option-2-from-wheel"]], "Step 5. (Optional) Software dependencies for codebase contributions": [[15, "step-5-optional-software-dependencies-for-codebase-contributions"]], "Onboarding New Functionality": [[16, "onboarding-new-functionality"]], "Profiling ttnn Operations": [[17, "profiling-ttnn-operations"]], "Perf Report Headers": [[17, "perf-report-headers"]], "profile_this description": [[17, "profile-this-description"]], "Shape": [[18, "shape"]], "Layout": [[18, "layout"], [202, "Layout"]], "Data Type": [[18, "data-type"], [202, "Data-Type"]], "Required Width Multiples for Data Types": [[18, "id5"]], "Storage": [[18, "storage"]], "Tensor Sharding": [[18, "tensor-sharding"]], "ttnn.MaxPool2d": [[19, "ttnn-maxpool2d"]], "ttnn.abs": [[20, "ttnn-abs"]], "Input Tensor 0": [[20, "id2"], [21, "id2"], [23, "id2"], [27, "id2"], [29, "id2"], [31, "id2"], [40, "id2"], [47, "id2"], [48, "id2"], [50, "id2"], [51, "id2"], [52, "id2"], [53, "id2"], [54, "id2"], [55, "id2"], [56, "id2"], [57, "id2"], [62, "id2"], [64, "id2"], [65, "id2"], [66, "id2"], [68, "id2"], [69, "id2"], [70, "id2"], [75, "id2"], [77, "id2"], [79, "id2"], [80, "id2"], [81, "id2"], [82, "id2"], [83, "id2"], [87, "id2"], [88, "id2"], [89, "id2"], [90, "id2"], [92, "id2"], [96, "id2"], [97, "id2"], [99, "id2"], [100, "id2"], [101, "id2"], [102, "id2"], [103, "id2"], [105, "id2"], [108, "id2"], [109, "id2"], [113, "id2"], [115, "id2"], [116, "id2"], [123, "id2"], [124, "id2"], [125, "id2"], [127, "id2"], [139, "id2"], [143, "id2"], [144, "id2"], [145, "id2"], [146, "id2"], [148, "id2"], [149, "id2"], [151, "id2"], [153, "id2"], [154, "id2"], [155, "id2"], [156, "id2"], [158, "id2"], [159, "id2"], [163, "id2"], [164, "id2"], [165, "id2"], [166, "id2"], [167, "id2"], [168, "id2"], [172, "id2"], [173, "id2"], [177, "id2"], [178, "id2"], [181, "id2"], [182, "id2"], [183, "id2"], [184, "id2"], [188, "id2"], [189, "id2"]], "ttnn.acos": [[21, "ttnn-acos"]], "ttnn.acosh": [[22, "ttnn-acosh"]], "ttnn.add": [[23, "ttnn-add"]], "Input Tensor 1": [[23, "id3"], [48, "id3"], [50, "id3"], [62, "id3"], [69, "id3"], [87, "id3"], [88, "id3"], [89, "id3"], [101, "id3"], [102, "id3"], [103, "id3"], [105, "id3"], [108, "id3"], [123, "id3"], [124, "id3"], [148, "id3"], [165, "id3"], [167, "id3"], [181, "id3"], [182, "id3"], [184, "id3"]], "ttnn.addcdiv": [[24, "ttnn-addcdiv"]], "ttnn.addcmul": [[25, "ttnn-addcmul"]], "ttnn.arange": [[26, "ttnn-arange"]], "ttnn.argmax": [[27, "ttnn-argmax"]], "ttnn.as_tensor": [[28, "ttnn-as-tensor"]], "ttnn.asin": [[29, "ttnn-asin"]], "ttnn.asinh": [[30, "ttnn-asinh"]], "ttnn.atan": [[31, "ttnn-atan"]], "ttnn.atan2": [[32, "ttnn-atan2"]], "ttnn.atanh": [[33, "ttnn-atanh"]], "ttnn.cbrt": [[34, "ttnn-cbrt"]], "ttnn.celu": [[35, "ttnn-celu"]], "ttnn.clip": [[36, "ttnn-clip"]], "ttnn.clone": [[37, "ttnn-clone"]], "ttnn.close_device": [[38, "ttnn-close-device"]], "ttnn.concat": [[39, "ttnn-concat"]], "ttnn.cos": [[40, "ttnn-cos"]], "ttnn.cosh": [[41, "ttnn-cosh"]], "ttnn.create_sharded_memory_config": [[42, "ttnn-create-sharded-memory-config"]], "ttnn.deallocate": [[43, "ttnn-deallocate"]], "ttnn.deg2rad": [[44, "ttnn-deg2rad"]], "ttnn.digamma": [[45, "ttnn-digamma"]], "ttnn.dump_tensor": [[46, "ttnn-dump-tensor"]], "ttnn.elu": [[47, "ttnn-elu"]], "ttnn.embedding": [[48, "ttnn-embedding"]], "ttnn.empty": [[49, "ttnn-empty"]], "ttnn.eq": [[50, "ttnn-eq"]], "ttnn.eqz": [[51, "ttnn-eqz"]], "ttnn.erf": [[52, "ttnn-erf"]], "ttnn.erfc": [[53, "ttnn-erfc"]], "ttnn.erfinv": [[54, "ttnn-erfinv"]], "ttnn.exp": [[55, "ttnn-exp"]], "ttnn.exp2": [[56, "ttnn-exp2"]], "ttnn.expm1": [[57, "ttnn-expm1"]], "ttnn.from_device": [[58, "ttnn-from-device"]], "ttnn.from_torch": [[59, "ttnn-from-torch"]], "ttnn.full": [[60, "ttnn-full"]], "ttnn.full_like": [[61, "ttnn-full-like"]], "ttnn.ge": [[62, "ttnn-ge"]], "ttnn.geglu": [[63, "ttnn-geglu"]], "ttnn.gelu": [[64, "ttnn-gelu"]], "ttnn.gez": [[65, "ttnn-gez"]], "ttnn.global_avg_pool2d": [[66, "ttnn-global-avg-pool2d"]], "ttnn.glu": [[67, "ttnn-glu"]], "ttnn.group_norm": [[68, "ttnn-group-norm"]], "ttnn.gt": [[69, "ttnn-gt"]], "ttnn.gtz": [[70, "ttnn-gtz"]], "ttnn.hardshrink": [[71, "ttnn-hardshrink"]], "ttnn.hardsigmoid": [[72, "ttnn-hardsigmoid"]], "ttnn.hardswish": [[73, "ttnn-hardswish"]], "ttnn.hardtanh": [[74, "ttnn-hardtanh"]], "ttnn.heaviside": [[75, "ttnn-heaviside"]], "ttnn.hypot": [[76, "ttnn-hypot"]], "ttnn.i0": [[77, "ttnn-i0"]], "ttnn.isclose": [[78, "ttnn-isclose"]], "ttnn.isfinite": [[79, "ttnn-isfinite"]], "ttnn.isinf": [[80, "ttnn-isinf"]], "ttnn.isnan": [[81, "ttnn-isnan"]], "ttnn.isneginf": [[82, "ttnn-isneginf"]], "ttnn.isposinf": [[83, "ttnn-isposinf"]], "ttnn.kv_cache.fill_cache_for_user_": [[84, "ttnn-kv-cache-fill-cache-for-user"]], "ttnn.kv_cache.update_cache_for_token_": [[85, "ttnn-kv-cache-update-cache-for-token"]], "ttnn.l1_loss": [[86, "ttnn-l1-loss"]], "ttnn.layer_norm": [[87, "ttnn-layer-norm"]], "Input Tensor 2": [[87, "id4"], [184, "id4"]], "Input Tensor 3": [[87, "id5"]], "ttnn.ldexp": [[88, "ttnn-ldexp"]], "ttnn.le": [[89, "ttnn-le"]], "ttnn.leaky_relu": [[90, "ttnn-leaky-relu"]], "ttnn.lerp": [[91, "ttnn-lerp"]], "ttnn.lez": [[92, "ttnn-lez"]], "ttnn.lgamma": [[93, "ttnn-lgamma"]], "ttnn.linear": [[94, "ttnn-linear"]], "ttnn.load_tensor": [[95, "ttnn-load-tensor"]], "ttnn.log": [[96, "ttnn-log"]], "ttnn.log10": [[97, "ttnn-log10"]], "ttnn.log1p": [[98, "ttnn-log1p"]], "ttnn.log2": [[99, "ttnn-log2"]], "ttnn.log_sigmoid": [[100, "ttnn-log-sigmoid"]], "ttnn.logaddexp": [[101, "ttnn-logaddexp"]], "ttnn.logaddexp2": [[102, "ttnn-logaddexp2"]], "ttnn.logical_and": [[103, "ttnn-logical-and"]], "ttnn.logical_not": [[104, "ttnn-logical-not"]], "ttnn.logical_or": [[105, "ttnn-logical-or"]], "ttnn.logical_xor": [[106, "ttnn-logical-xor"]], "ttnn.logit": [[107, "ttnn-logit"]], "ttnn.lt": [[108, "ttnn-lt"]], "ttnn.ltz": [[109, "ttnn-ltz"]], "ttnn.mac": [[110, "ttnn-mac"]], "ttnn.manage_device": [[111, "ttnn-manage-device"]], "ttnn.matmul": [[112, "ttnn-matmul"]], "ttnn.max": [[113, "ttnn-max"]], "ttnn.maximum": [[114, "ttnn-maximum"]], "ttnn.mean": [[115, "ttnn-mean"]], "ttnn.min": [[116, "ttnn-min"]], "ttnn.minimum": [[117, "ttnn-minimum"]], "ttnn.mish": [[118, "ttnn-mish"]], "ttnn.model_preprocessing.preprocess_model": [[119, "ttnn-model-preprocessing-preprocess-model"]], "ttnn.model_preprocessing.preprocess_model_parameters": [[120, "ttnn-model-preprocessing-preprocess-model-parameters"]], "ttnn.mse_loss": [[121, "ttnn-mse-loss"]], "ttnn.multigammaln": [[122, "ttnn-multigammaln"]], "ttnn.multiply": [[123, "ttnn-multiply"]], "ttnn.ne": [[124, "ttnn-ne"]], "ttnn.neg": [[125, "ttnn-neg"]], "ttnn.nextafter": [[126, "ttnn-nextafter"]], "ttnn.nez": [[127, "ttnn-nez"]], "ttnn.ones": [[128, "ttnn-ones"]], "ttnn.ones_like": [[129, "ttnn-ones-like"]], "ttnn.open_device": [[130, "ttnn-open-device"]], "ttnn.pad": [[131, "ttnn-pad"]], "ttnn.permute": [[132, "ttnn-permute"]], "ttnn.polygamma": [[133, "ttnn-polygamma"]], "ttnn.polyval": [[134, "ttnn-polyval"]], "ttnn.pow": [[135, "ttnn-pow"]], "ttnn.prelu": [[136, "ttnn-prelu"]], "ttnn.rad2deg": [[137, "ttnn-rad2deg"]], "ttnn.reallocate": [[138, "ttnn-reallocate"]], "ttnn.reciprocal": [[139, "ttnn-reciprocal"]], "ttnn.register_post_operation_hook": [[140, "ttnn-register-post-operation-hook"]], "ttnn.register_pre_operation_hook": [[141, "ttnn-register-pre-operation-hook"]], "ttnn.reglu": [[142, "ttnn-reglu"]], "ttnn.relu": [[143, "ttnn-relu"]], "ttnn.relu6": [[144, "ttnn-relu6"]], "ttnn.repeat": [[145, "ttnn-repeat"]], "ttnn.repeat_interleave": [[146, "ttnn-repeat-interleave"]], "ttnn.reshape": [[147, "ttnn-reshape"]], "ttnn.rms_norm": [[148, "ttnn-rms-norm"]], "ttnn.rsqrt": [[149, "ttnn-rsqrt"]], "ttnn.set_printoptions": [[150, "ttnn-set-printoptions"]], "ttnn.sigmoid": [[151, "ttnn-sigmoid"]], "ttnn.sigmoid_accurate": [[152, "ttnn-sigmoid-accurate"]], "ttnn.sign": [[153, "ttnn-sign"]], "ttnn.signbit": [[154, "ttnn-signbit"]], "ttnn.silu": [[155, "ttnn-silu"]], "ttnn.sin": [[156, "ttnn-sin"]], "ttnn.sinh": [[157, "ttnn-sinh"]], "ttnn.softmax": [[158, "ttnn-softmax"]], "ttnn.softplus": [[159, "ttnn-softplus"]], "ttnn.softshrink": [[160, "ttnn-softshrink"]], "ttnn.softsign": [[161, "ttnn-softsign"]], "ttnn.split": [[162, "ttnn-split"]], "ttnn.sqrt": [[163, "ttnn-sqrt"]], "ttnn.square": [[164, "ttnn-square"]], "ttnn.squared_difference": [[165, "ttnn-squared-difference"]], "ttnn.std": [[166, "ttnn-std"]], "ttnn.subtract": [[167, "ttnn-subtract"]], "ttnn.sum": [[168, "ttnn-sum"]], "ttnn.swiglu": [[169, "ttnn-swiglu"]], "ttnn.swish": [[170, "ttnn-swish"]], "ttnn.synchronize_device": [[171, "ttnn-synchronize-device"]], "ttnn.tan": [[172, "ttnn-tan"]], "ttnn.tanh": [[173, "ttnn-tanh"]], "ttnn.tanhshrink": [[174, "ttnn-tanhshrink"]], "ttnn.threshold": [[175, "ttnn-threshold"]], "ttnn.to_device": [[176, "ttnn-to-device"]], "ttnn.to_layout": [[177, "ttnn-to-layout"]], "ttnn.to_memory_config": [[178, "ttnn-to-memory-config"]], "ttnn.to_torch": [[179, "ttnn-to-torch"]], "ttnn.topk": [[180, "ttnn-topk"]], "ttnn.transformer.attention_softmax": [[181, "ttnn-transformer-attention-softmax"]], "ttnn.transformer.attention_softmax_": [[182, "ttnn-transformer-attention-softmax"]], "ttnn.transformer.concatenate_heads": [[183, "ttnn-transformer-concatenate-heads"]], "ttnn.transformer.rotary_embedding": [[184, "ttnn-transformer-rotary-embedding"]], "ttnn.transformer.split_query_key_value_and_split_heads": [[185, "ttnn-transformer-split-query-key-value-and-split-heads"]], "ttnn.tril": [[186, "ttnn-tril"]], "ttnn.triu": [[187, "ttnn-triu"]], "ttnn.upsample": [[188, "ttnn-upsample"]], "ttnn.var": [[189, "ttnn-var"]], "ttnn.where": [[190, "ttnn-where"]], "ttnn.xlogy": [[191, "ttnn-xlogy"]], "ttnn.zeros": [[192, "ttnn-zeros"]], "ttnn.zeros_like": [[193, "ttnn-zeros-like"]], "Tutorials": [[194, "id1"]], "Graphing Torch DiT_XL_2 With TTNN": [[195, "graphing-torch-dit-xl-2-with-ttnn"]], "Matmul Operation": [[196, "matmul-operation"]], "Multi-Head Attention": [[197, "multi-head-attention"], [204, "Multi-Head-Attention"]], "ttnn Profiling": [[198, "ttnn-profiling"]], "Resnet Basic Block": [[199, "resnet-basic-block"]], "Tensor and Add Operation": [[200, "tensor-and-add-operation"], [202, "Tensor-and-Add-Operation"]], "ttnn Tracer": [[201, "ttnn-tracer"]], "Creating a tensor": [[202, "Creating-a-tensor"]], "Host Storage: Borrowed vs Owned": [[202, "Host-Storage:-Borrowed-vs-Owned"]], "Device storage": [[202, "Device-storage"]], "Open the device": [[202, "Open-the-device"]], "Initialize tensors a and b with random values using torch": [[202, "Initialize-tensors-a-and-b-with-random-values-using-torch"], [203, "Initialize-tensors-a-and-b-with-random-values-using-torch"]], "Add tensor a and b": [[202, "Add-tensor-a-and-b"]], "Inspect the output tensor of the add in ttnn": [[202, "Inspect-the-output-tensor-of-the-add-in-ttnn"]], "Convert to torch and inspect the attributes of the torch tensor": [[202, "Convert-to-torch-and-inspect-the-attributes-of-the-torch-tensor"]], "Close the device": [[202, "Close-the-device"], [203, "Close-the-device"], [204, "Close-the-device"]], "Enable program cache": [[203, "Enable-program-cache"], [204, "Enable-program-cache"]], "Configuration": [[203, "Configuration"], [204, "Configuration"]], "Matrix multiply tensor a and b": [[203, "Matrix-multiply-tensor-a-and-b"]], "Inspect the layout of matrix multiplication output": [[203, "Inspect-the-layout-of-matrix-multiplication-output"]], "Inspect the result of the matrix multiplication": [[203, "Inspect-the-result-of-the-matrix-multiplication"]], "Matrix multiply tensor a and b by using more performant config": [[203, "Matrix-multiply-tensor-a-and-b-by-using-more-performant-config"]], "Write Multi-Head Attention using ttnn": [[204, "Write-Multi-Head-Attention-using-ttnn"]], "Initialize activations and weights using torch": [[204, "Initialize-activations-and-weights-using-torch"]], "Convert activations and weights to ttnn": [[204, "Convert-activations-and-weights-to-ttnn"]], "Run the first iteration of Multi-Head Attention": [[204, "Run-the-first-iteration-of-Multi-Head-Attention"]], "Run a subsequent iteration of Multi-Head Attention": [[204, "Run-a-subsequent-iteration-of-Multi-Head-Attention"]], "Write optimized version of Multi-Head Attention": [[204, "Write-optimized-version-of-Multi-Head-Attention"]], "Pre-process the parameters of the optimized model": [[204, "Pre-process-the-parameters-of-the-optimized-model"]], "Run the first iteration of the optimized Multi-Head Attention": [[204, "Run-the-first-iteration-of-the-optimized-Multi-Head-Attention"]], "Run a subsequent iteration of the optimized Multi-Head Attention": [[204, "Run-a-subsequent-iteration-of-the-optimized-Multi-Head-Attention"]], "Check that the output of the optimized version matches the output of the original implementation": [[204, "Check-that-the-output-of-the-optimized-version-matches-the-output-of-the-original-implementation"]], "Tracing ttnn operations and torch modules/functions": [[205, "Tracing-ttnn-operations-and-torch-modules/functions"]], "Trace torch functions": [[205, "Trace-torch-functions"]], "Trace torch functions and ttnn operations": [[205, "Trace-torch-functions-and-ttnn-operations"]], "Trace torch functions, torch modules and ttnn operations": [[205, "Trace-torch-functions,-torch-modules-and-ttnn-operations"]], "Trace models written using ttnn": [[205, "Trace-models-written-using-ttnn"]], "Profiling ttnn operations": [[206, "Profiling-ttnn-operations"]], "Resnet Block": [[207, "Resnet-Block"]], "Torch Module (from torchvision)": [[207, "Torch-Module-(from-torchvision)"]], "Create torch module and preprocess it to get ttnn parameters": [[207, "Create-torch-module-and-preprocess-it-to-get-ttnn-parameters"]], "Display the parameters of the module": [[207, "Display-the-parameters-of-the-module"]], "Display the traced torch graph": [[207, "Display-the-traced-torch-graph"]], "Implement ttnn version of the module. Pass in the parameters into the constructor.": [[207, "Implement-ttnn-version-of-the-module.-Pass-in-the-parameters-into-the-constructor."]], "Run ttnn module and display the traced graph": [[207, "Run-ttnn-module-and-display-the-traced-graph"]], "Build a graph of a pytorch based model": [[208, "Build-a-graph-of-a-pytorch-based-model"]], "Clone the library from https://github.com/facebookresearch/DiT.git": [[208, "Clone-the-library-from-https://github.com/facebookresearch/DiT.git"]], "Download DiT-XL/2 Models": [[208, "Download-DiT-XL/2-Models"]], "Sample from Pre-trained DiT Models and build the graph": [[208, "Sample-from-Pre-trained-DiT-Models-and-build-the-graph"]], "Display the graph": [[208, "Display-the-graph"]], "Using ttnn": [[209, "using-ttnn"]], "Basic Examples": [[209, "basic-examples"]], "1. Converting from and to torch tensor": [[209, "converting-from-and-to-torch-tensor"]], "2. Running an operation on the device": [[209, "running-an-operation-on-the-device"]], "3. Using __getitem__ to slice the tensor": [[209, "using-getitem-to-slice-the-tensor"]], "4. Enabling program cache": [[209, "enabling-program-cache"]], "5. Debugging intermediate tensors": [[209, "debugging-intermediate-tensors"]], "6. Tracing the graph of operations": [[209, "tracing-the-graph-of-operations"]], "7. Using tt_lib operation in ttnn": [[209, "using-tt-lib-operation-in-ttnn"]], "8. Enabling Logging": [[209, "enabling-logging"]], "9. Supported Python Operators": [[209, "supported-python-operators"]], "10. Changing the string representation of the tensor": [[209, "changing-the-string-representation-of-the-tensor"]], "11. Visualize using Web Browser": [[209, "visualize-using-web-browser"]], "12. Register pre- and/or post-operation hooks": [[209, "register-pre-and-or-post-operation-hooks"]], "13. Query all operations": [[209, "query-all-operations"]], "14. Disable Fallbacks": [[209, "disable-fallbacks"]], "Placeholder title": [[210, "placeholder-title"]]}, "indexentries": {"memoryconfig (class in tt_lib.tensor)": [[12, "tt_lib.tensor.MemoryConfig"]], "tensor (class in tt_lib.tensor)": [[12, "tt_lib.tensor.Tensor"]], "__init__() (tt_lib.tensor.memoryconfig method)": [[12, "tt_lib.tensor.MemoryConfig.__init__"]], "__init__() (tt_lib.tensor.tensor method)": [[12, "tt_lib.tensor.Tensor.__init__"]], "buffer() (tt_lib.tensor.tensor method)": [[12, "tt_lib.tensor.Tensor.buffer"]], "device() (tt_lib.tensor.tensor method)": [[12, "tt_lib.tensor.Tensor.device"]], "get_dtype() (tt_lib.tensor.tensor method)": [[12, "tt_lib.tensor.Tensor.get_dtype"]], "get_layout() (tt_lib.tensor.tensor method)": [[12, "tt_lib.tensor.Tensor.get_layout"]], "get_legacy_shape() (tt_lib.tensor.tensor method)": [[12, "tt_lib.tensor.Tensor.get_legacy_shape"]], "pad() (tt_lib.tensor.tensor method)": [[12, "tt_lib.tensor.Tensor.pad"]], "pad_to_tile() (tt_lib.tensor.tensor method)": [[12, "tt_lib.tensor.Tensor.pad_to_tile"]], "storage_type() (tt_lib.tensor.tensor method)": [[12, "tt_lib.tensor.Tensor.storage_type"]], "to() (tt_lib.tensor.tensor method)": [[12, "tt_lib.tensor.Tensor.to"]], "unpad() (tt_lib.tensor.tensor method)": [[12, "tt_lib.tensor.Tensor.unpad"]], "unpad_from_tile() (tt_lib.tensor.tensor method)": [[12, "tt_lib.tensor.Tensor.unpad_from_tile"]], "adaptiveavgpool2d (class in tt_lib.fallback_ops)": [[13, "tt_lib.fallback_ops.AdaptiveAvgPool2d"]], "addandnorm() (in module tt_lib.fused_ops.add_and_norm)": [[13, "tt_lib.fused_ops.add_and_norm.AddAndNorm"]], "batchnorm2d (class in tt_lib.fallback_ops)": [[13, "tt_lib.fallback_ops.BatchNorm2d"]], "bcastopdim (class in tt_lib.tensor)": [[13, "tt_lib.tensor.BcastOpDim"]], "bcastopmath (class in tt_lib.tensor)": [[13, "tt_lib.tensor.BcastOpMath"]], "conv2d (class in tt_lib.fallback_ops)": [[13, "tt_lib.fallback_ops.Conv2d"]], "groupnorm (class in tt_lib.fallback_ops)": [[13, "tt_lib.fallback_ops.GroupNorm"]], "layernorm (class in tt_lib.fallback_ops)": [[13, "tt_lib.fallback_ops.LayerNorm"]], "layernorm() (in module tt_lib.fused_ops.layernorm)": [[13, "tt_lib.fused_ops.layernorm.Layernorm"]], "linear() (in module tt_lib.fused_ops.linear)": [[13, "tt_lib.fused_ops.linear.Linear"]], "maxpool2d (class in tt_lib.fallback_ops)": [[13, "tt_lib.fallback_ops.MaxPool2d"]], "reduceopdim (class in tt_lib.tensor)": [[13, "tt_lib.tensor.ReduceOpDim"]], "reduceopmath (class in tt_lib.tensor)": [[13, "tt_lib.tensor.ReduceOpMath"]], "synchronize() (in module tt_lib.device)": [[13, "tt_lib.device.Synchronize"]], "abs() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.abs"]], "abs_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.abs_bw"]], "acos() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.acos"]], "acos_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.acos_bw"]], "acosh() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.acosh"]], "acosh_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.acosh_bw"]], "add1() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.add1"]], "add_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.add_bw"]], "add_layernorm() (in module tt_lib.operations.primary)": [[13, "tt_lib.operations.primary.add_layernorm"]], "add_layernorm() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.add_layernorm"]], "add_unary() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.add_unary"]], "addalpha() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.addalpha"]], "addalpha_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.addalpha_bw"]], "addcdiv() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.addcdiv"]], "addcdiv_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.addcdiv_bw"]], "addcmul() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.addcmul"]], "addcmul_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.addcmul_bw"]], "angle_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.angle_bw"]], "arange() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.arange"]], "argmax() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.argmax"]], "argmin() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.argmin"]], "asin() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.asin"]], "asin_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.asin_bw"]], "asinh() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.asinh"]], "asinh_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.asinh_bw"]], "assign() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.assign"]], "atan() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.atan"]], "atan2() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.atan2"]], "atan2_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.atan2_bw"]], "atan_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.atan_bw"]], "atanh() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.atanh"]], "atanh_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.atanh_bw"]], "bcast() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.bcast"]], "bias_gelu_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.bias_gelu_bw"]], "bias_gelu_unary() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.bias_gelu_unary"]], "bias_gelu_unary_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.bias_gelu_unary_bw"]], "binary_assign_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.binary_assign_bw"]], "binary_bitwise_and (class in tt_lib.fallback_ops)": [[13, "tt_lib.fallback_ops.binary_bitwise_and"]], "binary_bitwise_left_shift (class in tt_lib.fallback_ops)": [[13, "tt_lib.fallback_ops.binary_bitwise_left_shift"]], "binary_bitwise_or (class in tt_lib.fallback_ops)": [[13, "tt_lib.fallback_ops.binary_bitwise_or"]], "binary_bitwise_right_shift (class in tt_lib.fallback_ops)": [[13, "tt_lib.fallback_ops.binary_bitwise_right_shift"]], "binary_bitwise_xor (class in tt_lib.fallback_ops)": [[13, "tt_lib.fallback_ops.binary_bitwise_xor"]], "binary_eq_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.binary_eq_bw"]], "binary_fmod (class in tt_lib.fallback_ops)": [[13, "tt_lib.fallback_ops.binary_fmod"]], "binary_ge_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.binary_ge_bw"]], "binary_gt_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.binary_gt_bw"]], "binary_le_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.binary_le_bw"]], "binary_lt_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.binary_lt_bw"]], "binary_ne_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.binary_ne_bw"]], "bitwise_not (class in tt_lib.fallback_ops)": [[13, "tt_lib.fallback_ops.bitwise_not"]], "bmm() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.bmm"]], "cbrt() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.cbrt"]], "ceil (class in tt_lib.fallback_ops)": [[13, "tt_lib.fallback_ops.ceil"]], "ceil_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.ceil_bw"]], "celu() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.celu"]], "celu_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.celu_bw"]], "chunk() (in module tt_lib.fallback_ops)": [[13, "tt_lib.fallback_ops.chunk"]], "clamp_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.clamp_bw"]], "clamp_max_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.clamp_max_bw"]], "clamp_min_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.clamp_min_bw"]], "clip() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.clip"]], "clone() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.clone"]], "complex_abs() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.complex_abs"]], "complex_abs_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.complex_abs_bw"]], "complex_add() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.complex_add"]], "complex_add_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.complex_add_bw"]], "complex_div() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.complex_div"]], "complex_div_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.complex_div_bw"]], "complex_mul() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.complex_mul"]], "complex_mul_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.complex_mul_bw"]], "complex_recip() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.complex_recip"]], "complex_recip_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.complex_recip_bw"]], "complex_sub() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.complex_sub"]], "complex_sub_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.complex_sub_bw"]], "concat() (in module tt_lib.fallback_ops)": [[13, "tt_lib.fallback_ops.concat"]], "concat() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.concat"]], "concat_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.concat_bw"]], "conj() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.conj"]], "conj_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.conj_bw"]], "conv() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.conv"]], "conv2d() (in module tt_lib.fallback_ops)": [[13, "tt_lib.fallback_ops.conv2d"]], "convert_conv_weight_tensor_to_tiled_layout() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.convert_conv_weight_tensor_to_tiled_layout"]], "copy() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.copy"]], "cos() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.cos"]], "cos_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.cos_bw"]], "cosh() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.cosh"]], "cosh_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.cosh_bw"]], "cpu() (in module tt_lib.tensor.tensor)": [[13, "tt_lib.tensor.Tensor.cpu"]], "deg2rad() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.deg2rad"]], "deg2rad_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.deg2rad_bw"]], "digamma() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.digamma"]], "digamma_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.digamma_bw"]], "div() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.div"]], "div_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.div_bw"]], "div_no_nan() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.div_no_nan"]], "div_unary() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.div_unary"]], "elu() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.elu"]], "elu_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.elu_bw"]], "embedding_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.embedding_bw"]], "embeddings() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.embeddings"]], "empty() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.empty"]], "eqz() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.eqz"]], "erf() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.erf"]], "erf_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.erf_bw"]], "erfc() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.erfc"]], "erfc_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.erfc_bw"]], "erfinv() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.erfinv"]], "erfinv_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.erfinv_bw"]], "exp() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.exp"]], "exp2() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.exp2"]], "exp2_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.exp2_bw"]], "exp_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.exp_bw"]], "expm1() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.expm1"]], "expm1_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.expm1_bw"]], "fill_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.fill_bw"]], "fill_ones_rm() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.fill_ones_rm"]], "fill_rm() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.fill_rm"]], "fill_zero_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.fill_zero_bw"]], "floor (class in tt_lib.fallback_ops)": [[13, "tt_lib.fallback_ops.floor"]], "floor() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.floor"]], "floor_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.floor_bw"]], "floor_div() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.floor_div"]], "frac_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.frac_bw"]], "full() (in module tt_lib.fallback_ops)": [[13, "tt_lib.fallback_ops.full"]], "full() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.full"]], "full_like() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.full_like"]], "ge_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.ge_bw"]], "geglu() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.geglu"]], "gelu() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.gelu"]], "gelu_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.gelu_bw"]], "gez() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.gez"]], "global_max() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.global_max"]], "global_mean() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.global_mean"]], "global_min() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.global_min"]], "global_sum() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.global_sum"]], "glu() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.glu"]], "group_norm() (in module tt_lib.fallback_ops)": [[13, "tt_lib.fallback_ops.group_norm"]], "groupnorm() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.groupnorm"]], "gt_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.gt_bw"]], "gtz() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.gtz"]], "hardshrink() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.hardshrink"]], "hardshrink_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.hardshrink_bw"]], "hardsigmoid() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.hardsigmoid"]], "hardsigmoid_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.hardsigmoid_bw"]], "hardswish() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.hardswish"]], "hardswish_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.hardswish_bw"]], "hardtanh() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.hardtanh"]], "hardtanh_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.hardtanh_bw"]], "heaviside() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.heaviside"]], "hypot() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.hypot"]], "hypot_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.hypot_bw"]], "i0() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.i0"]], "i0_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.i0_bw"]], "identity() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.identity"]], "imag() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.imag"]], "imag_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.imag_bw"]], "interpolate() (in module tt_lib.fallback_ops)": [[13, "tt_lib.fallback_ops.interpolate"]], "isclose() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.isclose"]], "isfinite() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.isfinite"]], "isinf() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.isinf"]], "isnan() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.isnan"]], "isneginf() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.isneginf"]], "isposinf() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.isposinf"]], "lamb_optimizer() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.lamb_optimizer"]], "layer_norm() (in module tt_lib.fallback_ops)": [[13, "tt_lib.fallback_ops.layer_norm"]], "layernorm() (in module tt_lib.operations.primary)": [[13, "tt_lib.operations.primary.layernorm"]], "layernorm() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.layernorm"]], "ldexp_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.ldexp_bw"]], "le_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.le_bw"]], "leaky_relu() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.leaky_relu"]], "leaky_relu_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.leaky_relu_bw"]], "left_shift() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.left_shift"]], "lerp() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.lerp"]], "lerp_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.lerp_bw"]], "lez() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.lez"]], "lgamma() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.lgamma"]], "lgamma_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.lgamma_bw"]], "log() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.log"]], "log10() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.log10"]], "log10_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.log10_bw"]], "log1p() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.log1p"]], "log1p_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.log1p_bw"]], "log2() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.log2"]], "log2_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.log2_bw"]], "log_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.log_bw"]], "log_sigmoid() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.log_sigmoid"]], "log_sigmoid_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.log_sigmoid_bw"]], "logaddexp2_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.logaddexp2_bw"]], "logaddexp_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.logaddexp_bw"]], "logical_andi() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.logical_andi"]], "logical_not_unary() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.logical_not_unary"]], "logical_noti() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.logical_noti"]], "logical_ori() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.logical_ori"]], "logical_xor() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.logical_xor"]], "logical_xori() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.logical_xori"]], "logit() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.logit"]], "logit_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.logit_bw"]], "logiteps_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.logiteps_bw"]], "lt_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.lt_bw"]], "ltz() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.ltz"]], "mac() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.mac"]], "maeloss() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.maeloss"]], "matmul() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.matmul"]], "max_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.max_bw"]], "mean_hw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.mean_hw"]], "min_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.min_bw"]], "mish() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.mish"]], "moreh_groupnorm() (in module tt_lib.operations.primary)": [[13, "tt_lib.operations.primary.moreh_groupnorm"]], "moreh_groupnorm_backward() (in module tt_lib.operations.primary)": [[13, "tt_lib.operations.primary.moreh_groupnorm_backward"]], "moreh_logsoftmax() (in module tt_lib.operations.primary)": [[13, "tt_lib.operations.primary.moreh_logsoftmax"]], "moreh_logsoftmax_backward() (in module tt_lib.operations.primary)": [[13, "tt_lib.operations.primary.moreh_logsoftmax_backward"]], "moreh_mean() (in module tt_lib.operations.primary)": [[13, "tt_lib.operations.primary.moreh_mean"]], "moreh_mean_backward() (in module tt_lib.operations.primary)": [[13, "tt_lib.operations.primary.moreh_mean_backward"]], "moreh_norm() (in module tt_lib.operations.primary)": [[13, "tt_lib.operations.primary.moreh_norm"]], "moreh_norm_backward() (in module tt_lib.operations.primary)": [[13, "tt_lib.operations.primary.moreh_norm_backward"]], "moreh_softmax() (in module tt_lib.operations.primary)": [[13, "tt_lib.operations.primary.moreh_softmax"]], "moreh_softmax_backward() (in module tt_lib.operations.primary)": [[13, "tt_lib.operations.primary.moreh_softmax_backward"]], "moreh_softmin() (in module tt_lib.operations.primary)": [[13, "tt_lib.operations.primary.moreh_softmin"]], "moreh_softmin_backward() (in module tt_lib.operations.primary)": [[13, "tt_lib.operations.primary.moreh_softmin_backward"]], "mseloss() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.mseloss"]], "mul_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.mul_bw"]], "mul_unary() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.mul_unary"]], "multigammaln() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.multigammaln"]], "multigammaln_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.multigammaln_bw"]], "ne_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.ne_bw"]], "neg() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.neg"]], "neg_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.neg_bw"]], "nextafter() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.nextafter"]], "nez() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.nez"]], "normalize_global() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.normalize_global"]], "normalize_hw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.normalize_hw"]], "ones() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.ones"]], "ones_like() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.ones_like"]], "pad() (in module tt_lib.fallback_ops)": [[13, "tt_lib.fallback_ops.pad"]], "pad() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.pad"]], "permute() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.permute"]], "polar() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.polar"]], "polar_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.polar_bw"]], "polygamma() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.polygamma"]], "polygamma_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.polygamma_bw"]], "polyval() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.polyval"]], "pow() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.pow"]], "prod() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.prod"]], "prod_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.prod_bw"]], "rad2deg() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.rad2deg"]], "rad2deg_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.rad2deg_bw"]], "rdiv() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.rdiv"]], "rdiv_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.rdiv_bw"]], "real() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.real"]], "real_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.real_bw"]], "recip() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.recip"]], "reciprocal_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.reciprocal_bw"]], "reduce() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.reduce"]], "reglu() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.reglu"]], "relu() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.relu"]], "relu6() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.relu6"]], "relu6_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.relu6_bw"]], "relu_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.relu_bw"]], "relu_max() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.relu_max"]], "relu_min() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.relu_min"]], "repeat() (in module tt_lib.fallback_ops)": [[13, "tt_lib.fallback_ops.repeat"]], "repeat() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.repeat"]], "repeat_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.repeat_bw"]], "repeat_interleave() (in module tt_lib.fallback_ops)": [[13, "tt_lib.fallback_ops.repeat_interleave"]], "repeat_interleave() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.repeat_interleave"]], "reshape() (in module tt_lib.fallback_ops)": [[13, "tt_lib.fallback_ops.reshape"]], "reshape() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.reshape"]], "right_shift() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.right_shift"]], "rmsnorm() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.rmsnorm"]], "round() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.round"]], "round_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.round_bw"]], "rpow() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.rpow"]], "rpow_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.rpow_bw"]], "rsqrt() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.rsqrt"]], "rsqrt_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.rsqrt_bw"]], "rsub() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.rsub"]], "rsub_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.rsub_bw"]], "scale_mask_softmax_in_place() (in module tt_lib.operations.primary.transformers)": [[13, "tt_lib.operations.primary.transformers.scale_mask_softmax_in_place"]], "selu_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.selu_bw"]], "sigmoid() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.sigmoid"]], "sigmoid_accurate() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.sigmoid_accurate"]], "sign() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.sign"]], "sign_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.sign_bw"]], "signbit() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.signbit"]], "silu() (in module tt_lib.fallback_ops)": [[13, "tt_lib.fallback_ops.silu"]], "silu() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.silu"]], "silu_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.silu_bw"]], "sin() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.sin"]], "sin_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.sin_bw"]], "sinh() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.sinh"]], "sinh_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.sinh_bw"]], "softmax() (in module tt_lib.fallback_ops)": [[13, "tt_lib.fallback_ops.softmax"]], "softmax() (in module tt_lib.fused_ops.softmax)": [[13, "tt_lib.fused_ops.softmax.softmax"]], "softmax_in_place() (in module tt_lib.operations.primary)": [[13, "tt_lib.operations.primary.softmax_in_place"]], "softplus() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.softplus"]], "softplus_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.softplus_bw"]], "softshrink() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.softshrink"]], "softshrink_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.softshrink_bw"]], "softsign() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.softsign"]], "softsign_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.softsign_bw"]], "split_last_dim_two_chunks_tiled() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.split_last_dim_two_chunks_tiled"]], "sqrt() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.sqrt"]], "sqrt_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.sqrt_bw"]], "square() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.square"]], "square_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.square_bw"]], "squared_difference_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.squared_difference_bw"]], "std_hw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.std_hw"]], "sub_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.sub_bw"]], "sub_unary() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.sub_unary"]], "subalpha() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.subalpha"]], "subalpha_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.subalpha_bw"]], "sum() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.sum"]], "swiglu() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.swiglu"]], "swish() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.swish"]], "tan() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.tan"]], "tan_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.tan_bw"]], "tanh() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.tanh"]], "tanh_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.tanh_bw"]], "tanhshrink() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.tanhshrink"]], "tanhshrink_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.tanhshrink_bw"]], "tensor_slice() (in module tt_lib.fallback_ops)": [[13, "tt_lib.fallback_ops.tensor_slice"]], "threshold() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.threshold"]], "threshold_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.threshold_bw"]], "tiled_prod() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.tiled_prod"]], "tilize() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.tilize"]], "tilize_with_val_padding() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.tilize_with_val_padding"]], "tilize_with_zero_padding() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.tilize_with_zero_padding"]], "torch_argmax (class in tt_lib.fallback_ops)": [[13, "tt_lib.fallback_ops.torch_argmax"]], "torch_argmin (class in tt_lib.fallback_ops)": [[13, "tt_lib.fallback_ops.torch_argmin"]], "transpose() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.transpose"]], "tril() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.tril"]], "triu() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.triu"]], "trunc (class in tt_lib.fallback_ops)": [[13, "tt_lib.fallback_ops.trunc"]], "trunc() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.trunc"]], "trunc_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.trunc_bw"]], "typecast() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.typecast"]], "unary_add_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.unary_add_bw"]], "unary_assign_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.unary_assign_bw"]], "unary_bitwise_and (class in tt_lib.fallback_ops)": [[13, "tt_lib.fallback_ops.unary_bitwise_and"]], "unary_bitwise_left_shift (class in tt_lib.fallback_ops)": [[13, "tt_lib.fallback_ops.unary_bitwise_left_shift"]], "unary_bitwise_or (class in tt_lib.fallback_ops)": [[13, "tt_lib.fallback_ops.unary_bitwise_or"]], "unary_bitwise_right_shift (class in tt_lib.fallback_ops)": [[13, "tt_lib.fallback_ops.unary_bitwise_right_shift"]], "unary_bitwise_xor (class in tt_lib.fallback_ops)": [[13, "tt_lib.fallback_ops.unary_bitwise_xor"]], "unary_div_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.unary_div_bw"]], "unary_div_no_nan_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.unary_div_no_nan_bw"]], "unary_eq_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.unary_eq_bw"]], "unary_fmod (class in tt_lib.fallback_ops)": [[13, "tt_lib.fallback_ops.unary_fmod"]], "unary_fmod_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.unary_fmod_bw"]], "unary_gt() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.unary_gt"]], "unary_lt() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.unary_lt"]], "unary_mul_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.unary_mul_bw"]], "unary_ne() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.unary_ne"]], "unary_pow_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.unary_pow_bw"]], "unary_remainder_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.unary_remainder_bw"]], "unary_sub_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.unary_sub_bw"]], "unpad() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.unpad"]], "untilize() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.untilize"]], "untilize_with_unpadding() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.untilize_with_unpadding"]], "var_hw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.var_hw"]], "where() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.where"]], "where_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.where_bw"]], "xlogy() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.xlogy"]], "xlogy_bw() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.xlogy_bw"]], "zeros() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.zeros"]], "zeros_like() (in module tt_lib.tensor)": [[13, "tt_lib.tensor.zeros_like"]], "shape (class in ttnn)": [[18, "ttnn.Shape"]], "rank (ttnn.shape property)": [[18, "ttnn.Shape.rank"]], "with_tile_padding() (ttnn.shape method)": [[18, "ttnn.Shape.with_tile_padding"]], "maxpool2d (class in ttnn)": [[19, "ttnn.MaxPool2d"]], "abs() (in module ttnn)": [[20, "ttnn.abs"]], "acos() (in module ttnn)": [[21, "ttnn.acos"]], "acosh() (in module ttnn)": [[22, "ttnn.acosh"]], "add() (in module ttnn)": [[23, "ttnn.add"]], "addcdiv() (in module ttnn)": [[24, "ttnn.addcdiv"]], "addcmul() (in module ttnn)": [[25, "ttnn.addcmul"]], "arange() (in module ttnn)": [[26, "ttnn.arange"]], "argmax() (in module ttnn)": [[27, "ttnn.argmax"]], "as_tensor() (in module ttnn)": [[28, "ttnn.as_tensor"]], "asin() (in module ttnn)": [[29, "ttnn.asin"]], "asinh() (in module ttnn)": [[30, "ttnn.asinh"]], "atan() (in module ttnn)": [[31, "ttnn.atan"]], "atan2() (in module ttnn)": [[32, "ttnn.atan2"]], "atanh() (in module ttnn)": [[33, "ttnn.atanh"]], "cbrt() (in module ttnn)": [[34, "ttnn.cbrt"]], "celu() (in module ttnn)": [[35, "ttnn.celu"]], "clip() (in module ttnn)": [[36, "ttnn.clip"]], "clone() (in module ttnn)": [[37, "ttnn.clone"]], "close_device() (in module ttnn)": [[38, "ttnn.close_device"]], "concat() (in module ttnn)": [[39, "ttnn.concat"]], "cos() (in module ttnn)": [[40, "ttnn.cos"]], "cosh() (in module ttnn)": [[41, "ttnn.cosh"]], "create_sharded_memory_config() (in module ttnn)": [[42, "ttnn.create_sharded_memory_config"]], "deallocate() (in module ttnn)": [[43, "ttnn.deallocate"]], "deg2rad() (in module ttnn)": [[44, "ttnn.deg2rad"]], "digamma() (in module ttnn)": [[45, "ttnn.digamma"]], "dump_tensor() (in module ttnn)": [[46, "ttnn.dump_tensor"]], "elu() (in module ttnn)": [[47, "ttnn.elu"]], "embedding() (in module ttnn)": [[48, "ttnn.embedding"]], "empty() (in module ttnn)": [[49, "ttnn.empty"]], "eq() (in module ttnn)": [[50, "ttnn.eq"]], "eqz() (in module ttnn)": [[51, "ttnn.eqz"]], "erf() (in module ttnn)": [[52, "ttnn.erf"]], "erfc() (in module ttnn)": [[53, "ttnn.erfc"]], "erfinv() (in module ttnn)": [[54, "ttnn.erfinv"]], "exp() (in module ttnn)": [[55, "ttnn.exp"]], "exp2() (in module ttnn)": [[56, "ttnn.exp2"]], "expm1() (in module ttnn)": [[57, "ttnn.expm1"]], "from_device() (in module ttnn)": [[58, "ttnn.from_device"]], "from_torch() (in module ttnn)": [[59, "ttnn.from_torch"]], "full() (in module ttnn)": [[60, "ttnn.full"]], "full_like() (in module ttnn)": [[61, "ttnn.full_like"]], "ge() (in module ttnn)": [[62, "ttnn.ge"]], "geglu() (in module ttnn)": [[63, "ttnn.geglu"]], "gelu() (in module ttnn)": [[64, "ttnn.gelu"]], "gez() (in module ttnn)": [[65, "ttnn.gez"]], "global_avg_pool2d() (in module ttnn)": [[66, "ttnn.global_avg_pool2d"]], "glu() (in module ttnn)": [[67, "ttnn.glu"]], "group_norm() (in module ttnn)": [[68, "ttnn.group_norm"]], "gt() (in module ttnn)": [[69, "ttnn.gt"]], "gtz() (in module ttnn)": [[70, "ttnn.gtz"]], "hardshrink() (in module ttnn)": [[71, "ttnn.hardshrink"]], "hardsigmoid() (in module ttnn)": [[72, "ttnn.hardsigmoid"]], "hardswish() (in module ttnn)": [[73, "ttnn.hardswish"]], "hardtanh() (in module ttnn)": [[74, "ttnn.hardtanh"]], "heaviside() (in module ttnn)": [[75, "ttnn.heaviside"]], "hypot() (in module ttnn)": [[76, "ttnn.hypot"]], "i0() (in module ttnn)": [[77, "ttnn.i0"]], "isclose() (in module ttnn)": [[78, "ttnn.isclose"]], "isfinite() (in module ttnn)": [[79, "ttnn.isfinite"]], "isinf() (in module ttnn)": [[80, "ttnn.isinf"]], "isnan() (in module ttnn)": [[81, "ttnn.isnan"]], "isneginf() (in module ttnn)": [[82, "ttnn.isneginf"]], "isposinf() (in module ttnn)": [[83, "ttnn.isposinf"]], "fill_cache_for_user_() (in module ttnn.kv_cache)": [[84, "ttnn.kv_cache.fill_cache_for_user_"]], "update_cache_for_token_() (in module ttnn.kv_cache)": [[85, "ttnn.kv_cache.update_cache_for_token_"]], "l1_loss() (in module ttnn)": [[86, "ttnn.l1_loss"]], "layer_norm() (in module ttnn)": [[87, "ttnn.layer_norm"]], "ldexp() (in module ttnn)": [[88, "ttnn.ldexp"]], "le() (in module ttnn)": [[89, "ttnn.le"]], "leaky_relu() (in module ttnn)": [[90, "ttnn.leaky_relu"]], "lerp() (in module ttnn)": [[91, "ttnn.lerp"]], "lez() (in module ttnn)": [[92, "ttnn.lez"]], "lgamma() (in module ttnn)": [[93, "ttnn.lgamma"]], "linear() (in module ttnn)": [[94, "ttnn.linear"]], "load_tensor() (in module ttnn)": [[95, "ttnn.load_tensor"]], "log() (in module ttnn)": [[96, "ttnn.log"]], "log10() (in module ttnn)": [[97, "ttnn.log10"]], "log1p() (in module ttnn)": [[98, "ttnn.log1p"]], "log2() (in module ttnn)": [[99, "ttnn.log2"]], "log_sigmoid() (in module ttnn)": [[100, "ttnn.log_sigmoid"]], "logaddexp() (in module ttnn)": [[101, "ttnn.logaddexp"]], "logaddexp2() (in module ttnn)": [[102, "ttnn.logaddexp2"]], "logical_and() (in module ttnn)": [[103, "ttnn.logical_and"]], "logical_or() (in module ttnn)": [[105, "ttnn.logical_or"]], "logical_xor() (in module ttnn)": [[106, "ttnn.logical_xor"]], "logit() (in module ttnn)": [[107, "ttnn.logit"]], "lt() (in module ttnn)": [[108, "ttnn.lt"]], "ltz() (in module ttnn)": [[109, "ttnn.ltz"]], "mac() (in module ttnn)": [[110, "ttnn.mac"]], "manage_device() (in module ttnn)": [[111, "ttnn.manage_device"]], "matmul() (in module ttnn)": [[112, "ttnn.matmul"]], "max() (in module ttnn)": [[113, "ttnn.max"]], "maximum() (in module ttnn)": [[114, "ttnn.maximum"]], "mean() (in module ttnn)": [[115, "ttnn.mean"]], "min() (in module ttnn)": [[116, "ttnn.min"]], "minimum() (in module ttnn)": [[117, "ttnn.minimum"]], "mish() (in module ttnn)": [[118, "ttnn.mish"]], "preprocess_model() (in module ttnn.model_preprocessing)": [[119, "ttnn.model_preprocessing.preprocess_model"]], "preprocess_model_parameters() (in module ttnn.model_preprocessing)": [[120, "ttnn.model_preprocessing.preprocess_model_parameters"]], "mse_loss() (in module ttnn)": [[121, "ttnn.mse_loss"]], "multigammaln() (in module ttnn)": [[122, "ttnn.multigammaln"]], "multiply() (in module ttnn)": [[123, "ttnn.multiply"]], "ne() (in module ttnn)": [[124, "ttnn.ne"]], "neg() (in module ttnn)": [[125, "ttnn.neg"]], "nextafter() (in module ttnn)": [[126, "ttnn.nextafter"]], "nez() (in module ttnn)": [[127, "ttnn.nez"]], "ones() (in module ttnn)": [[128, "ttnn.ones"]], "ones_like() (in module ttnn)": [[129, "ttnn.ones_like"]], "open_device() (in module ttnn)": [[130, "ttnn.open_device"]], "pad() (in module ttnn)": [[131, "ttnn.pad"]], "permute() (in module ttnn)": [[132, "ttnn.permute"]], "polygamma() (in module ttnn)": [[133, "ttnn.polygamma"]], "polyval() (in module ttnn)": [[134, "ttnn.polyval"]], "pow() (in module ttnn)": [[135, "ttnn.pow"]], "prelu() (in module ttnn)": [[136, "ttnn.prelu"]], "rad2deg() (in module ttnn)": [[137, "ttnn.rad2deg"]], "reallocate() (in module ttnn)": [[138, "ttnn.reallocate"]], "reciprocal() (in module ttnn)": [[139, "ttnn.reciprocal"]], "register_post_operation_hook() (in module ttnn)": [[140, "ttnn.register_post_operation_hook"]], "register_pre_operation_hook() (in module ttnn)": [[141, "ttnn.register_pre_operation_hook"]], "reglu() (in module ttnn)": [[142, "ttnn.reglu"]], "relu() (in module ttnn)": [[143, "ttnn.relu"]], "relu6() (in module ttnn)": [[144, "ttnn.relu6"]], "repeat() (in module ttnn)": [[145, "ttnn.repeat"]], "repeat_interleave() (in module ttnn)": [[146, "ttnn.repeat_interleave"]], "reshape() (in module ttnn)": [[147, "ttnn.reshape"]], "rms_norm() (in module ttnn)": [[148, "ttnn.rms_norm"]], "rsqrt() (in module ttnn)": [[149, "ttnn.rsqrt"]], "set_printoptions() (in module ttnn)": [[150, "ttnn.set_printoptions"]], "sigmoid() (in module ttnn)": [[151, "ttnn.sigmoid"]], "sigmoid_accurate() (in module ttnn)": [[152, "ttnn.sigmoid_accurate"]], "sign() (in module ttnn)": [[153, "ttnn.sign"]], "signbit() (in module ttnn)": [[154, "ttnn.signbit"]], "silu() (in module ttnn)": [[155, "ttnn.silu"]], "sin() (in module ttnn)": [[156, "ttnn.sin"]], "sinh() (in module ttnn)": [[157, "ttnn.sinh"]], "softmax() (in module ttnn)": [[158, "ttnn.softmax"]], "softplus() (in module ttnn)": [[159, "ttnn.softplus"]], "softshrink() (in module ttnn)": [[160, "ttnn.softshrink"]], "softsign() (in module ttnn)": [[161, "ttnn.softsign"]], "sqrt() (in module ttnn)": [[163, "ttnn.sqrt"]], "square() (in module ttnn)": [[164, "ttnn.square"]], "squared_difference() (in module ttnn)": [[165, "ttnn.squared_difference"]], "std() (in module ttnn)": [[166, "ttnn.std"]], "subtract() (in module ttnn)": [[167, "ttnn.subtract"]], "sum() (in module ttnn)": [[168, "ttnn.sum"]], "swiglu() (in module ttnn)": [[169, "ttnn.swiglu"]], "swish() (in module ttnn)": [[170, "ttnn.swish"]], "synchronize_device() (in module ttnn)": [[171, "ttnn.synchronize_device"]], "tan() (in module ttnn)": [[172, "ttnn.tan"]], "tanh() (in module ttnn)": [[173, "ttnn.tanh"]], "tanhshrink() (in module ttnn)": [[174, "ttnn.tanhshrink"]], "threshold() (in module ttnn)": [[175, "ttnn.threshold"]], "to_device() (in module ttnn)": [[176, "ttnn.to_device"]], "to_layout() (in module ttnn)": [[177, "ttnn.to_layout"]], "to_memory_config() (in module ttnn)": [[178, "ttnn.to_memory_config"]], "to_torch() (in module ttnn)": [[179, "ttnn.to_torch"]], "attention_softmax() (in module ttnn.transformer)": [[181, "ttnn.transformer.attention_softmax"]], "attention_softmax_() (in module ttnn.transformer)": [[182, "ttnn.transformer.attention_softmax_"]], "concatenate_heads() (in module ttnn.transformer)": [[183, "ttnn.transformer.concatenate_heads"]], "rotary_embedding() (in module ttnn.transformer)": [[184, "ttnn.transformer.rotary_embedding"]], "split_query_key_value_and_split_heads() (in module ttnn.transformer)": [[185, "ttnn.transformer.split_query_key_value_and_split_heads"]], "tril() (in module ttnn)": [[186, "ttnn.tril"]], "triu() (in module ttnn)": [[187, "ttnn.triu"]], "upsample() (in module ttnn)": [[188, "ttnn.upsample"]], "var() (in module ttnn)": [[189, "ttnn.var"]], "where() (in module ttnn)": [[190, "ttnn.where"]], "xlogy() (in module ttnn)": [[191, "ttnn.xlogy"]], "zeros() (in module ttnn)": [[192, "ttnn.zeros"]], "zeros_like() (in module ttnn)": [[193, "ttnn.zeros_like"]]}})